# 2.4 进阶技巧和最佳实践

## 🎯 本章目标

掌握 Skills 的高级用法、性能优化、团队协作和调试技巧。

---

## 🔧 高级技巧

### 技巧 1：Skills 组合使用

**场景：** 创建复杂报告，需要多个 Skills 协同工作

**示例：季度业务报告**

```
用户请求: "创建 Q4 业务报告 PPT"

Claude 自动组合：
├─ brand-guidelines (品牌规范)
│  └─ 应用公司颜色、字体、Logo
├─ csv-analyzer (数据分析)
│  └─ 分析销售数据，生成图表
├─ markdown-report (报告生成)
│  └─ 创建文字内容
└─ powerpoint-generator (PPT 生成)
   └─ 组装成最终 PPT
```

**关键点：**
- ✅ 每个 Skill 专注单一功能
- ✅ Skills 自动协作，无需手动协调
- ✅ Claude 根据 description 判断调用顺序

---

### 技巧 2：分层 Skill 设计

**问题：** 单个 SKILL.md 太长（100+ 行）

**解决方案：** 分层引用

```
enterprise-reporting/
├── SKILL.md              # 主入口（简洁）
├── core/
│   ├── brand.md          # 品牌规范
│   ├── templates.md      # 模板说明
│   └── process.md        # 流程细节
├── templates/
│   ├── slide_1.pptx
│   └── slide_2.pptx
└── scripts/
    └── generate.py
```

**SKILL.md（精简版）：**

```markdown
---
name: enterprise-reporting
description: Generate enterprise reports with company branding. Use for quarterly reports, presentations, or business summaries.
---

# Enterprise Reporting

## Quick Start
1. Read brand guidelines: `core/brand.md`
2. Select template from: `core/templates.md`
3. Follow process in: `core/process.md`

## For Detailed Information
- Brand Guidelines: See `core/brand.md`
- Templates: See `core/templates.md`
- Process: See `core/process.md`
```

**好处：**
- ⚡ Level 1 加载快（主文件很小）
- 📁 Level 2/3 按需加载
- 📝 易于维护和更新

---

### 技巧 3：条件逻辑

**场景：** 根据不同条件使用不同流程

**SKILL.md 示例：**

```markdown
---
name: smart-analyzer
description: Analyze data files (CSV, JSON, Excel). Automatically detects file type and uses appropriate method.
---

# Smart Data Analyzer

## File Type Detection

### If CSV file:
1. Use `scripts/analyze_csv.py`
2. Generate distribution charts
3. Create summary table

### If JSON file:
1. Use `scripts/analyze_json.py`
2. Show data structure
3. Validate schema

### If Excel file:
1. Use `scripts/analyze_excel.py`
2. Process all sheets
3. Combine results

## Usage
```python
# Detect file type
if file.endswith('.csv'):
    python scripts/analyze_csv.py {file}
elif file.endswith('.json'):
    python scripts/analyze_json.py {file}
elif file.endswith('.xlsx'):
    python scripts/analyze_excel.py {file}
```
```

---

### 技巧 4：动态模板

**场景：** 模板需要根据数据动态生成

**templates/dynamic_report.md：**

```markdown
# {Title}

{% for item in key_findings %}
## Finding {{ loop.index }}: {{ item.title }}
{{ item.description }}

**Impact**: {{ item.impact }}
**Confidence**: {{ item.confidence }}%
{% endfor %}

## Summary
{{ summary }}
```

**配合 Jinja2 使用：**

```python
# scripts/generate_report.py
from jinja2 import Template

template = Template(open('templates/dynamic_report.md').read())

data = {
    'title': 'Q4 Analysis',
    'key_findings': [
        {'title': 'Sales Growth', 'description': '...', 'impact': 'High', 'confidence': 95},
        {'title': 'Market Share', 'description': '...', 'impact': 'Medium', 'confidence': 80},
    ],
    'summary': '...'
}

output = template.render(data)
```

---

## 🏢 团队协作最佳实践

### 方案 1：Git + Project Skills

**推荐方式** ✅

```bash
your-project/
├── .claude/
│   └── skills/
│       ├── team-reporting/
│       ├── code-review/
│       └── api-docs/
├── .gitignore
└── README.md
```

**设置流程：**

```bash
# 1. 初始化项目
cd your-project
mkdir -p .claude/skills

# 2. 创建团队 Skill
cd .claude/skills
mkdir team-reporting
# 创建 SKILL.md...

# 3. 提交到 Git
git add .claude/
git commit -m "Add team reporting skill"
git push

# 4. 团队成员拉取
git pull  # Skills 自动可用！
```

**优点：**
- ✅ 版本控制
- ✅ Code Review
- ✅ 自动同步
- ✅ 权限管理

---

### 方案 2：Claude Code Plugins

**适用场景：** 通用 Skills，多项目共享

**创建 Plugin：**

```json
// package.json
{
  "name": "acme-skills",
  "version": "1.0.0",
  "description": "Acme Corp shared skills",
  "skills": {
    "brand-guidelines": "./skills/brand-guidelines",
    "ppt-generator": "./skills/ppt-generator"
  }
}
```

**发布：**

```bash
# 1. 打包 Plugin
npm pack

# 2. 团队安装
claude plugin install acme-skills-1.0.0.tgz
```

---

### 方案 3：内部 Skills 仓库

**适用场景：** 大型组织，多团队共享

```
company-skills/
├── README.md
├── marketing/
│   ├── social-media/
│   └── blog-post/
├── engineering/
│   ├── code-review/
│   └── api-docs/
└── sales/
    ├── proposal/
    └── quote/
```

**使用方式：**

```bash
# 1. Clone 仓库
git clone git@github.com:company/skills.git ~/.claude/skills/company

# 2. Symlink 到 Personal Skills
ln -s ~/.claude/skills/company/engineering/code-review ~/.claude/skills/

# 3. 定期更新
cd ~/.claude/skills/company
git pull
```

---

## 🐛 调试技巧

### 调试级别 1：检查 Skill 是否加载

```bash
# 启用调试模式
claude --debug

# 输出示例：
# [DEBUG] Loading skills from ~/.claude/skills/
# [DEBUG] Loaded skill: csv-analyzer
# [DEBUG] Loaded skill: markdown-report
# [INFO] 2 skills loaded successfully
```

**常见问题：**

1. **Skill 未加载**
   ```
   [ERROR] Failed to load skill: invalid-skill
   [ERROR] Reason: SKILL.md not found
   ```
   → 检查文件路径和文件名

2. **YAML 解析错误**
   ```
   [ERROR] Failed to parse YAML in csv-analyzer/SKILL.md
   [ERROR] Line 3: expected ':' after key
   ```
   → 检查 YAML 格式

---

### 调试级别 2：验证 description

**测试方法：** 提问是否触发 Skill

```
测试用例 1:
你: "分析这个 CSV 文件"
预期: 加载 csv-analyzer Skill

测试用例 2:
你: "创建 PPT"
预期: 加载 powerpoint Skill

测试用例 3:
你: "写一个报告"
预期: 加载 markdown-report Skill
```

**如果未触发：**
1. 检查 description 是否包含触发关键词
2. 增加更多触发词
3. 使用更具体的描述

**优化示例：**

```yaml
# ❌ Before
description: CSV tool

# ✅ After
description: Analyze CSV files and generate statistics. Use when user mentions CSV, data analysis, or wants to explore spreadsheet data.
```

---

### 调试级别 3：脚本执行调试

**方法 1：手动测试脚本**

```bash
# 独立运行脚本
python scripts/analyze.py test.csv

# 检查输出和错误
```

**方法 2：添加日志**

```python
# scripts/analyze.py
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

def analyze_csv(file_path):
    logger.debug(f"Loading file: {file_path}")
    df = pd.read_csv(file_path)
    logger.debug(f"Loaded {len(df)} rows")
    # ...
```

**方法 3：SKILL.md 中添加调试指令**

```markdown
## Debugging

If script fails:
1. Check file path exists
2. Verify file encoding (UTF-8)
3. Run with verbose flag: `python scripts/analyze.py -v test.csv`
4. Check logs in `logs/analyzer.log`
```

---

## ⚡ 性能优化

### 优化 1：减少 SKILL.md 大小

**问题：** Level 2 加载慢（SKILL.md 太大）

**Before（100+ 行）：**
```markdown
---
name: big-skill
description: ...
---

# Big Skill

[100+ lines of content...]
```

**After（精简主文件）：**
```markdown
---
name: big-skill
description: ...
---

# Big Skill

## Quick Guide
Essential information here (10-20 lines)

## Detailed Documentation
See `docs/detailed_guide.md` for complete information

## Examples
See `examples/` folder
```

---

### 优化 2：缓存计算结果

**场景：** 重复计算相同数据

**scripts/analyze.py（添加缓存）：**

```python
import hashlib
import pickle
import os

def get_cache_key(file_path):
    """Generate cache key from file content"""
    with open(file_path, 'rb') as f:
        return hashlib.md5(f.read()).hexdigest()

def analyze_csv_cached(file_path):
    """Analyze CSV with caching"""
    cache_dir = 'cache/'
    os.makedirs(cache_dir, exist_ok=True)

    cache_key = get_cache_key(file_path)
    cache_file = f'{cache_dir}/{cache_key}.pkl'

    # Check cache
    if os.path.exists(cache_file):
        with open(cache_file, 'rb') as f:
            return pickle.load(f)

    # Compute
    result = analyze_csv(file_path)

    # Save cache
    with open(cache_file, 'wb') as f:
        pickle.dump(result, f)

    return result
```

---

### 优化 3：并行处理

**场景：** 处理多个文件

**scripts/batch_analyze.py：**

```python
from multiprocessing import Pool
import os

def analyze_file(file_path):
    """Analyze single file"""
    return analyze_csv(file_path)

def batch_analyze(file_paths, workers=4):
    """Analyze multiple files in parallel"""
    with Pool(workers) as pool:
        results = pool.map(analyze_file, file_paths)
    return results

# Usage
files = ['file1.csv', 'file2.csv', 'file3.csv']
results = batch_analyze(files)
```

---

## 🔒 安全最佳实践

### 1. 限制工具权限

```yaml
---
name: read-only-analyzer
description: ...
allowed-tools:
  - Read    # 只读
  - Grep    # 搜索
  - Glob    # 文件查找
# 禁止: Write, Edit, Bash
---
```

### 2. 验证输入

```python
# scripts/analyze.py
import os

def analyze_csv(file_path):
    # 验证文件存在
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")

    # 验证文件类型
    if not file_path.endswith('.csv'):
        raise ValueError("Only CSV files supported")

    # 验证文件大小（防止 OOM）
    max_size = 100 * 1024 * 1024  # 100MB
    if os.path.getsize(file_path) > max_size:
        raise ValueError("File too large (>100MB)")

    # 安全读取
    df = pd.read_csv(file_path)
    return analyze(df)
```

### 3. 审计第三方 Skills

**检查清单：**
- [ ] 检查所有脚本代码
- [ ] 验证网络请求目标
- [ ] 检查文件系统访问
- [ ] 审查依赖包
- [ ] 测试在沙盒环境

**示例审计流程：**

```bash
# 1. 检查 SKILL.md
cat SKILL.md | grep -E "(http|curl|wget|git clone)"

# 2. 检查 Python 脚本
grep -r "requests\|urllib\|subprocess" scripts/

# 3. 检查 Bash 命令
grep -r "rm -rf\|dd\|mkfs" scripts/

# 4. 检查依赖
cat requirements.txt  # 是否有可疑包？
```

---

## 📊 Skill 质量指标

### 评估标准

| 指标 | 优秀 | 良好 | 需改进 |
|------|------|------|--------|
| **description 长度** | 100-200 字符 | 50-100 字符 | <50 或 >500 字符 |
| **触发成功率** | >90% | 60-90% | <60% |
| **SKILL.md 长度** | <50 行 | 50-100 行 | >100 行 |
| **脚本执行时间** | <5 秒 | 5-30 秒 | >30 秒 |
| **文档完整性** | 有示例+troubleshooting | 有基本文档 | 缺少文档 |

### 改进建议

**如果触发率 <60%：**
1. 增强 description（添加触发词）
2. 拆分为多个更专注的 Skills
3. 添加更多使用示例

**如果执行时间 >30 秒：**
1. 添加缓存
2. 优化算法
3. 使用并行处理
4. 考虑预计算

---

## 🎓 核心要点总结

### 高级技巧
- ✅ Skills 自动组合
- ✅ 分层设计大型 Skills
- ✅ 条件逻辑处理不同场景
- ✅ 动态模板提高灵活性

### 团队协作
- ✅ Git + Project Skills（推荐）
- ✅ Plugins 共享通用 Skills
- ✅ 内部仓库管理企业 Skills

### 调试技巧
- ✅ 使用 `--debug` 模式
- ✅ 验证 description 触发
- ✅ 手动测试脚本
- ✅ 添加日志和错误处理

### 性能优化
- ✅ 精简 SKILL.md
- ✅ 缓存计算结果
- ✅ 并行处理批量任务

### 安全实践
- ✅ 限制工具权限
- ✅ 验证输入数据
- ✅ 审计第三方 Skills

---

**下一步：** [2.5 本章小结](./2.5-本章小结.md) - 回顾核心知识点和常见问题！
