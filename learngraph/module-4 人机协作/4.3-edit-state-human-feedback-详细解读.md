# LangGraph çŠ¶æ€ç¼–è¾‘ä¸äººå·¥åé¦ˆè¯¦ç»†è§£è¯»

## ğŸ“š æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è§£è¯» LangGraph ä¸­çš„**çŠ¶æ€ç¼–è¾‘ï¼ˆState Editingï¼‰**å’Œ**äººå·¥åé¦ˆï¼ˆHuman Feedbackï¼‰**æœºåˆ¶ã€‚è¿™æ˜¯æ„å»ºäººæœºåä½œ AI ç³»ç»Ÿçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿåœ¨ Agent æ‰§è¡Œè¿‡ç¨‹ä¸­æš‚åœã€æ£€æŸ¥ã€ä¿®æ”¹çŠ¶æ€ï¼Œå¹¶å¼•å…¥äººç±»æ™ºæ…§æ¥æŒ‡å¯¼ AI å†³ç­–ã€‚

---

## ğŸ“š æœ¯è¯­è¡¨

| æœ¯è¯­åç§° | LangGraph å®šä¹‰å’Œè§£è¯» | Python å®šä¹‰å’Œè¯´æ˜ | é‡è¦ç¨‹åº¦ |
|---------|---------------------|------------------|---------|
| **çŠ¶æ€ç¼–è¾‘(State Editing)** | åœ¨å›¾æ‰§è¡Œè¿‡ç¨‹ä¸­æš‚åœå¹¶ä¿®æ”¹çŠ¶æ€æ•°æ®çš„èƒ½åŠ›ï¼Œå…è®¸äººç±»å¹²é¢„ AI å†³ç­–è·¯å¾„ | é€šè¿‡ update_state() API å®ç° | â­â­â­â­â­ |
| **update_state()** | æ›´æ–°å›¾çŠ¶æ€çš„æ ¸å¿ƒæ–¹æ³•ï¼Œæ”¯æŒä¿®æ”¹çŠ¶æ€å€¼å¹¶æŒ‡å®šæ›´æ–°æ¥æºèŠ‚ç‚¹(as_node å‚æ•°) | `graph.update_state(config, values, as_node=...)` | â­â­â­â­â­ |
| **as_node å‚æ•°** | update_state çš„å…³é”®å‚æ•°ï¼ŒæŒ‡å®šçŠ¶æ€æ›´æ–°æ¥è‡ªå“ªä¸ªèŠ‚ç‚¹ï¼Œå†³å®šåç»­æ‰§è¡Œæµç¨‹ | å­—ç¬¦ä¸²ç±»å‹ï¼Œå€¼ä¸ºèŠ‚ç‚¹åç§° | â­â­â­â­â­ |
| **Reducer æœºåˆ¶** | çŠ¶æ€å­—æ®µçš„åˆå¹¶ç­–ç•¥ï¼Œå¦‚ add_messages ä¼šæ ¹æ®æ¶ˆæ¯ ID å†³å®šè¿½åŠ æˆ–è¦†ç›– | Annotated ç±»å‹æ³¨è§£å®ç° | â­â­â­â­â­ |
| **add_messages** | MessagesState çš„å†…ç½® reducerï¼Œæœ‰ ID åˆ™è¦†ç›–åŒ ID æ¶ˆæ¯ï¼Œæ—  ID åˆ™è¿½åŠ æ–°æ¶ˆæ¯ | `Annotated[list, add_messages]` | â­â­â­â­â­ |
| **Message ID** | æ¶ˆæ¯çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºæ¶ˆæ¯å»é‡å’Œè¦†ç›–ï¼ŒçŠ¶æ€ç¼–è¾‘æ—¶ä¿æŒ ID å®ç°æ¶ˆæ¯æ›¿æ¢ | BaseMessage çš„ id å±æ€§(å­—ç¬¦ä¸²æˆ– UUID) | â­â­â­â­â­ |
| **Human Feedback Node** | ä¸“é—¨ç”¨äºæ¥æ”¶äººç±»è¾“å…¥çš„ç©ºæ“ä½œèŠ‚ç‚¹ï¼Œä½œä¸ºäººæœºäº¤äº’çš„æ–­ç‚¹ä½ç½® | è¿”å›å€¼ä¸º None æˆ– pass çš„èŠ‚ç‚¹å‡½æ•° | â­â­â­â­ |
| **MessagesState** | LangGraph é¢„å®šä¹‰çš„çŠ¶æ€ç±»ï¼ŒåŒ…å« messages å­—æ®µå’Œ add_messages reducer | `from langgraph.graph import MessagesState` | â­â­â­â­â­ |
| **RunnableConfig** | LangChain çš„é…ç½®å¯¹è±¡ï¼Œä¼ é€’è¿è¡Œæ—¶å‚æ•°(å¦‚ callbacksã€streaming é…ç½®) | `from langchain_core.runnables import RunnableConfig` | â­â­â­ |
| **RemoveMessage** | ç‰¹æ®Šæ¶ˆæ¯ç±»å‹ï¼Œç”¨äºä»çŠ¶æ€ä¸­åˆ é™¤æŒ‡å®š ID çš„æ¶ˆæ¯(é€šè¿‡ add_messages å¤„ç†) | `RemoveMessage(id=message_id)` | â­â­â­â­ |
| **è¦†ç›– vs è¿½åŠ ** | çŠ¶æ€æ›´æ–°çš„ä¸¤ç§æ¨¡å¼:ä¿æŒ ID è¦†ç›–åŸæ¶ˆæ¯ï¼Œä¸æä¾› ID è¿½åŠ æ–°æ¶ˆæ¯ | ç”± add_messages reducer çš„é€»è¾‘å†³å®š | â­â­â­â­â­ |

---

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### ä»€ä¹ˆæ˜¯çŠ¶æ€ç¼–è¾‘ï¼Ÿ

**çŠ¶æ€ç¼–è¾‘ï¼ˆState Editingï¼‰** æ˜¯ LangGraph æä¾›çš„ä¸€ç§èƒ½åŠ›ï¼Œå…è®¸æˆ‘ä»¬åœ¨å›¾æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼š
- æš‚åœå›¾çš„æ‰§è¡Œï¼ˆä½¿ç”¨æ–­ç‚¹ï¼‰
- æ£€æŸ¥å½“å‰çŠ¶æ€
- ä¿®æ”¹çŠ¶æ€æ•°æ®
- ç»§ç»­æ‰§è¡Œ

è¿™æ˜¯ä¸€ç§"æ—¶å…‰æœº"èƒ½åŠ›ï¼Œè®©æˆ‘ä»¬å¯ä»¥å¹²é¢„ AI Agent çš„æ‰§è¡Œæµç¨‹ã€‚

### äººæœºåä½œçš„ä¸‰ç§æ¨¡å¼

åœ¨ä¹‹å‰çš„å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬äº†è§£äº†äººæœºåä½œçš„ä¸‰ç§ä¸»è¦æ¨¡å¼ï¼š

1. **å®¡æ‰¹æ¨¡å¼ï¼ˆApprovalï¼‰**
   - åœ¨å…³é”®æ“ä½œå‰æš‚åœ
   - å±•ç¤º AI è®¡åˆ’æ‰§è¡Œçš„æ“ä½œ
   - ç­‰å¾…äººç±»æ‰¹å‡†æˆ–æ‹’ç»
   - **ç¤ºä¾‹**ï¼šAI è®¡åˆ’åˆ é™¤æ•°æ®å‰ï¼Œå…ˆè·å¾—ç¡®è®¤

2. **è°ƒè¯•æ¨¡å¼ï¼ˆDebuggingï¼‰**
   - å›æº¯å›¾çš„æ‰§è¡Œå†å²
   - é‡ç°æˆ–é¿å…é”™è¯¯
   - åˆ†æé—®é¢˜æ ¹æº
   - **ç¤ºä¾‹**ï¼šå½“ AI å‡ºé”™æ—¶ï¼Œå›åˆ°ä¹‹å‰çš„æ£€æŸ¥ç‚¹é‡æ–°æ‰§è¡Œ

3. **ç¼–è¾‘æ¨¡å¼ï¼ˆEditingï¼‰** â­ æœ¬è¯¾é‡ç‚¹
   - ç›´æ¥ä¿®æ”¹å›¾çš„çŠ¶æ€
   - æ³¨å…¥äººç±»åé¦ˆæˆ–çŸ¥è¯†
   - çº æ­£ AI çš„ç†è§£åå·®
   - **ç¤ºä¾‹**ï¼šä¿®æ­£ AI è¯¯è§£çš„ç”¨æˆ·æ„å›¾

### ä¸ºä»€ä¹ˆéœ€è¦çŠ¶æ€ç¼–è¾‘ï¼Ÿ

è€ƒè™‘ä»¥ä¸‹åœºæ™¯ï¼š

**åœºæ™¯ 1ï¼šçº æ­£ AI ç†è§£**
```
ç”¨æˆ·ï¼š"è®¡ç®— 2 Ã— 3"
AIï¼šå‡†å¤‡æ‰§è¡Œ...
[æš‚åœ]
äººç±»ï¼š"ä¸å¯¹ï¼Œæˆ‘æƒ³è¦ 3 Ã— 3"
[ä¿®æ”¹çŠ¶æ€]
AIï¼šæ‰§è¡Œä¿®æ­£åçš„è®¡ç®— â†’ 9
```

**åœºæ™¯ 2ï¼šæ³¨å…¥ä¸“å®¶çŸ¥è¯†**
```
AIï¼šåˆ†ææ•°æ®ï¼Œå‘ç°å¼‚å¸¸å€¼...
[æš‚åœ]
ä¸“å®¶ï¼š"è¿™ä¸ªå¼‚å¸¸å€¼æ˜¯é¢„æœŸçš„ï¼Œæ˜¯å­£èŠ‚æ€§å› ç´ "
[æ·»åŠ ä¸Šä¸‹æ–‡åˆ°çŠ¶æ€]
AIï¼šåŸºäºä¸“å®¶åé¦ˆè°ƒæ•´åˆ†æ...
```

**åœºæ™¯ 3ï¼šå¼•å¯¼æ¢ç´¢æ–¹å‘**
```
ç ”ç©¶ Agentï¼šè§„åˆ’è°ƒç ” 10 ä¸ªä¸»é¢˜...
[æš‚åœ]
ç ”ç©¶å‘˜ï¼š"èšç„¦å‰ 3 ä¸ªå³å¯ï¼Œå…¶ä»–ä¸é‡è¦"
[ä¿®æ”¹å¾…å¤„ç†åˆ—è¡¨]
Agentï¼šæ‰§è¡Œç²¾ç®€åçš„è®¡åˆ’...
```

---

## ğŸ”§ å®æˆ˜æ¡ˆä¾‹ 1ï¼šåŸºç¡€çŠ¶æ€ç¼–è¾‘

### ç³»ç»Ÿæ¶æ„

æˆ‘ä»¬æ„å»ºä¸€ä¸ªæ•°å­¦è®¡ç®— Agentï¼Œæ”¯æŒåœ¨æ‰§è¡Œå‰ä¿®æ”¹ç”¨æˆ·è¾“å…¥ï¼š

```
ç”¨æˆ·è¾“å…¥ "Multiply 2 and 3"
        â†“
    [æ–­ç‚¹] interrupt_before=["assistant"]
        â†“
   (æ£€æŸ¥çŠ¶æ€)
        â†“
   (ä¿®æ”¹çŠ¶æ€) update_state()
        â†“
   [assistant] æ‰§è¡Œä¿®æ­£åçš„è®¡ç®—
        â†“
    [tools] è°ƒç”¨å·¥å…·
        â†“
   [assistant] è¿”å›ç»“æœ
```

### ä»£ç å®ç°è¯¦è§£

#### 1. å®šä¹‰å·¥å…·å’Œæ¨¡å‹

```python
from langchain_openai import ChatOpenAI

def multiply(a: int, b: int) -> int:
    """Multiply a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b

def add(a: int, b: int) -> int:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a + b

def divide(a: int, b: int) -> float:
    """Divide a by b.

    Args:
        a: first int
        b: second int
    """
    return a / b

tools = [add, multiply, divide]
llm = ChatOpenAI(model="gpt-5-nano")
llm_with_tools = llm.bind_tools(tools)
```

**å…³é”®ç‚¹ï¼š**
- å®šä¹‰äº†ä¸‰ä¸ªæ•°å­¦å·¥å…·ï¼šåŠ æ³•ã€ä¹˜æ³•ã€é™¤æ³•
- æ¯ä¸ªå·¥å…·éƒ½æœ‰æ¸…æ™°çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆdocstringï¼‰ï¼ŒLLM ä¼šæ®æ­¤ç†è§£å·¥å…·ç”¨é€”
- `bind_tools()` å°†å·¥å…·ç»‘å®šåˆ° LLMï¼Œä½¿å…¶èƒ½å¤Ÿè°ƒç”¨è¿™äº›å·¥å…·

**Python çŸ¥è¯†ç‚¹ï¼šå‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆDocstringï¼‰**

```python
def multiply(a: int, b: int) -> int:
    """Multiply a and b.  # ç®€çŸ­æè¿°

    Args:                 # å‚æ•°è¯´æ˜
        a: first int
        b: second int
    """
    return a * b
```

è¿™ç§æ ¼å¼éµå¾ª Google Style æ–‡æ¡£è§„èŒƒï¼ŒLangChain ä¼šè‡ªåŠ¨è§£æå¹¶è½¬æ¢ä¸ºå·¥å…·æè¿°ï¼Œä¾› LLM ç†è§£ã€‚

#### 2. æ„å»ºå›¾

```python
from IPython.display import Image, display
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import MessagesState
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition, ToolNode
from langchain_core.messages import HumanMessage, SystemMessage

# ç³»ç»Ÿæ¶ˆæ¯
sys_msg = SystemMessage(content="You are a helpful assistant tasked with performing arithmetic on a set of inputs.")

# åŠ©æ‰‹èŠ‚ç‚¹
def assistant(state: MessagesState):
    return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}

# æ„å»ºå›¾
builder = StateGraph(MessagesState)

# å®šä¹‰èŠ‚ç‚¹
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

# å®šä¹‰è¾¹
builder.add_edge(START, "assistant")
builder.add_conditional_edges(
    "assistant",
    tools_condition,  # è‡ªåŠ¨åˆ¤æ–­ï¼šå·¥å…·è°ƒç”¨ â†’ toolsï¼Œå¦åˆ™ â†’ END
)
builder.add_edge("tools", "assistant")

# ç¼–è¯‘å›¾ï¼ˆå…³é”®ï¼šè®¾ç½®æ–­ç‚¹ï¼‰
memory = MemorySaver()
graph = builder.compile(
    interrupt_before=["assistant"],  # â­ åœ¨ assistant å‰æš‚åœ
    checkpointer=memory
)
```

**LangGraph çŸ¥è¯†ç‚¹ï¼šinterrupt_before**

```python
graph = builder.compile(interrupt_before=["assistant"], checkpointer=memory)
#                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
#                       åœ¨æŒ‡å®šèŠ‚ç‚¹å‰è®¾ç½®æ–­ç‚¹
```

- `interrupt_before=["assistant"]`ï¼šåœ¨æ‰§è¡Œ `assistant` èŠ‚ç‚¹å‰æš‚åœ
- `checkpointer=memory`ï¼šä¿å­˜æ‰§è¡ŒçŠ¶æ€ï¼Œæ”¯æŒæ¢å¤å’Œä¿®æ”¹
- æ–­ç‚¹ä¼šè®©å›¾åœåœ¨æŒ‡å®šèŠ‚ç‚¹ä¹‹å‰ï¼Œç­‰å¾…äººå·¥å¹²é¢„

**ä¸ºä»€ä¹ˆéœ€è¦ checkpointerï¼Ÿ**

Checkpointer æ˜¯çŠ¶æ€ç®¡ç†çš„æ ¸å¿ƒï¼š
```python
MemorySaver()  # å†…å­˜å­˜å‚¨ï¼ˆå¼€å‘/æµ‹è¯•ï¼‰
# ç”Ÿäº§ç¯å¢ƒå¯ç”¨ï¼š
# PostgresSaver()  # æ•°æ®åº“å­˜å‚¨
# RedisSaver()     # Redis å­˜å‚¨
```

æ²¡æœ‰ checkpointerï¼Œå›¾æ— æ³•æš‚åœå’Œæ¢å¤ï¼

#### 3. æ‰§è¡Œå¹¶è§¦å‘æ–­ç‚¹

```python
# è¾“å…¥
initial_input = {"messages": "Multiply 2 and 3"}

# çº¿ç¨‹é…ç½®ï¼ˆç”¨äºè¿½è¸ªä¼šè¯ï¼‰
thread = {"configurable": {"thread_id": "1"}}

# è¿è¡Œå›¾ç›´åˆ°ç¬¬ä¸€ä¸ªæ–­ç‚¹
for event in graph.stream(initial_input, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
```

**è¾“å‡ºï¼š**
```
================================ Human Message =================================
Multiply 2 and 3
```

**è§‚å¯Ÿï¼š**
- å›¾æ¥æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯
- åœ¨ `assistant` èŠ‚ç‚¹å‰æš‚åœï¼ˆå› ä¸º `interrupt_before=["assistant"]`ï¼‰
- AI è¿˜æœªæ‰§è¡Œï¼Œæˆ‘ä»¬å¯ä»¥å¹²é¢„

#### 4. æ£€æŸ¥çŠ¶æ€

```python
state = graph.get_state(thread)
state
```

**è¾“å‡ºï¼š**
```python
StateSnapshot(
    values={'messages': [HumanMessage(content='Multiply 2 and 3', id='e7edcaba-...')]},
    next=('assistant',),  # â­ ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„èŠ‚ç‚¹
    config={'configurable': {'thread_id': '1', ...}},
    ...
)
```

**LangGraph çŸ¥è¯†ç‚¹ï¼šStateSnapshot**

`StateSnapshot` æ˜¯å›¾åœ¨æŸä¸ªæ—¶é—´ç‚¹çš„å®Œæ•´å¿«ç…§ï¼š

| å­—æ®µ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `values` | å½“å‰çŠ¶æ€æ•°æ® | `{'messages': [...]}` |
| `next` | å¾…æ‰§è¡Œçš„èŠ‚ç‚¹ | `('assistant',)` |
| `config` | ä¼šè¯é…ç½® | `{'thread_id': '1'}` |
| `tasks` | å¾…æ‰§è¡Œä»»åŠ¡ | `(PregelTask(...),)` |

é€šè¿‡ `next`ï¼Œæˆ‘ä»¬çŸ¥é“æš‚åœåœ¨å“ªä¸ªèŠ‚ç‚¹å‰ã€‚

#### 5. ä¿®æ”¹çŠ¶æ€ â­

```python
graph.update_state(
    thread,
    {"messages": [HumanMessage(content="No, actually multiply 3 and 3!")]},
)
```

**å…³é”®æ¦‚å¿µï¼šReducer æœºåˆ¶**

`MessagesState` çš„ `messages` å­—æ®µä½¿ç”¨ `add_messages` reducerï¼š

```python
class MessagesState(TypedDict):
    messages: Annotated[list, add_messages]  # ä½¿ç”¨ add_messages reducer
```

**Reducer çš„è¡Œä¸ºï¼š**

1. **å¦‚æœæä¾›æ¶ˆæ¯ ID**ï¼šè¦†ç›–å·²æœ‰æ¶ˆæ¯
   ```python
   # å‡è®¾åŸæ¶ˆæ¯ id='abc'
   update_state({"messages": [HumanMessage(content="æ–°å†…å®¹", id='abc')]})
   # ç»“æœï¼šåŸæ¶ˆæ¯è¢«æ›¿æ¢
   ```

2. **å¦‚æœä¸æä¾›æ¶ˆæ¯ ID**ï¼šè¿½åŠ æ–°æ¶ˆæ¯
   ```python
   update_state({"messages": [HumanMessage(content="æ–°æ¶ˆæ¯")]})
   # ç»“æœï¼šæ–°æ¶ˆæ¯è¢«è¿½åŠ åˆ°åˆ—è¡¨æœ«å°¾
   ```

åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œ**æ²¡æœ‰æä¾› IDï¼Œæ‰€ä»¥æ˜¯è¿½åŠ æ–°æ¶ˆæ¯**ã€‚

#### 6. éªŒè¯çŠ¶æ€ä¿®æ”¹

```python
new_state = graph.get_state(thread).values
for m in new_state['messages']:
    m.pretty_print()
```

**è¾“å‡ºï¼š**
```
================================ Human Message =================================
Multiply 2 and 3

================================ Human Message =================================
No, actually multiply 3 and 3!
```

**è§‚å¯Ÿï¼š**
- åŸå§‹æ¶ˆæ¯ä¿ç•™
- æ–°æ¶ˆæ¯è¢«è¿½åŠ 
- AI å°†çœ‹åˆ°ä¸¤æ¡æ¶ˆæ¯çš„ä¸Šä¸‹æ–‡

#### 7. ç»§ç»­æ‰§è¡Œ

```python
for event in graph.stream(None, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
```

**é‡è¦ï¼šä¼ é€’ `None` è¡¨ç¤ºä»å½“å‰çŠ¶æ€ç»§ç»­**

**è¾“å‡ºï¼š**
```
================================ Human Message =================================
No, actually multiply 3 and 3!

================================== Ai Message ==================================
Tool Calls:
  multiply (call_Mbu8...)
  Args:
    a: 3
    b: 3

================================= Tool Message =================================
Name: multiply
9
```

**æµç¨‹åˆ†æï¼š**
1. ä»æ–­ç‚¹æ¢å¤ï¼ŒAI çœ‹åˆ°ä¿®æ”¹åçš„æ¶ˆæ¯
2. AI ç†è§£ä¸ºè®¡ç®— 3 Ã— 3
3. è°ƒç”¨ `multiply` å·¥å…·
4. å¾—åˆ°ç»“æœ 9

#### 8. å†æ¬¡ç»§ç»­ï¼ˆå¤„ç†å·¥å…·è¿”å›ï¼‰

```python
for event in graph.stream(None, thread, stream_mode="values"):
    event['messages'][-1].pretty_print()
```

**è¾“å‡ºï¼š**
```
================================= Tool Message =================================
Name: multiply
9

================================== Ai Message ==================================
3 multiplied by 3 equals 9.
```

**æ³¨æ„ï¼š** å› ä¸ºè®¾ç½®äº† `interrupt_before=["assistant"]`ï¼Œæ‰€ä»¥åœ¨ assistant èŠ‚ç‚¹å‰åˆæš‚åœäº†ä¸€æ¬¡ã€‚éœ€è¦å†è°ƒç”¨ `stream(None, ...)` æ‰èƒ½å¾—åˆ°æœ€ç»ˆå›å¤ã€‚

---

## ğŸ­ å®æˆ˜æ¡ˆä¾‹ 2ï¼šä½¿ç”¨ LangGraph Studio

### Studio ç®€ä»‹

**LangGraph Studio** æ˜¯å¯è§†åŒ–å¼€å‘å·¥å…·ï¼Œå¯ä»¥ï¼š
- å¯è§†åŒ–å›¾ç»“æ„
- äº¤äº’å¼è°ƒè¯•
- å®æ—¶ä¿®æ”¹çŠ¶æ€
- æŸ¥çœ‹æ‰§è¡Œå†å²

### æœ¬åœ°è¿è¡Œ Studio

```bash
cd /path/to/module-3/studio
langgraph dev
```

**è¾“å‡ºï¼š**
```
ğŸš€ API: http://127.0.0.1:2024
ğŸ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
ğŸ“š API Docs: http://127.0.0.1:2024/docs
```

æ‰“å¼€æµè§ˆå™¨è®¿é—® Studio UI å³å¯ä½¿ç”¨å¯è§†åŒ–ç•Œé¢ã€‚

### ä½¿ç”¨ LangGraph SDK

Studio æä¾›äº† HTTP APIï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ SDK ç¼–ç¨‹è°ƒç”¨ï¼š

#### 1. è¿æ¥åˆ° Studio

```python
from langgraph_sdk import get_client

client = get_client(url="http://127.0.0.1:2024")
```

#### 2. åˆ›å»ºçº¿ç¨‹å¹¶è¿è¡Œï¼ˆå¸¦æ–­ç‚¹ï¼‰

```python
initial_input = {"messages": "Multiply 2 and 3"}
thread = await client.threads.create()

async for chunk in client.runs.stream(
    thread["thread_id"],
    "agent",  # agent åç§°ï¼ˆå®šä¹‰åœ¨ studio/agent.pyï¼‰
    input=initial_input,
    stream_mode="values",
    interrupt_before=["assistant"],  # â­ SDK æ”¯æŒåŠ¨æ€è®¾ç½®æ–­ç‚¹
):
    print(f"Receiving new event of type: {chunk.event}...")
    messages = chunk.data.get('messages', [])
    if messages:
        print(messages[-1])
```

**é‡è¦å‘ç°ï¼š** å³ä½¿ `studio/agent.py` ä¸­æ²¡æœ‰å®šä¹‰æ–­ç‚¹ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ API åŠ¨æ€æ³¨å…¥ï¼

**è¾“å‡ºï¼š**
```
Receiving new event of type: metadata...
--------------------------------------------------
Receiving new event of type: values...
{'content': 'Multiply 2 and 3', 'type': 'human', 'id': '...'}
--------------------------------------------------
```

#### 3. è·å–å½“å‰çŠ¶æ€

```python
current_state = await client.threads.get_state(thread['thread_id'])
current_state
```

**è¾“å‡ºï¼š**
```python
{
    'values': {
        'messages': [{'content': 'Multiply 2 and 3', 'type': 'human', ...}]
    },
    'next': ['assistant'],  # ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    'tasks': [...],
    'metadata': {...},
    ...
}
```

#### 4. æå–å¹¶ç¼–è¾‘æ¶ˆæ¯

```python
# è·å–æœ€åä¸€æ¡æ¶ˆæ¯
last_message = current_state['values']['messages'][-1]
last_message
```

**è¾“å‡ºï¼š**
```python
{
    'content': 'Multiply 2 and 3',
    'type': 'human',
    'id': '882dabe4-...',
    ...
}
```

**ä¿®æ”¹æ¶ˆæ¯å†…å®¹ï¼š**
```python
last_message['content'] = "No, actually multiply 3 and 3!"
```

**Python çŸ¥è¯†ç‚¹ï¼šå­—å…¸ä¿®æ”¹**

```python
# å­—å…¸æ˜¯å¯å˜å¯¹è±¡ï¼Œç›´æ¥ä¿®æ”¹ä¼šå½±å“åŸæ•°æ®
msg = {'content': 'old'}
msg['content'] = 'new'
print(msg)  # {'content': 'new'}
```

#### 5. æ›´æ–°çŠ¶æ€åˆ°æœåŠ¡å™¨

```python
await client.threads.update_state(
    thread['thread_id'],
    {"messages": last_message}
)
```

**å…³é”®ï¼š** å› ä¸ºæˆ‘ä»¬ä¿ç•™äº†æ¶ˆæ¯çš„ `id`ï¼Œæ‰€ä»¥ `add_messages` reducer ä¼š**è¦†ç›–**åŸæ¶ˆæ¯ï¼Œè€Œéè¿½åŠ ã€‚

#### 6. æ¢å¤æ‰§è¡Œ

```python
async for chunk in client.runs.stream(
    thread["thread_id"],
    assistant_id="agent",
    input=None,  # â­ ä¼ é€’ None è¡¨ç¤ºä»å½“å‰çŠ¶æ€ç»§ç»­
    stream_mode="values",
    interrupt_before=["assistant"],
):
    print(f"Receiving new event of type: {chunk.event}...")
    messages = chunk.data.get('messages', [])
    if messages:
        print(messages[-1])
```

**è¾“å‡ºï¼š**
```
Receiving new event of type: values...
{'content': 'No, actually multiply 3 and 3!', 'type': 'human', ...}
--------------------------------------------------
Receiving new event of type: values...
{'content': '', 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 3}, ...}], ...}
--------------------------------------------------
Receiving new event of type: values...
{'content': '9', 'type': 'tool', 'name': 'multiply', ...}
--------------------------------------------------
```

#### 7. æœ€ç»ˆç»“æœ

```python
async for chunk in client.runs.stream(
    thread["thread_id"],
    assistant_id="agent",
    input=None,
    stream_mode="values",
    interrupt_before=["assistant"],
):
    ...
```

**è¾“å‡ºï¼š**
```
{'content': 'The result of multiplying 3 by 3 is 9.', 'type': 'ai', ...}
```

---

## ğŸš€ å®æˆ˜æ¡ˆä¾‹ 3ï¼šç­‰å¾…ç”¨æˆ·è¾“å…¥èŠ‚ç‚¹

### è®¾è®¡æ¨¡å¼ï¼šHuman Feedback Node

å‰é¢æˆ‘ä»¬æ˜¯åœ¨æ–­ç‚¹åæ‰‹åŠ¨è°ƒç”¨ `update_state`ï¼Œç°åœ¨æˆ‘ä»¬è®¾è®¡ä¸€ä¸ª**ä¸“é—¨çš„èŠ‚ç‚¹**æ¥æ¥æ”¶äººç±»åé¦ˆã€‚

### ç³»ç»Ÿæ¶æ„

```
START
  â†“
[human_feedback] <â”€â”  (æ–­ç‚¹ï¼šç­‰å¾…äººå·¥è¾“å…¥)
  â†“                â”‚
[assistant]        â”‚
  â†“                â”‚
[tools]  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ ¸å¿ƒæ€è·¯ï¼š**
1. `human_feedback` æ˜¯ä¸€ä¸ª"ç©ºèŠ‚ç‚¹"ï¼ˆno-opï¼‰ï¼Œä»…ä½œä¸ºæ–­ç‚¹
2. åœ¨æ­¤èŠ‚ç‚¹å‰æš‚åœï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥
3. ä½¿ç”¨ `update_state(..., as_node="human_feedback")` æ³¨å…¥åé¦ˆ
4. ç»§ç»­æ‰§è¡Œ

### ä»£ç å®ç°

#### 1. å®šä¹‰èŠ‚ç‚¹

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import MessagesState, START, StateGraph
from langgraph.prebuilt import tools_condition, ToolNode
from langgraph.checkpoint.memory import MemorySaver

sys_msg = SystemMessage(content="You are a helpful assistant tasked with performing arithmetic on a set of inputs.")

# â­ äººå·¥åé¦ˆèŠ‚ç‚¹ï¼ˆç©ºæ“ä½œï¼‰
def human_feedback(state: MessagesState):
    pass

# åŠ©æ‰‹èŠ‚ç‚¹
def assistant(state: MessagesState):
    return {"messages": [llm_with_tools.invoke([sys_msg] + state["messages"])]}
```

**é‡è¦ï¼š** `human_feedback` èŠ‚ç‚¹ä»€ä¹ˆéƒ½ä¸åšï¼Œä»…ä½œä¸ºæš‚åœç‚¹ã€‚

#### 2. æ„å»ºå›¾

```python
builder = StateGraph(MessagesState)

# æ·»åŠ èŠ‚ç‚¹
builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))
builder.add_node("human_feedback", human_feedback)

# å®šä¹‰è¾¹
builder.add_edge(START, "human_feedback")
builder.add_edge("human_feedback", "assistant")
builder.add_conditional_edges("assistant", tools_condition)
builder.add_edge("tools", "human_feedback")  # â­ å·¥å…·æ‰§è¡Œåå›åˆ°åé¦ˆèŠ‚ç‚¹

# ç¼–è¯‘
memory = MemorySaver()
graph = builder.compile(
    interrupt_before=["human_feedback"],  # åœ¨ human_feedback å‰æš‚åœ
    checkpointer=memory
)
```

**å›¾çš„æ‰§è¡Œæµç¨‹ï¼š**
```
1. START â†’ human_feedback [æš‚åœ]
2. (äººå·¥è¾“å…¥) â†’ assistant
3. assistant â†’ tools (å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·)
4. tools â†’ human_feedback [æš‚åœ]
5. (äººå·¥ç¡®è®¤) â†’ assistant
6. assistant â†’ END
```

#### 3. äº¤äº’å¼æ‰§è¡Œ

```python
initial_input = {"messages": "Multiply 2 and 3"}
thread = {"configurable": {"thread_id": "5"}}

# è¿è¡Œåˆ°ç¬¬ä¸€ä¸ªæ–­ç‚¹
for event in graph.stream(initial_input, thread, stream_mode="values"):
    event["messages"][-1].pretty_print()

# è·å–ç”¨æˆ·è¾“å…¥
user_input = input("Tell me how you want to update the state: ")

# â­ ä½œä¸º human_feedback èŠ‚ç‚¹æ›´æ–°çŠ¶æ€
graph.update_state(
    thread,
    {"messages": user_input},
    as_node="human_feedback"  # å…³é”®å‚æ•°
)

# ç»§ç»­æ‰§è¡Œ
for event in graph.stream(None, thread, stream_mode="values"):
    event["messages"][-1].pretty_print()
```

**LangGraph çŸ¥è¯†ç‚¹ï¼šas_node å‚æ•°**

```python
graph.update_state(
    thread,
    {"messages": user_input},
    as_node="human_feedback"  # â­ æ¨¡æ‹Ÿè¯¥èŠ‚ç‚¹çš„è¾“å‡º
)
```

**ä½œç”¨ï¼š**
- å°†çŠ¶æ€æ›´æ–°è§†ä¸ºæ¥è‡ª `human_feedback` èŠ‚ç‚¹çš„è¾“å‡º
- å›¾ä¼šè®¤ä¸º `human_feedback` èŠ‚ç‚¹å·²æ‰§è¡Œå®Œæ¯•
- è‡ªåŠ¨æµå‘ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆ`assistant`ï¼‰

**å¦‚æœä¸æŒ‡å®š `as_node`ï¼š**
- çŠ¶æ€ä¼šè¢«æ›´æ–°ï¼Œä½†å›¾ä¸çŸ¥é“ä»å“ªä¸ªèŠ‚ç‚¹ç»§ç»­
- éœ€è¦æ‰‹åŠ¨ç®¡ç†æ‰§è¡Œæµç¨‹

#### 4. æ‰§è¡Œç»“æœ

**ç”¨æˆ·è¾“å…¥ï¼š** `no, multiply 3 and 3`

**è¾“å‡ºï¼š**
```
================================ Human Message =================================
Multiply 2 and 3

[æš‚åœï¼Œç­‰å¾…è¾“å…¥]

================================ Human Message =================================
no, multiply 3 and 3

================================== Ai Message ==================================
Tool Calls:
  multiply (call_...)
  Args:
    a: 3
    b: 3

================================= Tool Message =================================
Name: multiply
9
```

**å†æ¬¡ç»§ç»­ï¼š**
```python
for event in graph.stream(None, thread, stream_mode="values"):
    event["messages"][-1].pretty_print()
```

**è¾“å‡ºï¼š**
```
================================= Tool Message =================================
Name: multiply
9

================================== Ai Message ==================================
The result of multiplying 3 and 3 is 9.
```

---

## ğŸ“ æ ¸å¿ƒçŸ¥è¯†ç‚¹æ€»ç»“

### LangGraph ç‰¹æœ‰æ¦‚å¿µ

#### 1. æ–­ç‚¹æœºåˆ¶ï¼ˆInterruptï¼‰

| å‚æ•° | è¯´æ˜ | ç”¨é€” |
|------|------|------|
| `interrupt_before=["node"]` | åœ¨èŠ‚ç‚¹æ‰§è¡Œå‰æš‚åœ | äººå·¥å®¡æ‰¹ã€çŠ¶æ€æ£€æŸ¥ |
| `interrupt_after=["node"]` | åœ¨èŠ‚ç‚¹æ‰§è¡Œåæš‚åœ | éªŒè¯ç»“æœã€è°ƒè¯• |

```python
graph = builder.compile(
    interrupt_before=["assistant"],  # æ‰§è¡Œå‰æš‚åœ
    checkpointer=memory
)
```

#### 2. çŠ¶æ€ç®¡ç† API

| æ–¹æ³• | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `get_state(config)` | è·å–å½“å‰çŠ¶æ€ | `state = graph.get_state(thread)` |
| `update_state(config, values)` | æ›´æ–°çŠ¶æ€ | `graph.update_state(thread, {"messages": msg})` |
| `update_state(..., as_node="node")` | ä½œä¸ºæŒ‡å®šèŠ‚ç‚¹æ›´æ–° | `graph.update_state(thread, data, as_node="human")` |

#### 3. Reducer æœºåˆ¶

`add_messages` reducer çš„è¡Œä¸ºï¼š

```python
from langgraph.graph import MessagesState

# MessagesState å†…éƒ¨å®šä¹‰ï¼š
class MessagesState(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
```

**è¡Œä¸ºè§„åˆ™ï¼š**

| åœºæ™¯ | ç¤ºä¾‹ | ç»“æœ |
|------|------|------|
| æ–°æ¶ˆæ¯ï¼ˆæ—  IDï¼‰ | `update({"messages": [HumanMessage("Hi")]})` | è¿½åŠ åˆ°åˆ—è¡¨æœ«å°¾ |
| è¦†ç›–æ¶ˆæ¯ï¼ˆæœ‰ IDï¼‰ | `update({"messages": [HumanMessage("Hi", id="123")]})` | æ›¿æ¢ ID ä¸º "123" çš„æ¶ˆæ¯ |
| åˆ é™¤æ¶ˆæ¯ | `update({"messages": [RemoveMessage(id="123")]})` | åˆ é™¤æŒ‡å®šæ¶ˆæ¯ |

#### 4. ä¼šè¯ç®¡ç†ï¼ˆThreadï¼‰

```python
thread = {"configurable": {"thread_id": "1"}}
```

**Thread çš„ä½œç”¨ï¼š**
- éš”ç¦»ä¸åŒç”¨æˆ·/ä¼šè¯çš„çŠ¶æ€
- æ”¯æŒå¤šè½®å¯¹è¯
- è¿½è¸ªæ‰§è¡Œå†å²

**ç±»æ¯”ç†è§£ï¼š**
```python
# ç±»ä¼¼äºæ•°æ®åº“çš„ä¼šè¯ ID
user_1 = {"configurable": {"thread_id": "user_1"}}
user_2 = {"configurable": {"thread_id": "user_2"}}

# ä¸¤ä¸ªç”¨æˆ·çš„çŠ¶æ€å®Œå…¨éš”ç¦»
graph.stream(input1, user_1)  # ç”¨æˆ· 1 çš„ä¼šè¯
graph.stream(input2, user_2)  # ç”¨æˆ· 2 çš„ä¼šè¯
```

#### 5. Checkpointer æŒä¹…åŒ–

| ç±»å‹ | é€‚ç”¨åœºæ™¯ | æŒä¹…åŒ– |
|------|----------|--------|
| `MemorySaver()` | å¼€å‘ã€æµ‹è¯• | ä»…å†…å­˜ï¼Œé‡å¯ä¸¢å¤± |
| `SqliteSaver()` | æœ¬åœ°åº”ç”¨ | æ–‡ä»¶å­˜å‚¨ |
| `PostgresSaver()` | ç”Ÿäº§ç¯å¢ƒ | æ•°æ®åº“ |
| `RedisSaver()` | é«˜æ€§èƒ½åœºæ™¯ | Redis |

```python
from langgraph.checkpoint.postgres import PostgresSaver

# ç”Ÿäº§ç¯å¢ƒç¤ºä¾‹
checkpointer = PostgresSaver(connection_string="postgresql://...")
graph = builder.compile(checkpointer=checkpointer)
```

---

### Python ç‰¹æœ‰çŸ¥è¯†ç‚¹

#### 1. TypedDict vs Pydantic BaseModel

| ç‰¹æ€§ | TypedDict | BaseModel |
|------|-----------|-----------|
| ç±»å‹æ£€æŸ¥ | é™æ€ï¼ˆIDEï¼‰ | è¿è¡Œæ—¶ |
| æ•°æ®éªŒè¯ | æ—  | æœ‰ |
| æ€§èƒ½ | å¿« | ç¨æ…¢ |
| ç”¨é€” | çŠ¶æ€å®šä¹‰ | æ•°æ®æ¨¡å‹ |

```python
from typing_extensions import TypedDict
from pydantic import BaseModel

# TypedDict - ç”¨äºå›¾çŠ¶æ€
class MyState(TypedDict):
    messages: list
    count: int

# BaseModel - ç”¨äºç»“æ„åŒ–è¾“å‡º
class Response(BaseModel):
    answer: str
    confidence: float
```

#### 2. å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆDocstringï¼‰

```python
def multiply(a: int, b: int) -> int:
    """Multiply a and b.

    Args:
        a: first integer
        b: second integer

    Returns:
        The product of a and b

    Examples:
        >>> multiply(2, 3)
        6
    """
    return a * b
```

**æœ€ä½³å®è·µï¼š**
- ç¬¬ä¸€è¡Œï¼šç®€çŸ­åŠŸèƒ½æè¿°
- `Args`ï¼šå‚æ•°è¯´æ˜
- `Returns`ï¼šè¿”å›å€¼è¯´æ˜
- `Examples`ï¼šä½¿ç”¨ç¤ºä¾‹ï¼ˆå¯é€‰ï¼‰

#### 3. ç±»å‹æ³¨è§£ï¼ˆType Hintsï¼‰

```python
from typing import Annotated
from langgraph.graph import MessagesState

def assistant(state: MessagesState) -> dict:
    #             ^^^^^^^^^^^^^^     ^^^^
    #             è¾“å…¥ç±»å‹             è¾“å‡ºç±»å‹
    return {"messages": [...]}
```

**ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ**
- IDE è‡ªåŠ¨è¡¥å…¨
- é™æ€ç±»å‹æ£€æŸ¥ï¼ˆmypyï¼‰
- ä»£ç å¯è¯»æ€§

#### 4. async/await å¼‚æ­¥ç¼–ç¨‹

LangGraph SDK ä½¿ç”¨å¼‚æ­¥ APIï¼š

```python
# å¼‚æ­¥å‡½æ•°å®šä¹‰
async def main():
    # ç­‰å¾…å¼‚æ­¥æ“ä½œ
    state = await client.threads.get_state(thread_id)

    # å¼‚æ­¥è¿­ä»£
    async for chunk in client.runs.stream(...):
        print(chunk)

# è¿è¡Œå¼‚æ­¥å‡½æ•°
import asyncio
asyncio.run(main())
```

**åœ¨ Jupyter ä¸­ï¼š**
```python
# ç›´æ¥ä½¿ç”¨ awaitï¼ˆJupyter è‡ªåŠ¨å¤„ç†ï¼‰
state = await client.threads.get_state(thread_id)
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ä½•æ—¶ä½¿ç”¨çŠ¶æ€ç¼–è¾‘ï¼Ÿ

âœ… **é€‚ç”¨åœºæ™¯ï¼š**
- **çº æ­£ AI è¯¯è§£**ï¼šç”¨æˆ·è¡¨è¾¾ä¸æ¸…ï¼Œéœ€è¦äººå·¥æ¾„æ¸…
- **æ³¨å…¥é¢†åŸŸçŸ¥è¯†**ï¼šAI ç¼ºä¹ä¸“ä¸šçŸ¥è¯†ï¼Œä¸“å®¶æä¾›æŒ‡å¯¼
- **åŠ¨æ€è°ƒæ•´ç­–ç•¥**ï¼šæ ¹æ®ä¸­é—´ç»“æœè°ƒæ•´æ‰§è¡Œè®¡åˆ’
- **é”™è¯¯æ¢å¤**ï¼šAI å‡ºé”™ï¼Œäººå·¥ä¿®æ­£çŠ¶æ€åé‡è¯•

âŒ **ä¸é€‚ç”¨åœºæ™¯ï¼š**
- ç®€å•çš„å‚æ•°éªŒè¯ï¼ˆåº”åœ¨è¾“å…¥å‰å¤„ç†ï¼‰
- é¢‘ç¹çš„ç”¨æˆ·äº¤äº’ï¼ˆè€ƒè™‘é‡æ–°è®¾è®¡æµç¨‹ï¼‰
- è‡ªåŠ¨åŒ–æµç¨‹ï¼ˆç ´åè‡ªåŠ¨åŒ–ç‰¹æ€§ï¼‰

### 2. æ–­ç‚¹è®¾ç½®ç­–ç•¥

#### ç­–ç•¥ 1ï¼šå…³é”®å†³ç­–ç‚¹

```python
# åœ¨ AI åšé‡è¦å†³ç­–å‰æš‚åœ
interrupt_before=["delete_data", "send_email", "make_payment"]
```

#### ç­–ç•¥ 2ï¼šåˆ†é˜¶æ®µå®¡æ‰¹

```python
# å¤šä¸ªæ£€æŸ¥ç‚¹
interrupt_before=["plan", "execute", "finalize"]
```

#### ç­–ç•¥ 3ï¼šåŠ¨æ€æ–­ç‚¹ï¼ˆStudio APIï¼‰

```python
# æ ¹æ®è¿è¡Œæ—¶æ¡ä»¶è®¾ç½®æ–­ç‚¹
if is_production:
    interrupt_before = ["risky_operation"]
else:
    interrupt_before = []

client.runs.stream(..., interrupt_before=interrupt_before)
```

### 3. çŠ¶æ€æ›´æ–°æ¨¡å¼

#### æ¨¡å¼ 1ï¼šè¿½åŠ åé¦ˆ

```python
# ä¸æä¾› IDï¼Œè¿½åŠ æ–°æ¶ˆæ¯
graph.update_state(
    thread,
    {"messages": [HumanMessage("Additional info: ...")]},
    as_node="human_feedback"
)
```

#### æ¨¡å¼ 2ï¼šä¿®æ­£æ¶ˆæ¯

```python
# æä¾› IDï¼Œè¦†ç›–åŸæ¶ˆæ¯
state = graph.get_state(thread)
last_msg = state.values['messages'][-1]
last_msg['content'] = "Corrected message"

graph.update_state(
    thread,
    {"messages": [last_msg]},  # ä¿ç•™ ID
    as_node="human_feedback"
)
```

#### æ¨¡å¼ 3ï¼šéƒ¨åˆ†çŠ¶æ€æ›´æ–°

```python
# åªæ›´æ–°ç‰¹å®šå­—æ®µ
graph.update_state(
    thread,
    {"retry_count": 0, "error": None},  # ä¸å½±å“ messages
    as_node="error_handler"
)
```

### 4. ç”¨æˆ·ä½“éªŒè®¾è®¡

#### åŸåˆ™ 1ï¼šæ¸…æ™°çš„æš‚åœæç¤º

```python
print("â¸ AI is paused. Current plan:")
print(f"  - {state.values['planned_action']}")
user_input = input("Approve? (yes/no/edit): ")
```

#### åŸåˆ™ 2ï¼šæä¾›ä¸Šä¸‹æ–‡

```python
# å±•ç¤ºå®Œæ•´ä¸Šä¸‹æ–‡ï¼Œå¸®åŠ©ç”¨æˆ·å†³ç­–
for msg in state.values['messages']:
    print(f"{msg.type}: {msg.content}")
```

#### åŸåˆ™ 3ï¼šæ”¯æŒå¤šç§æ“ä½œ

```python
choice = input("Choose: (1) Approve (2) Edit (3) Cancel (4) Restart: ")

if choice == "1":
    graph.stream(None, thread)  # ç»§ç»­
elif choice == "2":
    new_input = input("Enter correction: ")
    graph.update_state(thread, {"messages": new_input})
    graph.stream(None, thread)
elif choice == "3":
    # å–æ¶ˆæ‰§è¡Œ
    pass
elif choice == "4":
    # é‡æ–°å¼€å§‹ï¼ˆæ–°çº¿ç¨‹ï¼‰
    thread = {"configurable": {"thread_id": str(uuid.uuid4())}}
```

### 5. é”™è¯¯å¤„ç†

#### æŠ€å·§ 1ï¼šéªŒè¯çŠ¶æ€æ›´æ–°

```python
try:
    graph.update_state(thread, {"messages": user_input})
    print("âœ… State updated successfully")
except Exception as e:
    print(f"âŒ Failed to update state: {e}")
```

#### æŠ€å·§ 2ï¼šçŠ¶æ€å›æ»š

```python
# ä¿å­˜åŸå§‹çŠ¶æ€
original_state = graph.get_state(thread)

try:
    graph.update_state(thread, new_data)
    result = graph.stream(None, thread)
except Exception as e:
    # æ¢å¤åŸçŠ¶æ€
    graph.update_state(thread, original_state.values)
    print(f"Rolled back due to error: {e}")
```

#### æŠ€å·§ 3ï¼šè¶…æ—¶å¤„ç†

```python
import asyncio

async def run_with_timeout():
    try:
        # ç­‰å¾…ç”¨æˆ·è¾“å…¥ï¼Œæœ€å¤š 60 ç§’
        user_input = await asyncio.wait_for(
            get_user_input_async(),
            timeout=60.0
        )
        graph.update_state(thread, {"messages": user_input})
    except asyncio.TimeoutError:
        # è¶…æ—¶ï¼Œä½¿ç”¨é»˜è®¤å€¼
        graph.update_state(thread, {"messages": "timeout - using default"})
```

---

## ğŸš€ è¿›é˜¶æŠ€å·§

### 1. å¤šè½®åé¦ˆå¾ªç¯

```python
# å…è®¸ç”¨æˆ·å¤šæ¬¡ä¿®æ­£
max_iterations = 3
for i in range(max_iterations):
    # æ‰§è¡Œåˆ°æ–­ç‚¹
    for event in graph.stream(None, thread, stream_mode="values"):
        print(event)

    # ç”¨æˆ·ç¡®è®¤
    satisfied = input("Satisfied? (yes/no): ")
    if satisfied == "yes":
        break

    # ä¿®æ­£
    correction = input("Enter correction: ")
    graph.update_state(thread, {"messages": correction}, as_node="human_feedback")
```

### 2. æ¡ä»¶æ–­ç‚¹

```python
def conditional_interrupt(state: MessagesState):
    # åªåœ¨ç‰¹å®šæ¡ä»¶ä¸‹æš‚åœ
    if state.get("confidence", 1.0) < 0.7:
        # ä½ç½®ä¿¡åº¦ï¼Œéœ€è¦äººå·¥ç¡®è®¤
        return "human_feedback"
    else:
        # é«˜ç½®ä¿¡åº¦ï¼Œç›´æ¥æ‰§è¡Œ
        return "execute"

builder.add_conditional_edges("assistant", conditional_interrupt)
```

### 3. åä½œå¼çŠ¶æ€ç¼–è¾‘

```python
# å¤šä¸ªä¸“å®¶åŒæ—¶æä¾›åé¦ˆ
state = graph.get_state(thread)

expert_1_feedback = "Consider approach A because..."
expert_2_feedback = "I suggest approach B because..."

# åˆå¹¶åé¦ˆ
combined_feedback = f"""
Expert 1: {expert_1_feedback}
Expert 2: {expert_2_feedback}
"""

graph.update_state(
    thread,
    {"messages": [HumanMessage(combined_feedback)]},
    as_node="expert_review"
)
```

### 4. ç‰ˆæœ¬æ§åˆ¶å’Œå®¡è®¡

```python
import json
from datetime import datetime

# è®°å½•æ¯æ¬¡çŠ¶æ€ä¿®æ”¹
def update_with_audit(thread, new_state, as_node=None):
    # è·å–ä¿®æ”¹å‰çŠ¶æ€
    before = graph.get_state(thread)

    # æ‰§è¡Œæ›´æ–°
    result = graph.update_state(thread, new_state, as_node=as_node)

    # è·å–ä¿®æ”¹åçŠ¶æ€
    after = graph.get_state(thread)

    # è®°å½•å®¡è®¡æ—¥å¿—
    audit_log = {
        "timestamp": datetime.now().isoformat(),
        "before": before.values,
        "after": after.values,
        "changes": new_state,
        "node": as_node
    }

    with open("audit.jsonl", "a") as f:
        f.write(json.dumps(audit_log) + "\n")

    return result
```

---

## ğŸ“Š çŠ¶æ€ç¼–è¾‘ vs å…¶ä»–æ¨¡å¼

### å¯¹æ¯”ï¼šä¸‰ç§äººæœºåä½œæ¨¡å¼

| ç‰¹æ€§ | å®¡æ‰¹æ¨¡å¼ | è°ƒè¯•æ¨¡å¼ | ç¼–è¾‘æ¨¡å¼ |
|------|---------|---------|---------|
| ä¸»è¦ç”¨é€” | ç¡®è®¤ AI æ“ä½œ | é‡ç°/é¿å…é”™è¯¯ | ä¿®æ­£/å¼•å¯¼ AI |
| çŠ¶æ€ä¿®æ”¹ | æ—  | å›æ»šåˆ°å†å²çŠ¶æ€ | ç›´æ¥ä¿®æ”¹å½“å‰çŠ¶æ€ |
| äº¤äº’æ—¶æœº | æ“ä½œå‰ | é”™è¯¯å | ä»»æ„æ—¶åˆ» |
| æŠ€æœ¯å®ç° | æ–­ç‚¹ | å†å²å›æº¯ | update_state |
| é€‚ç”¨åœºæ™¯ | é«˜é£é™©æ“ä½œ | æ•…éšœæ’æŸ¥ | åŠ¨æ€è°ƒæ•´ |

### ç¤ºä¾‹å¯¹æ¯”

#### å®¡æ‰¹æ¨¡å¼
```python
# ä»…ç¡®è®¤ï¼Œä¸ä¿®æ”¹
for event in graph.stream(input, thread):
    print(event)

confirm = input("Approve? (yes/no): ")
if confirm == "yes":
    graph.stream(None, thread)  # ç»§ç»­æ‰§è¡Œ
else:
    # å–æ¶ˆ
    pass
```

#### è°ƒè¯•æ¨¡å¼
```python
# å›åˆ°ä¹‹å‰çš„æ£€æŸ¥ç‚¹
history = graph.get_state_history(thread)
for state in history:
    print(state.config['checkpoint_id'])

# å›æ»šåˆ°ç‰¹å®šæ£€æŸ¥ç‚¹
graph.update_state(history[2].config, history[2].values)
```

#### ç¼–è¾‘æ¨¡å¼ï¼ˆæœ¬è¯¾é‡ç‚¹ï¼‰
```python
# ç›´æ¥ä¿®æ”¹çŠ¶æ€
state = graph.get_state(thread)
state.values['messages'][-1].content = "Modified"
graph.update_state(thread, state.values)
```

---

## ğŸ¯ å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹ 1ï¼šå®¢æœ Agent è¯¯è§£ä¿®æ­£

```python
# ç”¨æˆ·ï¼š"æˆ‘è¦é€€è´§"
# AI ç†è§£ï¼š"ç”¨æˆ·è¦æŸ¥è¯¢é€€è´§æ”¿ç­–"

# æš‚åœåœ¨ assistant å‰
state = graph.get_state(thread)
print(f"AI ç†è§£ï¼š{state.values['intent']}")

# å®¢æœä¿®æ­£
graph.update_state(
    thread,
    {"intent": "process_return", "clarification": "ç”¨æˆ·è¦åŠç†é€€è´§ï¼ŒéæŸ¥è¯¢"},
    as_node="human_supervisor"
)

# ç»§ç»­å¤„ç†
graph.stream(None, thread)
```

### æ¡ˆä¾‹ 2ï¼šç ”ç©¶ Agent æ–¹å‘è°ƒæ•´

```python
# AI è§„åˆ’ï¼šè°ƒç ” 10 ä¸ªæŠ€æœ¯æ–¹å‘
# ä¸“å®¶ï¼š"åªéœ€è¦å…³æ³¨ LLM å’Œ RAG"

state = graph.get_state(thread)
original_topics = state.values['research_topics']
print(f"åŸè®¡åˆ’ï¼š{original_topics}")

# ç²¾ç®€è®¡åˆ’
graph.update_state(
    thread,
    {"research_topics": ["LLM", "RAG"]},
    as_node="expert_review"
)

# æ‰§è¡Œç²¾ç®€åçš„è®¡åˆ’
graph.stream(None, thread)
```

### æ¡ˆä¾‹ 3ï¼šä»£ç ç”Ÿæˆ Agent éœ€æ±‚æ¾„æ¸…

```python
# ç”¨æˆ·ï¼š"å†™ä¸€ä¸ªæ’åºå‡½æ•°"
# AIï¼š"å‡†å¤‡å†™å¿«é€Ÿæ’åº..."

# æš‚åœï¼Œè®©ç”¨æˆ·æ˜ç¡®éœ€æ±‚
state = graph.get_state(thread)

clarification = input("éœ€è¦å“ªç§æ’åºç®—æ³•ï¼Ÿ(bubble/quick/merge): ")
performance = input("æ•°æ®è§„æ¨¡ï¼Ÿ(small/large): ")

# æ³¨å…¥æ¾„æ¸…ä¿¡æ¯
graph.update_state(
    thread,
    {
        "messages": [HumanMessage(f"Use {clarification} sort for {performance} dataset")],
        "algorithm": clarification,
        "scale": performance
    },
    as_node="requirement_clarification"
)

graph.stream(None, thread)
```

---

## ğŸ” å¸¸è§é—®é¢˜

### Q1: update_state åéœ€è¦è°ƒç”¨ stream(None) å—ï¼Ÿ

**éœ€è¦ï¼** `update_state` åªä¿®æ”¹çŠ¶æ€ï¼Œä¸æ¨è¿›æ‰§è¡Œã€‚å¿…é¡»è°ƒç”¨ `stream(None, thread)` æ‰èƒ½ç»§ç»­ã€‚

```python
# âŒ é”™è¯¯ï¼šçŠ¶æ€æ›´æ–°äº†ï¼Œä½†å›¾æ²¡ç»§ç»­æ‰§è¡Œ
graph.update_state(thread, {"messages": "new message"})

# âœ… æ­£ç¡®ï¼šæ›´æ–°åç»§ç»­æ‰§è¡Œ
graph.update_state(thread, {"messages": "new message"})
graph.stream(None, thread)  # ä»å½“å‰çŠ¶æ€ç»§ç»­
```

### Q2: as_node å‚æ•°æœ‰ä»€ä¹ˆç”¨ï¼Ÿ

**ä½œç”¨ï¼š** æŒ‡å®šçŠ¶æ€æ›´æ–°æ¥è‡ªå“ªä¸ªèŠ‚ç‚¹ï¼Œå½±å“åç»­æ‰§è¡Œæµã€‚

```python
# ä¸æŒ‡å®š as_nodeï¼šçŠ¶æ€æ›´æ–°ï¼Œä½†å›¾ä¸çŸ¥é“è¯¥æ‰§è¡Œå“ªä¸ªèŠ‚ç‚¹
graph.update_state(thread, data)

# æŒ‡å®š as_nodeï¼šæ¨¡æ‹Ÿè¯¥èŠ‚ç‚¹å·²æ‰§è¡Œï¼Œè‡ªåŠ¨æµå‘ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
graph.update_state(thread, data, as_node="human_feedback")
# â†’ å›¾è®¤ä¸º human_feedback å·²å®Œæˆï¼Œæ‰§è¡Œå…¶åç»­èŠ‚ç‚¹
```

### Q3: æ–­ç‚¹å’Œ as_node å¦‚ä½•é…åˆï¼Ÿ

**å…¸å‹æ¨¡å¼ï¼š**
```python
# 1. è®¾ç½®æ–­ç‚¹
graph = builder.compile(interrupt_before=["human_feedback"])

# 2. æ‰§è¡Œåˆ°æ–­ç‚¹
graph.stream(input, thread)

# 3. ä½œä¸º human_feedback èŠ‚ç‚¹æ›´æ–°çŠ¶æ€
graph.update_state(thread, data, as_node="human_feedback")

# 4. ç»§ç»­æ‰§è¡Œï¼ˆè·³è¿‡ human_feedbackï¼Œæ‰§è¡Œä¸‹ä¸€ä¸ªèŠ‚ç‚¹ï¼‰
graph.stream(None, thread)
```

### Q4: å¦‚ä½•è¦†ç›–æ¶ˆæ¯è€Œéè¿½åŠ ï¼Ÿ

**æ–¹æ³•ï¼š** ä¿ç•™æ¶ˆæ¯çš„ `id`ã€‚

```python
# è¿½åŠ ï¼ˆæ—  IDï¼‰
graph.update_state(thread, {"messages": [HumanMessage("new")]})

# è¦†ç›–ï¼ˆæœ‰ IDï¼‰
state = graph.get_state(thread)
msg = state.values['messages'][-1]
msg.content = "modified"
graph.update_state(thread, {"messages": [msg]})  # msg ä¿ç•™äº† ID
```

### Q5: MemorySaver é‡å¯åæ•°æ®ä¼šä¸¢å¤±å—ï¼Ÿ

**ä¼šï¼** `MemorySaver` åªå­˜åœ¨å†…å­˜ä¸­ï¼Œè¿›ç¨‹é‡å¯å³ä¸¢å¤±ã€‚

**ç”Ÿäº§ç¯å¢ƒæ–¹æ¡ˆï¼š**
```python
from langgraph.checkpoint.sqlite import SqliteSaver

# æŒä¹…åŒ–åˆ°æ–‡ä»¶
checkpointer = SqliteSaver.from_conn_string("checkpoints.db")
graph = builder.compile(checkpointer=checkpointer)
```

---

## ğŸ“– æ‰©å±•é˜…è¯»

- [LangGraph çŠ¶æ€ç¼–è¾‘å®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/)
- [Human-in-the-Loop å®Œæ•´æŒ‡å—](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/)
- [LangGraph Studio ä½¿ç”¨æ•™ç¨‹](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/)
- [Checkpointer æŒä¹…åŒ–æ–¹æ¡ˆ](https://langchain-ai.github.io/langgraph/reference/checkpoints/)

---

## ğŸ“ æœ¬ç« æ€»ç»“

### æ ¸å¿ƒæ”¶è·

1. **æ–­ç‚¹æœºåˆ¶**ï¼šé€šè¿‡ `interrupt_before/after` åœ¨å…³é”®èŠ‚ç‚¹æš‚åœæ‰§è¡Œ
2. **çŠ¶æ€ç®¡ç†**ï¼šä½¿ç”¨ `get_state` æ£€æŸ¥ã€`update_state` ä¿®æ”¹çŠ¶æ€
3. **Reducer æœºåˆ¶**ï¼š`add_messages` æ ¹æ®æ¶ˆæ¯ ID å†³å®šè¿½åŠ æˆ–è¦†ç›–
4. **as_node å‚æ•°**ï¼šæ¨¡æ‹ŸèŠ‚ç‚¹è¾“å‡ºï¼Œæ§åˆ¶æ‰§è¡Œæµç¨‹
5. **äººå·¥åé¦ˆèŠ‚ç‚¹**ï¼šè®¾è®¡ä¸“é—¨çš„"ç©ºèŠ‚ç‚¹"ä½œä¸ºäººæœºäº¤äº’ç‚¹
6. **LangGraph Studio**ï¼šå¯è§†åŒ–å·¥å…·ï¼Œæ”¯æŒåŠ¨æ€æ–­ç‚¹å’ŒçŠ¶æ€ç¼–è¾‘

### è®¾è®¡æ¨¡å¼

| æ¨¡å¼ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| **æ£€æŸ¥ç‚¹å®¡æ‰¹** | åœ¨èŠ‚ç‚¹å‰æš‚åœï¼Œç­‰å¾…ç¡®è®¤ | é«˜é£é™©æ“ä½œ |
| **åé¦ˆæ³¨å…¥** | ä¸“é—¨èŠ‚ç‚¹æ¥æ”¶äººç±»è¾“å…¥ | å¤šè½®åä½œ |
| **çŠ¶æ€ä¿®æ­£** | ç›´æ¥ä¿®æ”¹é”™è¯¯çŠ¶æ€ | çº æ­£ AI è¯¯è§£ |
| **åŠ¨æ€æ–­ç‚¹** | æ ¹æ®æ¡ä»¶å†³å®šæ˜¯å¦æš‚åœ | è‡ªé€‚åº”å®¡æ‰¹ |

### ä¸‹ä¸€æ­¥

æŒæ¡äº†çŠ¶æ€ç¼–è¾‘å’Œäººå·¥åé¦ˆï¼Œä½ å·²ç»å…·å¤‡æ„å»º**é«˜åº¦å¯æ§çš„ AI Agent** çš„èƒ½åŠ›ã€‚æ¥ä¸‹æ¥ï¼Œå¯ä»¥å­¦ä¹ ï¼š
- **å¹¶è¡Œå¤„ç†**ï¼šå¤šä¸ª Agent ååŒå·¥ä½œ
- **å­å›¾ï¼ˆSubgraphï¼‰**ï¼šæ¨¡å—åŒ–å¤æ‚æµç¨‹
- **æŒä¹…åŒ–ç­–ç•¥**ï¼šç”Ÿäº§çº§çŠ¶æ€ç®¡ç†
- **é«˜çº§è·¯ç”±**ï¼šåŠ¨æ€å†³ç­–å’Œæ¡ä»¶æ‰§è¡Œ

çŠ¶æ€ç¼–è¾‘æ˜¯äººæœºåä½œçš„åŸºçŸ³ï¼ŒæŒæ¡å®ƒå°†è®©ä½ çš„ AI ç³»ç»Ÿæ›´åŠ æ™ºèƒ½ã€å¯é ã€å¯æ§ï¼
