# LangGraph ç”¨æˆ·éœ€æ±‚æ¾„æ¸…ä¸ç ”ç©¶è§„åˆ’è¯¦ç»†è§£è¯»

## ğŸ“š æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è§£è¯» **Scopingï¼ˆéœ€æ±‚æ¾„æ¸…ä¸ç ”ç©¶è§„åˆ’ï¼‰** åœ¨ Deep Research ç³»ç»Ÿä¸­çš„å…³é”®ä½œç”¨ã€‚è¿™æ˜¯æ•´ä¸ªç ”ç©¶æµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œä¹Ÿæ˜¯æœ€é‡è¦çš„ä¸€æ­¥â€”â€”å¦‚æœéœ€æ±‚ç†è§£é”™è¯¯ï¼Œåç»­æ‰€æœ‰ç ”ç©¶éƒ½å°†åç¦»æ–¹å‘ã€‚

**æ ¸å¿ƒé—®é¢˜ï¼š** ç”¨æˆ·çš„åˆå§‹è¯·æ±‚å¾€å¾€æ¨¡ç³Šã€ä¸å®Œæ•´ï¼Œç¼ºå°‘å…³é”®ä¿¡æ¯ã€‚

**ç¤ºä¾‹ï¼š**
- âŒ "ç ”ç©¶æœ€å¥½çš„å’–å•¡åº—" â†’ æœ€å¥½æŒ‡ä»€ä¹ˆï¼Ÿå’–å•¡è´¨é‡ï¼Ÿæ°›å›´ï¼Ÿä»·æ ¼ï¼Ÿ
- âŒ "å¯¹æ¯” A å’Œ B" â†’ å¯¹æ¯”å“ªäº›ç»´åº¦ï¼ŸæŠ€æœ¯ï¼Ÿä»·æ ¼ï¼Ÿç”¨æˆ·ä½“éªŒï¼Ÿ
- âŒ "åˆ†æç‰¹æ–¯æ‹‰" â†’ åˆ†æä»€ä¹ˆï¼Ÿè‚¡ç¥¨ï¼ŸæŠ€æœ¯ï¼Ÿå¸‚åœºï¼Ÿ

**Scoping çš„ç›®æ ‡ï¼š** é€šè¿‡æ™ºèƒ½å¯¹è¯ï¼Œå°†æ¨¡ç³Šè¯·æ±‚è½¬åŒ–ä¸ºæ¸…æ™°ã€ç»“æ„åŒ–çš„ç ”ç©¶ç®€æŠ¥ã€‚

---

## ğŸ“š æœ¯è¯­è¡¨

| æœ¯è¯­åç§° | LangGraph å®šä¹‰å’Œè§£è¯» | Python å®šä¹‰å’Œè¯´æ˜ | é‡è¦ç¨‹åº¦ |
|---------|---------------------|------------------|---------|
| **Scoping** | éœ€æ±‚æ¾„æ¸…ä¸ç ”ç©¶è§„åˆ’é˜¶æ®µï¼Œé€šè¿‡å¯¹è¯æ˜ç¡®ç”¨æˆ·çœŸå®éœ€æ±‚å¹¶ç”Ÿæˆç ”ç©¶ç®€æŠ¥ | N/A (å·¥ä½œæµæ¦‚å¿µ) | â­â­â­â­â­ |
| **ClarifyWithUser** | ç»“æ„åŒ–è¾“å‡º Schemaï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦å‘ç”¨æˆ·æé—® | `class ClarifyWithUser(BaseModel)` | â­â­â­â­â­ |
| **ResearchQuestion** | ç»“æ„åŒ–è¾“å‡º Schemaï¼Œç”¨äºç”Ÿæˆç ”ç©¶ç®€æŠ¥ | `class ResearchQuestion(BaseModel)` | â­â­â­â­â­ |
| **Command** | LangGraph æ§åˆ¶æµå¯¹è±¡ï¼Œç”¨äºåŠ¨æ€è·¯ç”±å’ŒçŠ¶æ€æ›´æ–° | `Command(goto="node", update={...})` | â­â­â­â­â­ |
| **Structured Output** | å¼ºåˆ¶ LLM è¾“å‡ºç¬¦åˆé¢„å®šä¹‰ Schema çš„æŠ€æœ¯ | `model.with_structured_output(Schema)` | â­â­â­â­â­ |
| **get_buffer_string** | å°†æ¶ˆæ¯å†å²è½¬åŒ–ä¸ºå­—ç¬¦ä¸²æ ¼å¼ | `from langchain_core.messages import get_buffer_string` | â­â­â­â­ |
| **MessagesState** | LangGraph é¢„å®šä¹‰çŠ¶æ€ç±»ï¼Œç®¡ç†æ¶ˆæ¯å†å² | `class MessagesState(TypedDict)` | â­â­â­â­ |
| **Research Brief** | è¯¦ç»†çš„ç ”ç©¶è§„åˆ’æ–‡æ¡£ï¼ŒæŒ‡å¯¼åç»­ç ”ç©¶æ–¹å‘ | å­—ç¬¦ä¸²ï¼ŒåŒ…å«ç ”ç©¶ä¸»é¢˜ã€èŒƒå›´ã€æ ‡å‡†ç­‰ | â­â­â­â­â­ |
| **LLM-as-judge** | ä½¿ç”¨ LLM è¯„ä¼°å…¶ä»– LLM è¾“å‡ºè´¨é‡çš„æŠ€æœ¯ | è¯„ä¼°å‡½æ•°ï¼Œè°ƒç”¨ LLM å¹¶è¿”å›è¯„åˆ† | â­â­â­â­ |

---

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ Scopingï¼Ÿ

**Scoping** æ˜¯ Deep Research ç³»ç»Ÿçš„ç¬¬ä¸€é˜¶æ®µï¼ŒåŒ…å«ä¸¤ä¸ªå­æ­¥éª¤ï¼š

1. **User Clarificationï¼ˆç”¨æˆ·æ¾„æ¸…ï¼‰** - åˆ¤æ–­æ˜¯å¦éœ€è¦å‘ç”¨æˆ·æé—®ä»¥æ¾„æ¸…éœ€æ±‚
2. **Brief Generationï¼ˆç®€æŠ¥ç”Ÿæˆï¼‰** - å°†å¯¹è¯å†å²è½¬åŒ–ä¸ºè¯¦ç»†çš„ç ”ç©¶ç®€æŠ¥

**å®Œæ•´æµç¨‹ï¼š**

```
ç”¨æˆ·è¾“å…¥: "ç ”ç©¶æœ€å¥½çš„å’–å•¡åº—"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: ç”¨æˆ·æ¾„æ¸…                     â”‚
â”‚ LLM åˆ†æ: "æœ€å¥½"çš„æ ‡å‡†ä¸æ˜ç¡®          â”‚
â”‚ ç”Ÿæˆé—®é¢˜: "æ‚¨å…³æ³¨å’–å•¡è´¨é‡ã€æ°›å›´è¿˜æ˜¯ä»·æ ¼ï¼Ÿ"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
ç”¨æˆ·å›å¤: "å’–å•¡è´¨é‡"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: ç®€æŠ¥ç”Ÿæˆ                     â”‚
â”‚ å°†å¯¹è¯è½¬åŒ–ä¸ºç ”ç©¶ç®€æŠ¥:                 â”‚
â”‚ "ç ”ç©¶æ—§é‡‘å±±åœ°åŒºä»¥å’–å•¡è´¨é‡è‘—ç§°çš„å’–å•¡åº—ï¼Œâ”‚
â”‚  é‡ç‚¹å…³æ³¨ä¸“ä¸šè¯„åˆ†ã€è±†æºã€çƒ˜ç„™æŠ€æœ¯..."  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ä¸ºä»€ä¹ˆéœ€è¦ Scopingï¼Ÿ

**é—®é¢˜ 1ï¼šç”¨æˆ·è¯·æ±‚ç¼ºå°‘å…³é”®ä¿¡æ¯**

å¸¸è§ç¼ºå¤±ä¿¡æ¯ï¼š
- **èŒƒå›´å’Œè¾¹ç•Œ** - åº”è¯¥åŒ…æ‹¬/æ’é™¤ä»€ä¹ˆï¼Ÿ
- **å—ä¼—å’Œç›®çš„** - è¿™ä¸ªç ”ç©¶æ˜¯ç»™è°çœ‹çš„ï¼Œä¸ºä»€ä¹ˆéœ€è¦ï¼Ÿ
- **å…·ä½“è¦æ±‚** - æœ‰ç‰¹å®šçš„æ¥æºã€æ—¶é—´èŒƒå›´ã€çº¦æŸå—ï¼Ÿ
- **æœ¯è¯­æ¾„æ¸…** - é¢†åŸŸæœ¯è¯­æˆ–ç¼©å†™æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ

**ç¤ºä¾‹å¯¹æ¯”ï¼š**

| æ¨¡ç³Šè¯·æ±‚ | ç¼ºå¤±ä¿¡æ¯ | æ¾„æ¸…é—®é¢˜ |
|---------|---------|---------|
| "ç ”ç©¶æœ€å¥½çš„å’–å•¡åº—" | åœ°ç‚¹ã€æ ‡å‡† | "å“ªä¸ªåŸå¸‚ï¼Ÿå…³æ³¨ä»€ä¹ˆæ ‡å‡†ï¼Ÿ" |
| "å¯¹æ¯” OpenAI å’Œ Anthropic" | å¯¹æ¯”ç»´åº¦ | "å¯¹æ¯”æŠ€æœ¯èƒ½åŠ›ã€ä»·æ ¼è¿˜æ˜¯ä½¿ç”¨ä½“éªŒï¼Ÿ" |
| "åˆ†æ TSLA" | åˆ†æè§’åº¦ | "åˆ†æè‚¡ç¥¨è¡¨ç°ã€æŠ€æœ¯åˆ›æ–°è¿˜æ˜¯å¸‚åœºç«äº‰ï¼Ÿ" |

**é—®é¢˜ 2ï¼šé¿å…é”™è¯¯å‡è®¾**

å¦‚æœä¸æ¾„æ¸…éœ€æ±‚ï¼ŒLLM å¯èƒ½åŸºäºè‡ªèº«åå¥½åšå‡ºå‡è®¾ï¼š

```python
# âŒ é”™è¯¯å‡è®¾ç¤ºä¾‹
User: "ç ”ç©¶æœ€å¥½çš„å’–å•¡åº—"
LLM (å‡è®¾): "ç”¨æˆ·å¯èƒ½å…³å¿ƒä»·æ ¼å’Œä¾¿åˆ©æ€§"
â†’ ç ”ç©¶ç»“æœ: è¿é”å’–å•¡åº—ï¼ˆStarbucks, Peet'sï¼‰

# âœ… æ­£ç¡®æµç¨‹
User: "ç ”ç©¶æœ€å¥½çš„å’–å•¡åº—"
LLM: "æ‚¨å…³æ³¨å’–å•¡è´¨é‡ã€æ°›å›´è¿˜æ˜¯ä»·æ ¼ï¼Ÿ"
User: "å’–å•¡è´¨é‡"
â†’ ç ”ç©¶ç»“æœ: ç²¾å“å’–å•¡åº—ï¼ˆBlue Bottle, Sightglassï¼‰
```

---

## ğŸ”§ æŠ€æœ¯å®ç°è¯¦è§£

### 1. çŠ¶æ€å®šä¹‰

```python
from typing_extensions import Optional, Annotated, Sequence
from langchain_core.messages import BaseMessage
from langgraph.graph import MessagesState
from langgraph.graph.message import add_messages
from pydantic import BaseModel, Field

# ===== çŠ¶æ€å®šä¹‰ =====

class AgentState(MessagesState):
    """
    ä¸»çŠ¶æ€ç±»ï¼Œç»§æ‰¿è‡ª MessagesState

    MessagesState æä¾›:
    - messages: æ¶ˆæ¯å†å²ï¼ˆè‡ªåŠ¨ä½¿ç”¨ add_messages reducerï¼‰

    æ–°å¢å­—æ®µ:
    - research_brief: ç”Ÿæˆçš„ç ”ç©¶ç®€æŠ¥
    - supervisor_messages: ä¸ supervisor çš„é€šä¿¡
    """
    research_brief: Optional[str]
    supervisor_messages: Annotated[Sequence[BaseMessage], add_messages]
```

**å…³é”®ç‚¹ï¼š**
- `MessagesState` - LangGraph é¢„å®šä¹‰åŸºç±»ï¼Œè‡ªåŠ¨ç®¡ç†æ¶ˆæ¯å†å²
- `add_messages` - Reducerï¼Œè‡ªåŠ¨å¤„ç†æ¶ˆæ¯è¿½åŠ /æ›´æ–°/åˆ é™¤
- `Optional[str]` - ç ”ç©¶ç®€æŠ¥åˆå§‹ä¸º Noneï¼Œç”Ÿæˆåæ‰æœ‰å€¼

---

### 2. Structured Output Schema

**ä¸ºä»€ä¹ˆä½¿ç”¨ Structured Outputï¼Ÿ**

ä¼ ç»Ÿæ–¹å¼ï¼ˆå­—ç¬¦ä¸²è¾“å‡ºï¼‰çš„é—®é¢˜ï¼š
```python
# âŒ ä¸å¯é çš„å­—ç¬¦ä¸²è§£æ
response = llm.invoke("åˆ¤æ–­æ˜¯å¦éœ€è¦æ¾„æ¸…ï¼Œå›ç­” yes/no")
# å¯èƒ½è¾“å‡º: "Yes, I think..."  "YES"  "yes."  "éœ€è¦æ¾„æ¸…"
# â†’ éš¾ä»¥å¯é è§£æ
```

Structured Output çš„ä¼˜åŠ¿ï¼š
```python
# âœ… å¯é çš„ç»“æ„åŒ–è¾“å‡º
class ClarifyWithUser(BaseModel):
    need_clarification: bool  # å¼ºåˆ¶ bool ç±»å‹
    question: str
    verification: str

response = llm.with_structured_output(ClarifyWithUser).invoke(...)
# ä¿è¯è¿”å›: response.need_clarification æ˜¯ True/False
```

**å®Œæ•´ Schema å®šä¹‰ï¼š**

```python
class ClarifyWithUser(BaseModel):
    """ç”¨æˆ·æ¾„æ¸…å†³ç­–å’Œé—®é¢˜ Schema"""

    need_clarification: bool = Field(
        description="æ˜¯å¦éœ€è¦å‘ç”¨æˆ·æé—®ä»¥æ¾„æ¸…éœ€æ±‚",
    )
    question: str = Field(
        description="å¦‚æœéœ€è¦æ¾„æ¸…ï¼Œå‘ç”¨æˆ·æå‡ºçš„é—®é¢˜ï¼ˆä½¿ç”¨ Markdown æ ¼å¼ï¼‰",
    )
    verification: str = Field(
        description="å¦‚æœä¸éœ€è¦æ¾„æ¸…ï¼Œç¡®è®¤å¼€å§‹ç ”ç©¶çš„æ¶ˆæ¯",
    )
```

**å·¥ä½œæµç¨‹ï¼š**
```python
if response.need_clarification:
    # è¿”å›é—®é¢˜ç»™ç”¨æˆ·
    return {"messages": [AIMessage(content=response.question)]}
else:
    # ç¡®è®¤å¼€å§‹ç ”ç©¶
    return {"messages": [AIMessage(content=response.verification)]}
```

---

### 3. Prompt è®¾è®¡

**æ ¸å¿ƒ Promptï¼ˆclarify_with_user_instructionsï¼‰ï¼š**

```python
clarify_with_user_instructions = """
è¿™æ˜¯ç”¨æˆ·ä¸ä½ çš„å¯¹è¯å†å²:
<Messages>
{messages}
</Messages>

ä»Šå¤©çš„æ—¥æœŸæ˜¯ {date}ã€‚

è¯„ä¼°æ˜¯å¦éœ€è¦æé—®æ¾„æ¸…ï¼Œæˆ–è€…ç”¨æˆ·å·²ç»æä¾›äº†è¶³å¤Ÿä¿¡æ¯ã€‚

é‡è¦æç¤º: å¦‚æœä½ å·²ç»åœ¨å¯¹è¯å†å²ä¸­é—®è¿‡æ¾„æ¸…é—®é¢˜ï¼Œå‡ ä¹æ€»æ˜¯ä¸éœ€è¦å†é—®ã€‚
åªåœ¨ç»å¯¹å¿…è¦æ—¶æ‰æå‡ºæ–°é—®é¢˜ã€‚

å¦‚æœæœ‰ç¼©å†™ã€ç®€ç§°æˆ–æœªçŸ¥æœ¯è¯­ï¼Œè¯·ç”¨æˆ·æ¾„æ¸…ã€‚

å¦‚æœéœ€è¦æé—®ï¼Œéµå¾ªä»¥ä¸‹å‡†åˆ™:
- ç®€æ´çš„åŒæ—¶æ”¶é›†æ‰€æœ‰å¿…è¦ä¿¡æ¯
- ç¡®ä¿æ”¶é›†æ‰§è¡Œç ”ç©¶ä»»åŠ¡æ‰€éœ€çš„å…¨éƒ¨ä¿¡æ¯
- é€‚å½“æ—¶ä½¿ç”¨é¡¹ç›®ç¬¦å·æˆ–ç¼–å·åˆ—è¡¨ä»¥æé«˜æ¸…æ™°åº¦
- ç¡®ä¿ä½¿ç”¨ Markdown æ ¼å¼ï¼Œå¯è¢« Markdown æ¸²æŸ“å™¨æ­£ç¡®æ˜¾ç¤º
- ä¸è¦è¯¢é—®ä¸å¿…è¦çš„ä¿¡æ¯æˆ–ç”¨æˆ·å·²ç»æä¾›çš„ä¿¡æ¯

ä»¥æœ‰æ•ˆ JSON æ ¼å¼å“åº”ï¼ŒåŒ…å«ä»¥ä¸‹é”®:
"need_clarification": boolean,
"question": "<å‘ç”¨æˆ·æé—®ä»¥æ¾„æ¸…ç ”ç©¶èŒƒå›´>",
"verification": "<ç¡®è®¤æˆ‘ä»¬å°†å¼€å§‹ç ”ç©¶çš„æ¶ˆæ¯>"

å¦‚æœéœ€è¦æ¾„æ¸…é—®é¢˜ï¼Œè¿”å›:
"need_clarification": true,
"question": "<ä½ çš„æ¾„æ¸…é—®é¢˜>",
"verification": ""

å¦‚æœä¸éœ€è¦æ¾„æ¸…é—®é¢˜ï¼Œè¿”å›:
"need_clarification": false,
"question": "",
"verification": "<ç¡®è®¤æ¶ˆæ¯ï¼šä½ å°†åŸºäºæä¾›çš„ä¿¡æ¯å¼€å§‹ç ”ç©¶>"

å¯¹äºä¸éœ€è¦æ¾„æ¸…æ—¶çš„ç¡®è®¤æ¶ˆæ¯:
- ç¡®è®¤ä½ æœ‰è¶³å¤Ÿä¿¡æ¯ç»§ç»­
- ç®€è¦æ€»ç»“ä½ ä»è¯·æ±‚ä¸­ç†è§£çš„å…³é”®å†…å®¹
- ç¡®è®¤ä½ ç°åœ¨å°†å¼€å§‹ç ”ç©¶è¿‡ç¨‹
- ä¿æŒç®€æ´å’Œä¸“ä¸š
"""
```

**Prompt è®¾è®¡åŸåˆ™ï¼š**

1. **é˜²æ­¢é‡å¤æé—®**
   ```
   é‡è¦æç¤º: å¦‚æœä½ å·²ç»åœ¨å¯¹è¯å†å²ä¸­é—®è¿‡æ¾„æ¸…é—®é¢˜ï¼Œå‡ ä¹æ€»æ˜¯ä¸éœ€è¦å†é—®ã€‚
   ```

2. **æ˜ç¡®è¾“å‡ºæ ¼å¼**
   - ä½¿ç”¨ JSON Schema
   - æä¾›æ­£è´Ÿç¤ºä¾‹ï¼ˆéœ€è¦æ¾„æ¸… vs ä¸éœ€è¦æ¾„æ¸…ï¼‰

3. **æä¾›ä¸Šä¸‹æ–‡**
   - åŒ…å«å®Œæ•´å¯¹è¯å†å²
   - æä¾›å½“å‰æ—¥æœŸï¼ˆå¯¹æ—¶é—´æ•æ„Ÿçš„ç ”ç©¶å¾ˆé‡è¦ï¼‰

4. **è´¨é‡è¦æ±‚**
   - ä½¿ç”¨ Markdown æ ¼å¼
   - ç®€æ´ä½†å®Œæ•´
   - é¡¹ç›®ç¬¦å·æé«˜å¯è¯»æ€§

---

### 4. èŠ‚ç‚¹å®ç°ï¼šclarify_with_user

```python
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage, AIMessage, get_buffer_string
from langgraph.types import Command

# åˆå§‹åŒ–æ¨¡å‹
model = init_chat_model(model="openai:gpt-4.1", temperature=0.0)

def clarify_with_user(state: AgentState) -> Command:
    """
    åˆ¤æ–­æ˜¯å¦éœ€è¦å‘ç”¨æˆ·æé—®ä»¥æ¾„æ¸…éœ€æ±‚

    ä½¿ç”¨ Structured Output ç¡®ä¿å¯é çš„å†³ç­–

    Returns:
        Command å¯¹è±¡ï¼ŒæŒ‡å‘ä¸‹ä¸€ä¸ªèŠ‚ç‚¹:
        - å¦‚æœéœ€è¦æ¾„æ¸… â†’ goto=END (è¿”å›é—®é¢˜ç»™ç”¨æˆ·)
        - å¦‚æœä¸éœ€è¦æ¾„æ¸… â†’ goto="write_research_brief"
    """
    # è®¾ç½® Structured Output æ¨¡å‹
    structured_output_model = model.with_structured_output(ClarifyWithUser)

    # è°ƒç”¨æ¨¡å‹è¿›è¡Œåˆ¤æ–­
    response = structured_output_model.invoke([
        HumanMessage(content=clarify_with_user_instructions.format(
            messages=get_buffer_string(messages=state["messages"]),
            date=get_today_str()
        ))
    ])

    # åŸºäºåˆ¤æ–­ç»“æœè·¯ç”±
    if response.need_clarification:
        # éœ€è¦æ¾„æ¸…ï¼šç»“æŸå½“å‰æ‰§è¡Œï¼Œè¿”å›é—®é¢˜ç»™ç”¨æˆ·
        return Command(
            goto=END,
            update={"messages": [AIMessage(content=response.question)]}
        )
    else:
        # ä¸éœ€è¦æ¾„æ¸…ï¼šç»§ç»­åˆ°ç®€æŠ¥ç”Ÿæˆ
        return Command(
            goto="write_research_brief",
            update={"messages": [AIMessage(content=response.verification)]}
        )
```

**å…³é”®æŠ€æœ¯ï¼šCommand å¯¹è±¡**

```python
Command(
    goto="next_node",  # ä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„èŠ‚ç‚¹ï¼ˆæˆ– ENDï¼‰
    update={...}        # è¦æ›´æ–°çš„çŠ¶æ€å­—æ®µ
)
```

**Command çš„ä¼˜åŠ¿ï¼š**
- ğŸ¯ **çµæ´»è·¯ç”±** - èŠ‚ç‚¹å¯ä»¥åŠ¨æ€å†³å®šä¸‹ä¸€æ­¥
- ğŸ”„ **çŠ¶æ€æ›´æ–°** - åŒæ—¶æ›´æ–°çŠ¶æ€å’Œè·³è½¬
- ğŸ“Š **æ¸…æ™°è¯­ä¹‰** - ä»£ç æ„å›¾ä¸€ç›®äº†ç„¶

**å¯¹æ¯”ä¼ ç»Ÿæ¡ä»¶è¾¹ï¼š**

```python
# âŒ ä¼ ç»Ÿæ–¹å¼ï¼šéœ€è¦å•ç‹¬çš„è·¯ç”±å‡½æ•°
def should_continue(state):
    if needs_clarification(state):
        return "end"
    return "write_brief"

builder.add_conditional_edges("clarify", should_continue, {...})

# âœ… ä½¿ç”¨ Commandï¼šå†³ç­–å’Œè·¯ç”±åœ¨ä¸€ä¸ªèŠ‚ç‚¹ä¸­
def clarify_with_user(state):
    if response.need_clarification:
        return Command(goto=END, update={...})
    return Command(goto="write_research_brief", update={...})
```

---

### 5. èŠ‚ç‚¹å®ç°ï¼šwrite_research_brief

```python
class ResearchQuestion(BaseModel):
    """ç ”ç©¶ç®€æŠ¥ Schema"""
    research_brief: str = Field(
        description="è¯¦ç»†çš„ç ”ç©¶ç®€æŠ¥ï¼Œå°†æŒ‡å¯¼åç»­ç ”ç©¶",
    )

def write_research_brief(state: AgentState):
    """
    å°†å¯¹è¯å†å²è½¬åŒ–ä¸ºè¯¦ç»†çš„ç ”ç©¶ç®€æŠ¥

    ä½¿ç”¨ Structured Output ç¡®ä¿ç®€æŠ¥æ ¼å¼ç¬¦åˆè¦æ±‚
    """
    # è®¾ç½® Structured Output æ¨¡å‹
    structured_output_model = model.with_structured_output(ResearchQuestion)

    # ç”Ÿæˆç ”ç©¶ç®€æŠ¥
    response = structured_output_model.invoke([
        HumanMessage(content=transform_messages_into_research_topic_prompt.format(
            messages=get_buffer_string(state.get("messages", [])),
            date=get_today_str()
        ))
    ])

    # æ›´æ–°çŠ¶æ€
    return {
        "research_brief": response.research_brief,
        "supervisor_messages": [HumanMessage(content=f"{response.research_brief}.")]
    }
```

**ç ”ç©¶ç®€æŠ¥çš„è´¨é‡è¦æ±‚ï¼š**

å¥½çš„ç ”ç©¶ç®€æŠ¥åº”è¯¥åŒ…å«ï¼š
1. **æ˜ç¡®çš„ç ”ç©¶ä¸»é¢˜** - è¦ç ”ç©¶ä»€ä¹ˆï¼Ÿ
2. **å…·ä½“çš„èŒƒå›´** - åŒ…æ‹¬/æ’é™¤ä»€ä¹ˆï¼Ÿ
3. **è¯„ä¼°æ ‡å‡†** - å¦‚ä½•åˆ¤æ–­"å¥½"ï¼Ÿ
4. **ä¼˜å…ˆä¿¡æ¯æº** - é¦–é€‰ä»€ä¹ˆç±»å‹çš„æ¥æºï¼Ÿ
5. **æ—¶é—´è¦æ±‚** - æˆªæ­¢åˆ°ä»€ä¹ˆæ—¶å€™çš„ä¿¡æ¯ï¼Ÿ

**ç¤ºä¾‹å¯¹æ¯”ï¼š**

| è´¨é‡ | ç ”ç©¶ç®€æŠ¥å†…å®¹ |
|------|-------------|
| âŒ å·® | "ç ”ç©¶æ—§é‡‘å±±çš„å’–å•¡åº—" |
| âš ï¸ ä¸€èˆ¬ | "ç ”ç©¶æ—§é‡‘å±±çš„ç²¾å“å’–å•¡åº—ï¼Œå…³æ³¨å’–å•¡è´¨é‡" |
| âœ… å¥½ | "ç ”ç©¶æ—§é‡‘å±±ä»¥å’–å•¡è´¨é‡è‘—ç§°çš„ç²¾å“å’–å•¡åº—ã€‚é‡ç‚¹å…³æ³¨è±†æºã€çƒ˜ç„™æŠ€æœ¯ã€ä¸“ä¸šè¯„åˆ†ï¼ˆå¦‚ Coffee Reviewï¼‰å’Œç”¨æˆ·è¯„ä»·ã€‚ä¼˜å…ˆä½¿ç”¨å’–å•¡åº—å®˜ç½‘ã€ç¬¬ä¸‰æ–¹ä¸“ä¸šè¯„æµ‹ï¼ˆSpecialty Coffee Associationï¼‰å’Œè¯„ä»·èšåˆç½‘ç«™ï¼ˆYelp, Google Reviewsï¼‰ã€‚æˆªæ­¢åˆ° 2025å¹´7æœˆçš„æœ€æ–°æ•°æ®ã€‚" |

---

### 6. å›¾æ„å»º

```python
from langgraph.graph import StateGraph, START, END

# æ„å»º Scoping å·¥ä½œæµ
scope_builder = StateGraph(AgentState, input_schema=AgentInputState)

# æ·»åŠ èŠ‚ç‚¹
scope_builder.add_node("clarify_with_user", clarify_with_user)
scope_builder.add_node("write_research_brief", write_research_brief)

# æ·»åŠ è¾¹
scope_builder.add_edge(START, "clarify_with_user")
scope_builder.add_edge("write_research_brief", END)

# ç¼–è¯‘
scope_research = scope_builder.compile()
```

**å›¾çš„æ‰§è¡Œæµç¨‹ï¼š**

```
START
  â†“
clarify_with_user
  â†“ (decision)
  â”œâ”€ need_clarification? â†’ END (è¿”å›é—®é¢˜)
  â””â”€ sufficient info? â†’ write_research_brief â†’ END
```

---

## ğŸ­ å®æˆ˜æ¡ˆä¾‹ï¼šå’–å•¡åº—ç ”ç©¶

### ç¤ºä¾‹ 1ï¼šéœ€è¦æ¾„æ¸…

```python
from langchain_core.messages import HumanMessage
from langgraph.checkpoint.memory import MemorySaver

# ç¼–è¯‘å¸¦ checkpointer çš„å›¾ï¼ˆç”¨äºæµ‹è¯•ï¼‰
checkpointer = MemorySaver()
scope = scope_builder.compile(checkpointer=checkpointer)

# ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šæ¨¡ç³Šè¯·æ±‚
thread = {"configurable": {"thread_id": "1"}}
result = scope.invoke({
    "messages": [HumanMessage(content="æˆ‘æƒ³ç ”ç©¶æ—§é‡‘å±±æœ€å¥½çš„å’–å•¡åº—ã€‚")]
}, config=thread)

print(result['messages'][-1].content)
```

**è¾“å‡ºï¼š**
```
æ‚¨èƒ½å…·ä½“è¯´æ˜ä»€ä¹ˆæ ‡å‡†å¯¹æ‚¨æ¥è¯´æœ€é‡è¦å—ï¼Ÿä¾‹å¦‚ï¼š
- å’–å•¡è´¨é‡
- æ°›å›´å’Œç¯å¢ƒ
- Wi-Fi å¯ç”¨æ€§
- é£Ÿç‰©é€‰é¡¹
- å…¶ä»–å› ç´ ï¼Ÿ
```

**ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šæä¾›æ¾„æ¸…**
```python
result = scope.invoke({
    "messages": [HumanMessage(content="å’–å•¡è´¨é‡æ˜¯æœ€é‡è¦çš„æ ‡å‡†ã€‚")]
}, config=thread)

print(result['messages'][-1].content)
```

**è¾“å‡ºï¼š**
```
æ„Ÿè°¢æ¾„æ¸…ï¼Œå’–å•¡è´¨é‡æ˜¯æ‚¨çš„é¦–è¦æ ‡å‡†ã€‚æˆ‘æœ‰è¶³å¤Ÿä¿¡æ¯ç»§ç»­ï¼Œ
ç°åœ¨å°†å¼€å§‹ç ”ç©¶æ—§é‡‘å±±åŸºäºå’–å•¡è´¨é‡çš„æœ€ä½³å’–å•¡åº—ã€‚
```

**ç”Ÿæˆçš„ç ”ç©¶ç®€æŠ¥ï¼š**
```python
print(result["research_brief"])
```

**è¾“å‡ºï¼š**
```
æˆ‘æƒ³è¯†åˆ«å’Œè¯„ä¼°æ—§é‡‘å±±è¢«è®¤ä¸ºæ˜¯åŸºäºå’–å•¡è´¨é‡çš„æœ€ä½³å’–å•¡åº—ã€‚
æˆ‘çš„ç ”ç©¶åº”ä¸“æ³¨äºåˆ†æå’Œæ¯”è¾ƒæ—§é‡‘å±±åœ°åŒºçš„å’–å•¡åº—ï¼Œä»¥å’–å•¡è´¨é‡
ä½œä¸ºä¸»è¦æ ‡å‡†ã€‚æˆ‘å¯¹è¯„ä¼°å’–å•¡è´¨é‡çš„æ–¹æ³•æŒå¼€æ”¾æ€åº¦ï¼ˆä¾‹å¦‚ï¼Œ
ä¸“å®¶è¯„æµ‹ã€å®¢æˆ·è¯„åˆ†ã€ç²¾å“å’–å•¡è®¤è¯ï¼‰ï¼Œå¯¹æ°›å›´ã€åœ°ç‚¹ã€Wi-Fi
æˆ–é£Ÿç‰©é€‰é¡¹æ²¡æœ‰çº¦æŸï¼Œé™¤éå®ƒä»¬ç›´æ¥å½±å“æ„ŸçŸ¥çš„å’–å•¡è´¨é‡ã€‚

è¯·ä¼˜å…ˆè€ƒè™‘ä¸»è¦æ¥æºï¼Œå¦‚å’–å•¡åº—å®˜ç½‘ã€ä¿¡èª‰è‰¯å¥½çš„ç¬¬ä¸‰æ–¹å’–å•¡
è¯„æµ‹ç»„ç»‡ï¼ˆå¦‚ Coffee Review æˆ– Specialty Coffee Associationï¼‰
ä»¥åŠçŸ¥åè¯„ä»·èšåˆç½‘ç«™ï¼ˆå¦‚ Google æˆ– Yelpï¼‰ï¼Œåœ¨è¿™äº›ç½‘ç«™å¯ä»¥
æ‰¾åˆ°å…³äºå’–å•¡è´¨é‡çš„ç›´æ¥å®¢æˆ·åé¦ˆã€‚

ç ”ç©¶åº”äº§ç”Ÿä¸€ä¸ªæœ‰å……åˆ†æ”¯æŒçš„åˆ—è¡¨æˆ–æ’åï¼Œå¼ºè°ƒæˆªæ­¢åˆ° 2025å¹´7æœˆ
çš„æœ€æ–°å¯ç”¨æ•°æ®æ‰€æ˜¾ç¤ºçš„å’–å•¡è´¨é‡ã€‚
```

---

### ç¤ºä¾‹ 2ï¼šç«‹å³æ»¡è¶³ï¼ˆæ— éœ€æ¾„æ¸…ï¼‰

```python
thread2 = {"configurable": {"thread_id": "2"}}
result = scope.invoke({
    "messages": [HumanMessage(content="""
    æˆ‘æƒ³ç ”ç©¶æ—§é‡‘å±±åŸºäºå’–å•¡è´¨é‡çš„æœ€ä½³å’–å•¡åº—ã€‚
    è¯·å…³æ³¨ä¸“ä¸šè¯„åˆ†ï¼ˆCoffee Reviewï¼‰ã€è±†æºå’Œçƒ˜ç„™æŠ€æœ¯ã€‚
    ä¼˜å…ˆä½¿ç”¨å®˜ç½‘å’Œä¸“ä¸šè¯„æµ‹ç½‘ç«™ã€‚
    """)]
}, config=thread2)

print(result['messages'][-1].content)
```

**è¾“å‡ºï¼š**
```
æ„Ÿè°¢æ‚¨æä¾›å…·ä½“çš„ç ”ç©¶å‚æ•°ã€‚æ‚¨å·²ç»æ˜ç¡®æŒ‡å®šäº†åœ°ç‚¹ï¼ˆæ—§é‡‘å±±ï¼‰ã€
ä¸»è¦æ ‡å‡†ï¼ˆå’–å•¡è´¨é‡ï¼‰ä»¥åŠè¯„ä¼°æ–¹æ³•ï¼ˆä¸“ä¸šè¯„åˆ†ã€è±†æºã€çƒ˜ç„™æŠ€æœ¯ï¼‰ã€‚
æˆ‘ç°åœ¨å°†å¼€å§‹åŸºäºæä¾›çš„æ ‡å‡†è¿›è¡Œç ”ç©¶ã€‚
```

**ç›´æ¥ç”Ÿæˆç®€æŠ¥ï¼Œæ— éœ€é¢å¤–æ¾„æ¸…ã€‚**

---

## ğŸ“ æ ¸å¿ƒçŸ¥è¯†ç‚¹æ€»ç»“

### LangGraph ç‰¹æœ‰æ¦‚å¿µ

#### 1. Structured Output çš„å¼ºå¤§ä¹‹å¤„

**ä¼ ç»Ÿå­—ç¬¦ä¸²è¾“å‡ºçš„é—®é¢˜ï¼š**
```python
# âŒ ä¸å¯é 
response = llm.invoke("åˆ¤æ–­æ˜¯å¦éœ€è¦æ¾„æ¸…ï¼Œå›ç­” true/false")
# å¯èƒ½è¿”å›: "True"  "true"  "TRUE"  "yes"  "I think true"
if "true" in response.lower():  # è„†å¼±çš„è§£æ
    ...
```

**Structured Output çš„ä¼˜åŠ¿ï¼š**
```python
# âœ… å¯é 
class Decision(BaseModel):
    need_clarification: bool

response = llm.with_structured_output(Decision).invoke(...)
if response.need_clarification:  # ç±»å‹å®‰å…¨
    ...
```

**é‡è¦æç¤ºï¼š** Structured Output ä½¿ç”¨ LLM çš„ function calling èƒ½åŠ›ï¼Œç¡®ä¿è¾“å‡ºç¬¦åˆ Schemaã€‚

---

#### 2. Command å¯¹è±¡çš„çµæ´»æ€§

**Command vs æ¡ä»¶è¾¹å¯¹æ¯”ï¼š**

| ç‰¹æ€§ | æ¡ä»¶è¾¹ | Command |
|------|--------|---------|
| è·¯ç”±å†³ç­– | å•ç‹¬çš„è·¯ç”±å‡½æ•° | èŠ‚ç‚¹å†…éƒ¨å†³ç­– |
| çŠ¶æ€æ›´æ–° | åˆ†ç¦»çš„é€»è¾‘ | ä¸€èµ·å¤„ç† |
| ä»£ç ç»„ç»‡ | åˆ†æ•£åœ¨å¤šå¤„ | é›†ä¸­åœ¨èŠ‚ç‚¹ä¸­ |
| çµæ´»æ€§ | è¾ƒä½ | é«˜ |

**ä½¿ç”¨å»ºè®®ï¼š**
- âœ… **ç®€å•é™æ€è·¯ç”±** - ä½¿ç”¨æ¡ä»¶è¾¹
- âœ… **å¤æ‚åŠ¨æ€è·¯ç”±** - ä½¿ç”¨ Command

---

#### 3. MessagesState çš„ä¾¿åˆ©æ€§

**æ‰‹åŠ¨ç®¡ç† vs MessagesStateï¼š**

```python
# âŒ æ‰‹åŠ¨ç®¡ç†æ¶ˆæ¯
class MyState(TypedDict):
    messages: list

def node(state):
    new_messages = state["messages"] + [new_msg]  # æ‰‹åŠ¨è¿½åŠ 
    return {"messages": new_messages}

# âœ… ä½¿ç”¨ MessagesState
class MyState(MessagesState):
    pass  # è‡ªåŠ¨åŒ…å« messages + add_messages reducer

def node(state):
    return {"messages": [new_msg]}  # è‡ªåŠ¨è¿½åŠ 
```

**add_messages Reducer åŠŸèƒ½ï¼š**
- ğŸ”„ **è¿½åŠ æ¶ˆæ¯** - é»˜è®¤è¡Œä¸º
- ğŸ”„ **è¦†ç›–æ¶ˆæ¯** - å¦‚æœæä¾›ç›¸åŒ ID
- ğŸ”„ **åˆ é™¤æ¶ˆæ¯** - ä½¿ç”¨ RemoveMessage

---

### Python ç‰¹æœ‰çŸ¥è¯†ç‚¹

#### 1. Pydantic BaseModel

```python
from pydantic import BaseModel, Field

class ClarifyWithUser(BaseModel):
    need_clarification: bool = Field(
        description="æ˜¯å¦éœ€è¦æ¾„æ¸…"  # è¿™ä¸ªæè¿°ä¼šä¼ é€’ç»™ LLM
    )
```

**Field çš„ä½œç”¨ï¼š**
- ğŸ“ **description** - å‘Šè¯‰ LLM è¿™ä¸ªå­—æ®µçš„ç”¨é€”
- ğŸ“ **examples** - æä¾›ç¤ºä¾‹å€¼
- ğŸ“ **constraints** - æ·»åŠ éªŒè¯è§„åˆ™

---

#### 2. get_buffer_string å·¥å…·å‡½æ•°

```python
from langchain_core.messages import get_buffer_string

messages = [
    HumanMessage("ä½ å¥½"),
    AIMessage("ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ"),
    HumanMessage("å‘Šè¯‰æˆ‘å…³äºå’–å•¡çš„ä¿¡æ¯")
]

buffer = get_buffer_string(messages)
# è¾“å‡º:
# Human: ä½ å¥½
# AI: ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ
# Human: å‘Šè¯‰æˆ‘å…³äºå’–å•¡çš„ä¿¡æ¯
```

**ç”¨é€”ï¼š** å°†æ¶ˆæ¯åˆ—è¡¨æ ¼å¼åŒ–ä¸º LLM å¯è¯»çš„å­—ç¬¦ä¸²ã€‚

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ä½•æ—¶éœ€è¦æ¾„æ¸…ï¼Ÿ

**éœ€è¦æ¾„æ¸…çš„åœºæ™¯ï¼š**
- âœ… è¯·æ±‚åŒ…å«æ¨¡ç³Šæœ¯è¯­ï¼ˆ"æœ€å¥½"ã€"é¡¶çº§"ã€"ä¼˜ç§€"ï¼‰
- âœ… ç¼ºå°‘å…³é”®å‚æ•°ï¼ˆåœ°ç‚¹ã€æ—¶é—´ã€æ ‡å‡†ï¼‰
- âœ… ä½¿ç”¨ç¼©å†™æˆ–ä¸“ä¸šæœ¯è¯­
- âœ… å¯¹æ¯”ä»»åŠ¡ä½†æœªæŒ‡å®šç»´åº¦

**ä¸éœ€è¦æ¾„æ¸…çš„åœºæ™¯ï¼š**
- âŒ è¯·æ±‚éå¸¸å…·ä½“ï¼ˆ"2024å¹´Q4 TSLA è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿"ï¼‰
- âŒ å·²ç»åœ¨å¯¹è¯ä¸­æ¾„æ¸…è¿‡
- âŒ å¸¸è¯†æ€§è¯·æ±‚ï¼ˆ"Python å¦‚ä½•å®šä¹‰å‡½æ•°"ï¼‰

---

### 2. Prompt è®¾è®¡æŠ€å·§

**æŠ€å·§ 1ï¼šæä¾›æ­£è´Ÿç¤ºä¾‹**

```python
prompt = """
å¦‚æœéœ€è¦æ¾„æ¸…ï¼Œè¿”å›:
{
  "need_clarification": true,
  "question": "æ‚¨å…³æ³¨çš„æ˜¯å’–å•¡è´¨é‡ã€æ°›å›´è¿˜æ˜¯ä»·æ ¼ï¼Ÿ",
  "verification": ""
}

å¦‚æœä¸éœ€è¦æ¾„æ¸…ï¼Œè¿”å›:
{
  "need_clarification": false,
  "question": "",
  "verification": "æˆ‘å°†åŸºäºæ‚¨æä¾›çš„æ ‡å‡†å¼€å§‹ç ”ç©¶ã€‚"
}
"""
```

**æŠ€å·§ 2ï¼šé˜²æ­¢é‡å¤æé—®**

```python
# åœ¨ Prompt ä¸­æ˜ç¡®æŒ‡å‡º
"å¦‚æœä½ å·²ç»åœ¨å¯¹è¯å†å²ä¸­é—®è¿‡æ¾„æ¸…é—®é¢˜ï¼Œå‡ ä¹æ€»æ˜¯ä¸éœ€è¦å†é—®ã€‚"
```

**æŠ€å·§ 3ï¼šä½¿ç”¨ XML æ ‡ç­¾ç»„ç»‡ä¸Šä¸‹æ–‡**

```python
prompt = """
<Messages>
{messages}
</Messages>

<Instructions>
...
</Instructions>

<Output Format>
...
</Output Format>
"""
```

---

### 3. ç ”ç©¶ç®€æŠ¥çš„è´¨é‡æ ‡å‡†

**è¯„ä¼°æ ‡å‡†ï¼š**

| æ ‡å‡† | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **å®Œæ•´æ€§** | åŒ…å«æ‰€æœ‰ç”¨æˆ·æåˆ°çš„è¦ç‚¹ | å¦‚æœç”¨æˆ·æåˆ°"å’–å•¡è´¨é‡"ï¼Œç®€æŠ¥å¿…é¡»åŒ…å« |
| **æ— å‡è®¾** | ä¸æ·»åŠ ç”¨æˆ·æœªæåŠçš„åå¥½ | ç”¨æˆ·æœªæåˆ°"ä»·æ ¼"ï¼Œä¸åº”å‡è®¾ä»·æ ¼é‡è¦ |
| **å…·ä½“æ€§** | æ˜ç¡®çš„è¯„ä¼°æ ‡å‡†å’Œæ¥æº | "ä¸“ä¸šè¯„åˆ†ï¼ˆCoffee Reviewï¼‰"è€Œé"å¥½çš„è¯„ä»·" |
| **å¯æ‰§è¡Œ** | æä¾›è¶³å¤Ÿç»†èŠ‚ä¾›ç ”ç©¶ Agent æ‰§è¡Œ | æ˜ç¡®æ—¶é—´èŒƒå›´ã€åœ°ç†èŒƒå›´ã€æ•°æ®æº |

---

### 4. é”™è¯¯å¤„ç†

**å¸¸è§é—®é¢˜ï¼š**

**é—®é¢˜ 1ï¼šLLM æ‹’ç»ä½¿ç”¨ Structured Output**

```python
# âŒ LLM è¿”å›è‡ªç„¶è¯­è¨€è€Œé JSON
try:
    response = llm.with_structured_output(ClarifyWithUser).invoke(...)
except Exception as e:
    # é™çº§ç­–ç•¥ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æ
    ...
```

**è§£å†³æ–¹æ¡ˆï¼š**
- ä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹ï¼ˆGPT-4 è€Œé GPT-3.5ï¼‰
- åœ¨ Prompt ä¸­å¼ºè°ƒè¾“å‡ºæ ¼å¼è¦æ±‚
- æä¾›æ›´å¤šç¤ºä¾‹

**é—®é¢˜ 2ï¼šå¯¹è¯å†å²å¤ªé•¿**

```python
# å¦‚æœå¯¹è¯è¶…è¿‡ 100 è½®
if len(state["messages"]) > 100:
    # åªä¿ç•™æœ€è¿‘ 50 è½®
    recent_messages = state["messages"][-50:]
    buffer = get_buffer_string(recent_messages)
```

---

## ğŸ” è¯„ä¼°æ–¹æ³•

### è®¾è®¡è¯„ä¼°å™¨

**è¯„ä¼°ç›®æ ‡ï¼š**
1. ç ”ç©¶ç®€æŠ¥æ˜¯å¦åŒ…å«æ‰€æœ‰ç”¨æˆ·æåˆ°çš„æ ‡å‡†ï¼Ÿ
2. ç ”ç©¶ç®€æŠ¥æ˜¯å¦é¿å…äº†ç”¨æˆ·æœªæåŠçš„å‡è®¾ï¼Ÿ

**è¯„ä¼°å™¨ 1ï¼šSuccess Criteriaï¼ˆæˆåŠŸæ ‡å‡†ï¼‰**

```python
from pydantic import BaseModel, Field

class Criteria(BaseModel):
    criteria_text: str = Field(description="å…·ä½“çš„æˆåŠŸæ ‡å‡†")
    reasoning: str = Field(description="è¯„ä¼°æ¨ç†")
    is_captured: bool = Field(description="æ˜¯å¦åœ¨ç®€æŠ¥ä¸­ä½“ç°")

def evaluate_success_criteria(outputs: dict, reference_outputs: dict):
    """
    è¯„ä¼°ç ”ç©¶ç®€æŠ¥æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€æ ‡å‡†
    """
    research_brief = outputs["research_brief"]
    success_criteria = reference_outputs["criteria"]

    model = ChatOpenAI(model="gpt-4.1", temperature=0)
    structured_model = model.with_structured_output(Criteria)

    # æ‰¹é‡è¯„ä¼°æ¯ä¸ªæ ‡å‡†
    individual_evaluations = []
    for criterion in success_criteria:
        response = structured_model.invoke([
            HumanMessage(content=f"""
            ç ”ç©¶ç®€æŠ¥: {research_brief}

            è¯„ä¼°æ ‡å‡†: {criterion}

            åˆ¤æ–­è¿™ä¸ªæ ‡å‡†æ˜¯å¦åœ¨ç ”ç©¶ç®€æŠ¥ä¸­å¾—åˆ°å……åˆ†ä½“ç°ã€‚
            """)
        ])
        individual_evaluations.append(response)

    # è®¡ç®—æ€»åˆ†
    captured_count = sum(1 for eval in individual_evaluations if eval.is_captured)
    total_count = len(individual_evaluations)

    return {
        "key": "success_criteria_score",
        "score": captured_count / total_count,
        "individual_evaluations": individual_evaluations
    }
```

**è¯„ä¼°å™¨ 2ï¼šNo Assumptionsï¼ˆæ— å‡è®¾ï¼‰**

```python
class NoAssumptions(BaseModel):
    no_assumptions: bool = Field(
        description="ç ”ç©¶ç®€æŠ¥æ˜¯å¦é¿å…äº†æœªç»ç”¨æˆ·æ˜ç¡®çš„å‡è®¾"
    )
    reasoning: str = Field(description="è¯„ä¼°æ¨ç†")

def evaluate_no_assumptions(outputs: dict, reference_outputs: dict):
    """
    è¯„ä¼°ç ”ç©¶ç®€æŠ¥æ˜¯å¦é¿å…äº†é”™è¯¯å‡è®¾
    """
    research_brief = outputs["research_brief"]
    success_criteria = reference_outputs["criteria"]

    model = ChatOpenAI(model="gpt-4.1", temperature=0)
    structured_model = model.with_structured_output(NoAssumptions)

    response = structured_model.invoke([
        HumanMessage(content=f"""
        ç ”ç©¶ç®€æŠ¥: {research_brief}
        ç”¨æˆ·æ˜ç¡®çš„æ ‡å‡†: {success_criteria}

        è¯„ä¼°ç ”ç©¶ç®€æŠ¥æ˜¯å¦åŒ…å«äº†ç”¨æˆ·æœªæ˜ç¡®æåŠçš„å‡è®¾æˆ–åå¥½ã€‚
        """)
    ])

    return {
        "key": "no_assumptions_score",
        "score": response.no_assumptions,
        "reasoning": response.reasoning
    }
```

**è¿è¡Œè¯„ä¼°ï¼š**

```python
from langsmith import Client

client = Client()

# åˆ›å»ºæ•°æ®é›†
dataset_name = "scoping_quality"
dataset = client.create_dataset(dataset_name, description="Scoping è´¨é‡è¯„ä¼°")

# æ·»åŠ æµ‹è¯•ç”¨ä¾‹
client.create_examples(
    dataset_id=dataset.id,
    examples=[
        {
            "inputs": {"messages": conversation_1},
            "outputs": {"criteria": ["å½“å‰å¹´é¾„ 25", "ç›®æ ‡é€€ä¼‘å¹´é¾„ 45", "é«˜é£é™©æ‰¿å—", ...]}
        }
    ]
)

# è¿è¡Œè¯„ä¼°
client.evaluate(
    lambda inputs: scope.invoke(inputs),
    data=dataset_name,
    evaluators=[evaluate_success_criteria, evaluate_no_assumptions],
    experiment_prefix="Scoping Quality"
)
```

---

## ğŸ“– æ‰©å±•é˜…è¯»

- [LangGraph Scoping å®˜æ–¹æŒ‡å—](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/)
- [Structured Output æ–‡æ¡£](https://python.langchain.com/docs/how_to/structured_output/)
- [Command å¯¹è±¡è¯¦è§£](https://langchain-ai.github.io/langgraph/how-tos/graph-api/#combine-control-flow-and-state-updates-with-command)
- [LLM-as-judge æœ€ä½³å®è·µ](https://hamel.dev/blog/posts/llm-judge/)

---

## ğŸ‰ æ€»ç»“

Scoping æ˜¯ Deep Research çš„å…³é”®ç¬¬ä¸€æ­¥ï¼š

1. **æ™ºèƒ½æ¾„æ¸…** - ä½¿ç”¨ Structured Output å¯é åˆ¤æ–­æ˜¯å¦éœ€è¦æé—®
2. **Command æ§åˆ¶æµ** - çµæ´»è·¯ç”±åˆ°ä¸åŒèŠ‚ç‚¹
3. **ç ”ç©¶ç®€æŠ¥ç”Ÿæˆ** - å°†å¯¹è¯è½¬åŒ–ä¸ºç»“æ„åŒ–è§„åˆ’
4. **è¯„ä¼°é©±åŠ¨** - ä½¿ç”¨ LLM-as-judge æŒç»­æ”¹è¿›è´¨é‡

**æ ¸å¿ƒæŠ€å·§ï¼š**
- `ClarifyWithUser` Schema ç¡®ä¿å¯é å†³ç­–
- `Command` å¯¹è±¡å®ç°åŠ¨æ€è·¯ç”±
- `get_buffer_string` æ ¼å¼åŒ–æ¶ˆæ¯å†å²
- è¯„ä¼°å™¨éªŒè¯ç®€æŠ¥è´¨é‡

é€šè¿‡ Scopingï¼Œæˆ‘ä»¬é¿å…äº†åŸºäºæ¨¡ç³Šéœ€æ±‚è¿›è¡Œç ”ç©¶çš„é™·é˜±ï¼Œä¸ºåç»­çš„æ·±åº¦ç ”ç©¶æ‰“ä¸‹åšå®åŸºç¡€ï¼

ğŸ¯ **ä¸‹ä¸€æ­¥ï¼š** è®©æˆ‘ä»¬ç»§ç»­åˆ° **9.2 ç ”ç©¶æ™ºèƒ½ä½“åŸºç¡€** â€” å­¦ä¹ å¦‚ä½•æ„å»ºèƒ½è‡ªä¸»æœç´¢ã€åæ€ã€å†³ç­–çš„ç ”ç©¶ Agentï¼
