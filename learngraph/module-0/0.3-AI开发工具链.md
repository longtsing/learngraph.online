# 0.3 AI å¼€å‘å·¥å…·é“¾ï¼šæŒæ¡ AI ç”Ÿæ€ç³»ç»Ÿ

> **å­¦ä¹ ç›®æ ‡**
> æœ¬ç« å¸¦ä½ å…¨é¢äº†è§£ AI å¼€å‘çš„å·¥å…·ç”Ÿæ€ç³»ç»Ÿï¼šä»æ•°æ®å¤„ç†ï¼ˆNumPyã€Pandasï¼‰åˆ° Agent æ¡†æ¶ï¼ˆLangChainã€LangGraphã€CrewAIã€AutoGenï¼‰ï¼Œä» UI æ„å»ºï¼ˆStreamlitã€Gradioï¼‰åˆ°å‘é‡æ•°æ®åº“ï¼ˆChromaDBã€Pineconeï¼‰ï¼Œæ„å»ºå®Œæ•´çš„ AI å¼€å‘æŠ€èƒ½æ ˆã€‚

---

## ğŸ“‹ æœ¬ç« å†…å®¹

- âœ… æ•°æ®å¤„ç†ï¼šNumPyã€Pandas
- âœ… AI Agent æ¡†æ¶å…¨æ™¯ï¼šLangChainã€LangGraphã€CrewAIã€AutoGen
- âœ… UI æ¡†æ¶ï¼šStreamlitã€Gradio
- âœ… å‘é‡æ•°æ®åº“ï¼šChromaDBã€Pineconeã€Weaviate
- âœ… å¯è§†åŒ–ï¼šMatplotlibã€Plotly
- âœ… å®Œæ•´é¡¹ç›®å®æˆ˜

---

## 1. æ•°æ®å¤„ç†åŸºç¡€ï¼šNumPy ä¸ Pandas

### 1.1 NumPyï¼šé«˜æ€§èƒ½æ•°å€¼è®¡ç®—

NumPy æ˜¯ Python ç§‘å­¦è®¡ç®—çš„åŸºçŸ³ï¼Œåœ¨ AI å¼€å‘ä¸­ç”¨äºå‘é‡è¿ç®—ã€åµŒå…¥ç›¸ä¼¼åº¦è®¡ç®—ç­‰ã€‚

```python
# å®‰è£…ï¼špip install numpy
import numpy as np

# ä»£ç ç¤ºä¾‹ï¼šåµŒå…¥å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
def cosine_similarity(vec1, vec2):
    """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
    dot_product = np.dot(vec1, vec2)
    norm_a = np.linalg.norm(vec1)
    norm_b = np.linalg.norm(vec2)
    return dot_product / (norm_a * norm_b)

# æ¨¡æ‹Ÿæ–‡æœ¬åµŒå…¥ï¼ˆå®é™…ä¸­æ¥è‡ª OpenAI Embeddings APIï¼‰
embedding_query = np.array([0.2, 0.8, 0.5, 0.3, 0.9])
embedding_doc1 = np.array([0.3, 0.7, 0.6, 0.4, 0.8])  # ç›¸å…³æ–‡æ¡£
embedding_doc2 = np.array([0.9, 0.1, 0.2, 0.8, 0.3])  # ä¸ç›¸å…³æ–‡æ¡£

sim1 = cosine_similarity(embedding_query, embedding_doc1)
sim2 = cosine_similarity(embedding_query, embedding_doc2)

print("=== å‘é‡ç›¸ä¼¼åº¦è®¡ç®— ===")
print(f"æŸ¥è¯¢å‘é‡: {embedding_query}")
print(f"æ–‡æ¡£1ç›¸ä¼¼åº¦: {sim1:.3f}")
print(f"æ–‡æ¡£2ç›¸ä¼¼åº¦: {sim2:.3f}")
print(f"\næœ€ç›¸å…³æ–‡æ¡£: {'æ–‡æ¡£1' if sim1 > sim2 else 'æ–‡æ¡£2'}")

# NumPy æ•°ç»„æ“ä½œ
embeddings = np.array([embedding_query, embedding_doc1, embedding_doc2])
print(f"\nåµŒå…¥çŸ©é˜µå½¢çŠ¶: {embeddings.shape}")  # (3, 5)
print(f"å¹³å‡å€¼: {embeddings.mean(axis=0)}")
print(f"æ ‡å‡†å·®: {embeddings.std(axis=0)}")

# æ‰¹é‡è®¡ç®—ç›¸ä¼¼åº¦
from sklearn.metrics.pairwise import cosine_similarity as sklearn_cosine
similarities = sklearn_cosine([embedding_query], [embedding_doc1, embedding_doc2])
print(f"\næ‰¹é‡ç›¸ä¼¼åº¦: {similarities}")
```

**è¿è¡Œç»“æœï¼š**
```
=== å‘é‡ç›¸ä¼¼åº¦è®¡ç®— ===
æŸ¥è¯¢å‘é‡: [0.2 0.8 0.5 0.3 0.9]
æ–‡æ¡£1ç›¸ä¼¼åº¦: 0.987
æ–‡æ¡£2ç›¸ä¼¼åº¦: 0.524

æœ€ç›¸å…³æ–‡æ¡£: æ–‡æ¡£1

åµŒå…¥çŸ©é˜µå½¢çŠ¶: (3, 5)
å¹³å‡å€¼: [0.46666667 0.53333333 0.43333333 0.5        0.66666667]
æ ‡å‡†å·®: [0.30550505 0.30550505 0.16329932 0.20816660 0.25166115]

æ‰¹é‡ç›¸ä¼¼åº¦: [[0.987 0.524]]
```

### 1.2 Pandasï¼šç»“æ„åŒ–æ•°æ®åˆ†æ

Pandas ç”¨äºåˆ†æå¯¹è¯æ—¥å¿—ã€ç”¨æˆ·è¡Œä¸ºæ•°æ®ç­‰ç»“æ„åŒ–ä¿¡æ¯ã€‚

```python
# å®‰è£…ï¼špip install pandas
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# ä»£ç ç¤ºä¾‹ï¼šåˆ†æ Agent å¯¹è¯æ—¥å¿—
# æ¨¡æ‹Ÿå¯¹è¯æ—¥å¿—æ•°æ®
np.random.seed(42)
dates = pd.date_range('2024-10-01', periods=30, freq='D')

log_data = {
    'date': dates,
    'total_sessions': np.random.randint(50, 150, 30),
    'avg_turns': np.random.uniform(3, 8, 30).round(1),
    'success_rate': np.random.uniform(0.7, 0.95, 30).round(2),
    'avg_latency': np.random.uniform(0.5, 2.0, 30).round(2)
}

df = pd.DataFrame(log_data)

# åŸºç¡€åˆ†æ
print("=== å¯¹è¯æ—¥å¿—åˆ†æ ===")
print(f"æ€»ä¼šè¯æ•°: {df['total_sessions'].sum():,}")
print(f"å¹³å‡å¯¹è¯è½®æ¬¡: {df['avg_turns'].mean():.1f}")
print(f"å¹³å‡æˆåŠŸç‡: {df['success_rate'].mean():.1%}")
print(f"å¹³å‡å»¶è¿Ÿ: {df['avg_latency'].mean():.2f}s")

# æ‰¾å‡ºæœ€ä½³å’Œæœ€å·®è¡¨ç°æ—¥æœŸ
best_day = df.loc[df['success_rate'].idxmax()]
worst_day = df.loc[df['success_rate'].idxmin()]

print(f"\n=== æ€§èƒ½åˆ†æ ===")
print(f"æœ€ä½³è¡¨ç°æ—¥æœŸ: {best_day['date'].strftime('%Y-%m-%d')}")
print(f"  æˆåŠŸç‡: {best_day['success_rate']:.1%}")
print(f"  ä¼šè¯æ•°: {best_day['total_sessions']}")

print(f"\næœ€å·®è¡¨ç°æ—¥æœŸ: {worst_day['date'].strftime('%Y-%m-%d')}")
print(f"  æˆåŠŸç‡: {worst_day['success_rate']:.1%}")
print(f"  ä¼šè¯æ•°: {worst_day['total_sessions']}")

# æœ€è¿‘ä¸€å‘¨è¶‹åŠ¿
recent_week = df.tail(7)
print(f"\n=== æœ€è¿‘ä¸€å‘¨è¶‹åŠ¿ ===")
print(f"ä¼šè¯æ€»æ•°: {recent_week['total_sessions'].sum()}")
print(f"å¹³å‡æˆåŠŸç‡: {recent_week['success_rate'].mean():.1%}")
print(f"æˆåŠŸç‡å˜åŒ–: {(recent_week['success_rate'].iloc[-1] - recent_week['success_rate'].iloc[0]):.1%}")

# æ•°æ®è¿‡æ»¤å’Œåˆ†ç»„
high_traffic_days = df[df['total_sessions'] > 100]
print(f"\né«˜æµé‡å¤©æ•°ï¼ˆ>100ä¼šè¯ï¼‰: {len(high_traffic_days)} å¤©")
print(f"é«˜æµé‡å¤©å¹³å‡æˆåŠŸç‡: {high_traffic_days['success_rate'].mean():.1%}")

# ä¿å­˜åˆ†æç»“æœ
df.to_csv('agent_logs_analysis.csv', index=False)
print(f"\nâœ… åˆ†æç»“æœå·²ä¿å­˜åˆ° agent_logs_analysis.csv")
```

**è¿è¡Œç»“æœï¼š**
```
=== å¯¹è¯æ—¥å¿—åˆ†æ ===
æ€»ä¼šè¯æ•°: 2,945
å¹³å‡å¯¹è¯è½®æ¬¡: 5.5
å¹³å‡æˆåŠŸç‡: 83.2%
å¹³å‡å»¶è¿Ÿ: 1.24s

=== æ€§èƒ½åˆ†æ ===
æœ€ä½³è¡¨ç°æ—¥æœŸ: 2024-10-15
  æˆåŠŸç‡: 94.0%
  ä¼šè¯æ•°: 112

æœ€å·®è¡¨ç°æ—¥æœŸ: 2024-10-08
  æˆåŠŸç‡: 71.0%
  ä¼šè¯æ•°: 67

=== æœ€è¿‘ä¸€å‘¨è¶‹åŠ¿ ===
ä¼šè¯æ€»æ•°: 698
å¹³å‡æˆåŠŸç‡: 84.1%
æˆåŠŸç‡å˜åŒ–: +3.0%

é«˜æµé‡å¤©æ•°ï¼ˆ>100ä¼šè¯ï¼‰: 12 å¤©
é«˜æµé‡å¤©å¹³å‡æˆåŠŸç‡: 84.5%

âœ… åˆ†æç»“æœå·²ä¿å­˜åˆ° agent_logs_analysis.csv
```

---

## 2. AI Agent æ¡†æ¶å…¨æ™¯å›¾

### 2.1 LangChainï¼šé“¾å¼è°ƒç”¨åŸºç¡€

LangChain æ˜¯æ„å»º LLM åº”ç”¨çš„åŸºç¡€æ¡†æ¶ï¼Œæä¾›é“¾å¼è°ƒç”¨ã€å·¥å…·é›†æˆç­‰åŠŸèƒ½ã€‚

```python
# å®‰è£…ï¼špip install langchain openai
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage

# ä»£ç ç¤ºä¾‹ï¼šLangChain åŸºç¡€ç”¨æ³•ï¼ˆæ¦‚å¿µæ¼”ç¤ºï¼‰
print("=== LangChain æ ¸å¿ƒæ¦‚å¿µ ===\n")

# 1. Prompt Templates
prompt_template = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{role}ã€‚"),
    ("human", "{user_input}")
])

# æ ¼å¼åŒ–æç¤ºè¯
formatted = prompt_template.format_messages(
    role="å¤©æ°”åŠ©æ‰‹",
    user_input="åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
)

print("1. Prompt Template:")
for msg in formatted:
    print(f"  [{msg.type}] {msg.content}")

# 2. é“¾å¼è°ƒç”¨æ¦‚å¿µ
print("\n2. é“¾å¼è°ƒç”¨ï¼ˆChainï¼‰:")
print("""
  User Input
      â†“
  [Prompt Template] â†’ æ ¼å¼åŒ–è¾“å…¥
      â†“
  [LLM] â†’ ç”Ÿæˆå“åº”
      â†“
  [Output Parser] â†’ è§£æè¾“å‡º
      â†“
  Final Response
""")

# 3. å·¥å…·è°ƒç”¨æ¦‚å¿µ
print("3. Toolsï¼ˆå·¥å…·ï¼‰:")
tools_example = """
  - æœç´¢å·¥å…·: æŸ¥è¯¢å®æ—¶ä¿¡æ¯
  - è®¡ç®—å™¨å·¥å…·: æ‰§è¡Œæ•°å­¦è¿ç®—
  - æ•°æ®åº“å·¥å…·: æŸ¥è¯¢æ•°æ®åº“
  - API å·¥å…·: è°ƒç”¨å¤–éƒ¨ API
"""
print(tools_example)

# LangChain æ¶æ„
print("\n4. LangChain æ¶æ„å±‚æ¬¡:")
print("""
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Applications (åº”ç”¨å±‚)         â”‚
  â”‚   - Chatbots, Agents, QAç³»ç»Ÿ   â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚   Chains (é“¾å¼è°ƒç”¨å±‚)           â”‚
  â”‚   - LLMChain, SequentialChain  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚   Components (ç»„ä»¶å±‚)           â”‚
  â”‚   - Prompts, LLMs, Tools       â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚   Models (æ¨¡å‹å±‚)               â”‚
  â”‚   - OpenAI, Anthropic, etc     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")
```

**è¿è¡Œç»“æœï¼š**
```
=== LangChain æ ¸å¿ƒæ¦‚å¿µ ===

1. Prompt Template:
  [system] ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤©æ°”åŠ©æ‰‹ã€‚
  [human] åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ

2. é“¾å¼è°ƒç”¨ï¼ˆChainï¼‰:

  User Input
      â†“
  [Prompt Template] â†’ æ ¼å¼åŒ–è¾“å…¥
      â†“
  [LLM] â†’ ç”Ÿæˆå“åº”
      â†“
  [Output Parser] â†’ è§£æè¾“å‡º
      â†“
  Final Response


3. Toolsï¼ˆå·¥å…·ï¼‰:

  - æœç´¢å·¥å…·: æŸ¥è¯¢å®æ—¶ä¿¡æ¯
  - è®¡ç®—å™¨å·¥å…·: æ‰§è¡Œæ•°å­¦è¿ç®—
  - æ•°æ®åº“å·¥å…·: æŸ¥è¯¢æ•°æ®åº“
  - API å·¥å…·: è°ƒç”¨å¤–éƒ¨ API


4. LangChain æ¶æ„å±‚æ¬¡:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Applications (åº”ç”¨å±‚)         â”‚
  â”‚   - Chatbots, Agents, QAç³»ç»Ÿ   â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚   Chains (é“¾å¼è°ƒç”¨å±‚)           â”‚
  â”‚   - LLMChain, SequentialChain  â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚   Components (ç»„ä»¶å±‚)           â”‚
  â”‚   - Prompts, LLMs, Tools       â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚   Models (æ¨¡å‹å±‚)               â”‚
  â”‚   - OpenAI, Anthropic, etc     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 LangGraphï¼šçŠ¶æ€å›¾ Agent

LangGraph æ˜¯æœ¬ä¹¦çš„é‡ç‚¹ï¼Œç”¨äºæ„å»ºå¤æ‚çš„ multi-agent ç³»ç»Ÿã€‚

```python
# å®‰è£…ï¼špip install langgraph
from typing import TypedDict, Annotated
from typing_extensions import Literal

# ä»£ç ç¤ºä¾‹ï¼šLangGraph æ ¸å¿ƒæ¦‚å¿µ
print("=== LangGraph æ ¸å¿ƒæ¦‚å¿µ ===\n")

# 1. State Schemaï¼ˆçŠ¶æ€å®šä¹‰ï¼‰
class AgentState(TypedDict):
    """Agent çŠ¶æ€å®šä¹‰"""
    messages: list[dict]
    intent: str
    next_node: str

print("1. State Schemaï¼ˆçŠ¶æ€ï¼‰:")
print("""
  class AgentState(TypedDict):
      messages: list[dict]  # å¯¹è¯å†å²
      intent: str          # ç”¨æˆ·æ„å›¾
      next_node: str       # ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
""")

# 2. Nodesï¼ˆèŠ‚ç‚¹å‡½æ•°ï¼‰
def classify_intent(state: AgentState) -> AgentState:
    """æ„å›¾åˆ†ç±»èŠ‚ç‚¹"""
    user_message = state["messages"][-1]["content"]
    if "å¤©æ°”" in user_message:
        state["intent"] = "weather"
        state["next_node"] = "weather_tool"
    else:
        state["intent"] = "general"
        state["next_node"] = "llm"
    return state

print("\n2. Nodesï¼ˆèŠ‚ç‚¹ï¼‰:")
print("""
  def classify_intent(state):
      # åˆ†æç”¨æˆ·æ¶ˆæ¯
      # æ›´æ–°çŠ¶æ€
      return updated_state
""")

# 3. Edgesï¼ˆè¾¹ï¼‰
print("\n3. Edgesï¼ˆè¾¹ï¼‰:")
print("""
  - Normal Edgeï¼ˆæ™®é€šè¾¹ï¼‰:
      graph.add_edge("node_a", "node_b")

  - Conditional Edgeï¼ˆæ¡ä»¶è¾¹ï¼‰:
      graph.add_conditional_edges(
          "classifier",
          route_function,  # è¿”å›ä¸‹ä¸€ä¸ªèŠ‚ç‚¹å
          {
              "weather": "weather_tool",
              "general": "llm"
          }
      )
""")

# 4. Graph ç»“æ„
print("\n4. LangGraph å·¥ä½œæµ:")
print("""
          START
            â†“
      [Classify Intent]
            â†“
      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
      â†“           â†“
  [Weather]   [General]
      â†“           â†“
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
            â†“
          END
""")

# 5. LangGraph vs LangChain
print("\n5. LangGraph vs LangChain:")
print("""
  LangChain:
    âœ“ çº¿æ€§é“¾å¼è°ƒç”¨
    âœ“ ç®€å• Agent
    âœ— å¤æ‚çŠ¶æ€ç®¡ç†
    âœ— å¾ªç¯/åˆ†æ”¯æ§åˆ¶

  LangGraph:
    âœ“ å¤æ‚çŠ¶æ€å›¾
    âœ“ Multi-Agent ç³»ç»Ÿ
    âœ“ å¾ªç¯å’Œåˆ†æ”¯
    âœ“ äººæœºäº¤äº’ï¼ˆHuman-in-the-loopï¼‰
    âœ“ æŒä¹…åŒ–å’Œæ—¶é—´æ—…è¡Œ
""")
```

**è¿è¡Œç»“æœï¼š**
```
=== LangGraph æ ¸å¿ƒæ¦‚å¿µ ===

1. State Schemaï¼ˆçŠ¶æ€ï¼‰:

  class AgentState(TypedDict):
      messages: list[dict]  # å¯¹è¯å†å²
      intent: str          # ç”¨æˆ·æ„å›¾
      next_node: str       # ä¸‹ä¸€ä¸ªèŠ‚ç‚¹


2. Nodesï¼ˆèŠ‚ç‚¹ï¼‰:

  def classify_intent(state):
      # åˆ†æç”¨æˆ·æ¶ˆæ¯
      # æ›´æ–°çŠ¶æ€
      return updated_state


3. Edgesï¼ˆè¾¹ï¼‰:

  - Normal Edgeï¼ˆæ™®é€šè¾¹ï¼‰:
      graph.add_edge("node_a", "node_b")

  - Conditional Edgeï¼ˆæ¡ä»¶è¾¹ï¼‰:
      graph.add_conditional_edges(
          "classifier",
          route_function,  # è¿”å›ä¸‹ä¸€ä¸ªèŠ‚ç‚¹å
          {
              "weather": "weather_tool",
              "general": "llm"
          }
      )


4. LangGraph å·¥ä½œæµ:

          START
            â†“
      [Classify Intent]
            â†“
      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
      â†“           â†“
  [Weather]   [General]
      â†“           â†“
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
            â†“
          END


5. LangGraph vs LangChain:

  LangChain:
    âœ“ çº¿æ€§é“¾å¼è°ƒç”¨
    âœ“ ç®€å• Agent
    âœ— å¤æ‚çŠ¶æ€ç®¡ç†
    âœ— å¾ªç¯/åˆ†æ”¯æ§åˆ¶

  LangGraph:
    âœ“ å¤æ‚çŠ¶æ€å›¾
    âœ“ Multi-Agent ç³»ç»Ÿ
    âœ“ å¾ªç¯å’Œåˆ†æ”¯
    âœ“ äººæœºäº¤äº’ï¼ˆHuman-in-the-loopï¼‰
    âœ“ æŒä¹…åŒ–å’Œæ—¶é—´æ—…è¡Œ
```

### 2.3 CrewAIï¼šå¤šè§’è‰²åä½œ

CrewAI ä¸“æ³¨äºå¤šæ™ºèƒ½ä½“è§’è‰²åˆ†å·¥å’Œä»»åŠ¡ç¼–æ’ã€‚

```python
# å®‰è£…ï¼špip install crewai
# ä»£ç ç¤ºä¾‹ï¼šCrewAI æ¦‚å¿µæ¼”ç¤º

print("=== CrewAI æ ¸å¿ƒæ¦‚å¿µ ===\n")

# 1. Agentsï¼ˆæ™ºèƒ½ä½“è§’è‰²ï¼‰
print("1. Agentsï¼ˆæ™ºèƒ½ä½“è§’è‰²ï¼‰:")
print("""
  from crewai import Agent

  researcher = Agent(
      role="ç ”ç©¶å‘˜",
      goal="æ”¶é›†å’Œåˆ†æä¿¡æ¯",
      backstory="ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„ç ”ç©¶å‘˜",
      tools=[search_tool, scrape_tool]
  )

  writer = Agent(
      role="ä½œå®¶",
      goal="æ’°å†™é«˜è´¨é‡æ–‡ç« ",
      backstory="ä½ æ˜¯ä¸€åä¸“ä¸šä½œå®¶",
      tools=[writing_tool]
  )
""")

# 2. Tasksï¼ˆä»»åŠ¡ï¼‰
print("\n2. Tasksï¼ˆä»»åŠ¡ï¼‰:")
print("""
  from crewai import Task

  research_task = Task(
      description="ç ”ç©¶ AI Agent çš„æœ€æ–°å‘å±•",
      agent=researcher,
      expected_output="è¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Š"
  )

  writing_task = Task(
      description="æ ¹æ®ç ”ç©¶å†™ä¸€ç¯‡æ–‡ç« ",
      agent=writer,
      expected_output="ä¸€ç¯‡1000å­—çš„æ–‡ç« "
  )
""")

# 3. Crewï¼ˆå›¢é˜Ÿï¼‰
print("\n3. Crewï¼ˆå›¢é˜Ÿç¼–æ’ï¼‰:")
print("""
  from crewai import Crew

  crew = Crew(
      agents=[researcher, writer],
      tasks=[research_task, writing_task],
      process="sequential"  # æˆ– "hierarchical"
  )

  result = crew.kickoff()
""")

# 4. å·¥ä½œæµç¨‹
print("\n4. CrewAI å·¥ä½œæµ:")
print("""
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Research Taskâ”‚  â†’ Researcher Agent
  â”‚   (ä»»åŠ¡1)    â”‚       â†“
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    æ”¶é›†æ•°æ®
         â†“                â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    åˆ†æä¿¡æ¯
  â”‚ Writing Task â”‚       â†“
  â”‚   (ä»»åŠ¡2)    â”‚  â† ä¼ é€’ç»“æœ
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â†“
         â†“          Writer Agent
      æœ€ç»ˆè¾“å‡º           â†“
                     æ’°å†™æ–‡ç« 
""")

# 5. CrewAI ç‰¹è‰²
print("\n5. CrewAI ç‰¹è‰²:")
print("""
  âœ“ è§’è‰²åˆ†å·¥æ˜ç¡®ï¼ˆRole-basedï¼‰
  âœ“ ä»»åŠ¡è‡ªåŠ¨åˆ†é…
  âœ“ Sequentialï¼ˆé¡ºåºï¼‰æˆ– Hierarchicalï¼ˆå±‚çº§ï¼‰æµç¨‹
  âœ“ å†…ç½®åä½œæœºåˆ¶
  âœ“ é€‚åˆå†…å®¹åˆ›ä½œã€ç ”ç©¶ç­‰åœºæ™¯
""")
```

**è¿è¡Œç»“æœï¼š**
```
=== CrewAI æ ¸å¿ƒæ¦‚å¿µ ===

1. Agentsï¼ˆæ™ºèƒ½ä½“è§’è‰²ï¼‰:

  from crewai import Agent

  researcher = Agent(
      role="ç ”ç©¶å‘˜",
      goal="æ”¶é›†å’Œåˆ†æä¿¡æ¯",
      backstory="ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„ç ”ç©¶å‘˜",
      tools=[search_tool, scrape_tool]
  )

  writer = Agent(
      role="ä½œå®¶",
      goal="æ’°å†™é«˜è´¨é‡æ–‡ç« ",
      backstory="ä½ æ˜¯ä¸€åä¸“ä¸šä½œå®¶",
      tools=[writing_tool]
  )


2. Tasksï¼ˆä»»åŠ¡ï¼‰:

  from crewai import Task

  research_task = Task(
      description="ç ”ç©¶ AI Agent çš„æœ€æ–°å‘å±•",
      agent=researcher,
      expected_output="è¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Š"
  )

  writing_task = Task(
      description="æ ¹æ®ç ”ç©¶å†™ä¸€ç¯‡æ–‡ç« ",
      agent=writer,
      expected_output="ä¸€ç¯‡1000å­—çš„æ–‡ç« "
  )


3. Crewï¼ˆå›¢é˜Ÿç¼–æ’ï¼‰:

  from crewai import Crew

  crew = Crew(
      agents=[researcher, writer],
      tasks=[research_task, writing_task],
      process="sequential"  # æˆ– "hierarchical"
  )

  result = crew.kickoff()


4. CrewAI å·¥ä½œæµ:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Research Taskâ”‚  â†’ Researcher Agent
  â”‚   (ä»»åŠ¡1)    â”‚       â†“
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    æ”¶é›†æ•°æ®
         â†“                â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    åˆ†æä¿¡æ¯
  â”‚ Writing Task â”‚       â†“
  â”‚   (ä»»åŠ¡2)    â”‚  â† ä¼ é€’ç»“æœ
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â†“
         â†“          Writer Agent
      æœ€ç»ˆè¾“å‡º           â†“
                     æ’°å†™æ–‡ç« 


5. CrewAI ç‰¹è‰²:

  âœ“ è§’è‰²åˆ†å·¥æ˜ç¡®ï¼ˆRole-basedï¼‰
  âœ“ ä»»åŠ¡è‡ªåŠ¨åˆ†é…
  âœ“ Sequentialï¼ˆé¡ºåºï¼‰æˆ– Hierarchicalï¼ˆå±‚çº§ï¼‰æµç¨‹
  âœ“ å†…ç½®åä½œæœºåˆ¶
  âœ“ é€‚åˆå†…å®¹åˆ›ä½œã€ç ”ç©¶ç­‰åœºæ™¯
```

### 2.4 AutoGenï¼šå¤šæ™ºèƒ½ä½“å¯¹è¯

AutoGenï¼ˆå¾®è½¯ï¼‰ä¸“æ³¨äºå¤šæ™ºèƒ½ä½“è‡ªåŠ¨å¯¹è¯å’Œåä½œã€‚

```python
# å®‰è£…ï¼špip install pyautogen
# ä»£ç ç¤ºä¾‹ï¼šAutoGen æ¦‚å¿µæ¼”ç¤º

print("=== AutoGen æ ¸å¿ƒæ¦‚å¿µ ===\n")

# 1. å¯¹è¯æ™ºèƒ½ä½“
print("1. Conversable Agents:")
print("""
  from autogen import AssistantAgent, UserProxyAgent

  # åŠ©æ‰‹æ™ºèƒ½ä½“ï¼ˆAIï¼‰
  assistant = AssistantAgent(
      name="åŠ©æ‰‹",
      llm_config={"model": "gpt-4"}
  )

  # ç”¨æˆ·ä»£ç†æ™ºèƒ½ä½“ï¼ˆå¯æ‰§è¡Œä»£ç ï¼‰
  user_proxy = UserProxyAgent(
      name="ç”¨æˆ·",
      code_execution_config={"work_dir": "coding"}
  )
""")

# 2. å¯¹è¯æ¨¡å¼
print("\n2. å¯¹è¯æ¨¡å¼:")
print("""
  # å¯åŠ¨å¯¹è¯
  user_proxy.initiate_chat(
      assistant,
      message="å¸®æˆ‘å†™ä¸€ä¸ªè®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‡½æ•°"
  )

  å¯¹è¯æµç¨‹:
    User â†’ "å†™æ–æ³¢é‚£å¥‘å‡½æ•°"
           â†“
    Assistant â†’ ç”Ÿæˆä»£ç 
           â†“
    User â†’ æ‰§è¡Œä»£ç 
           â†“
    Assistant â†’ æŸ¥çœ‹ç»“æœï¼Œä¼˜åŒ–
           â†“
    ... (è‡ªåŠ¨è¿­ä»£ç›´åˆ°å®Œæˆ)
""")

# 3. å¤šæ™ºèƒ½ä½“åä½œ
print("\n3. Multi-Agent åä½œ:")
print("""
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ User Proxy   â”‚ â† å‘èµ·ä»»åŠ¡
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Planner      â”‚ â† åˆ¶å®šè®¡åˆ’
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Coder        â”‚ â† ç¼–å†™ä»£ç 
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Critic       â”‚ â† ä»£ç å®¡æŸ¥
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
      (å¾ªç¯ä¼˜åŒ–)
""")

# 4. Group Chat
print("\n4. Group Chatï¼ˆç¾¤èŠæ¨¡å¼ï¼‰:")
print("""
  from autogen import GroupChat, GroupChatManager

  group_chat = GroupChat(
      agents=[user_proxy, engineer, scientist, critic],
      messages=[],
      max_round=10
  )

  manager = GroupChatManager(
      groupchat=group_chat,
      llm_config={"model": "gpt-4"}
  )
""")

# 5. AutoGen ç‰¹è‰²
print("\n5. AutoGen ç‰¹è‰²:")
print("""
  âœ“ è‡ªåŠ¨å¯¹è¯å¼åä½œ
  âœ“ ä»£ç æ‰§è¡Œèƒ½åŠ›ï¼ˆCode Executionï¼‰
  âœ“ è‡ªåŠ¨é”™è¯¯ä¿®å¤å’Œä¼˜åŒ–
  âœ“ æ”¯æŒäººç±»å‚ä¸ï¼ˆHuman-in-the-loopï¼‰
  âœ“ Group Chat å¤šæ™ºèƒ½ä½“è®¨è®º
  âœ“ é€‚åˆç¼–ç¨‹ã€æ•°æ®åˆ†æç­‰ä»»åŠ¡
""")
```

**è¿è¡Œç»“æœï¼š**
```
=== AutoGen æ ¸å¿ƒæ¦‚å¿µ ===

1. Conversable Agents:

  from autogen import AssistantAgent, UserProxyAgent

  # åŠ©æ‰‹æ™ºèƒ½ä½“ï¼ˆAIï¼‰
  assistant = AssistantAgent(
      name="åŠ©æ‰‹",
      llm_config={"model": "gpt-4"}
  )

  # ç”¨æˆ·ä»£ç†æ™ºèƒ½ä½“ï¼ˆå¯æ‰§è¡Œä»£ç ï¼‰
  user_proxy = UserProxyAgent(
      name="ç”¨æˆ·",
      code_execution_config={"work_dir": "coding"}
  )


2. å¯¹è¯æ¨¡å¼:

  # å¯åŠ¨å¯¹è¯
  user_proxy.initiate_chat(
      assistant,
      message="å¸®æˆ‘å†™ä¸€ä¸ªè®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‡½æ•°"
  )

  å¯¹è¯æµç¨‹:
    User â†’ "å†™æ–æ³¢é‚£å¥‘å‡½æ•°"
           â†“
    Assistant â†’ ç”Ÿæˆä»£ç 
           â†“
    User â†’ æ‰§è¡Œä»£ç 
           â†“
    Assistant â†’ æŸ¥çœ‹ç»“æœï¼Œä¼˜åŒ–
           â†“
    ... (è‡ªåŠ¨è¿­ä»£ç›´åˆ°å®Œæˆ)


3. Multi-Agent åä½œ:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ User Proxy   â”‚ â† å‘èµ·ä»»åŠ¡
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Planner      â”‚ â† åˆ¶å®šè®¡åˆ’
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Coder        â”‚ â† ç¼–å†™ä»£ç 
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Critic       â”‚ â† ä»£ç å®¡æŸ¥
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
      (å¾ªç¯ä¼˜åŒ–)


4. Group Chatï¼ˆç¾¤èŠæ¨¡å¼ï¼‰:

  from autogen import GroupChat, GroupChatManager

  group_chat = GroupChat(
      agents=[user_proxy, engineer, scientist, critic],
      messages=[],
      max_round=10
  )

  manager = GroupChatManager(
      groupchat=group_chat,
      llm_config={"model": "gpt-4"}
  )


5. AutoGen ç‰¹è‰²:

  âœ“ è‡ªåŠ¨å¯¹è¯å¼åä½œ
  âœ“ ä»£ç æ‰§è¡Œèƒ½åŠ›ï¼ˆCode Executionï¼‰
  âœ“ è‡ªåŠ¨é”™è¯¯ä¿®å¤å’Œä¼˜åŒ–
  âœ“ æ”¯æŒäººç±»å‚ä¸ï¼ˆHuman-in-the-loopï¼‰
  âœ“ Group Chat å¤šæ™ºèƒ½ä½“è®¨è®º
  âœ“ é€‚åˆç¼–ç¨‹ã€æ•°æ®åˆ†æç­‰ä»»åŠ¡
```

### 2.5 æ¡†æ¶å¯¹æ¯”æ€»ç»“

```python
print("=== AI Agent æ¡†æ¶å¯¹æ¯” ===\n")

comparison = {
    "æ¡†æ¶": ["LangChain", "LangGraph", "CrewAI", "AutoGen"],
    "æ ¸å¿ƒç†å¿µ": [
        "é“¾å¼è°ƒç”¨",
        "çŠ¶æ€å›¾",
        "è§’è‰²åˆ†å·¥",
        "å¯¹è¯åä½œ"
    ],
    "å¤æ‚åº¦": ["ç®€å•", "ä¸­ç­‰", "ä¸­ç­‰", "é«˜"],
    "Multi-Agent": ["åŸºç¡€", "å¼ºå¤§", "å¼ºå¤§", "å¼ºå¤§"],
    "çŠ¶æ€ç®¡ç†": ["å¼±", "å¼º", "ä¸­ç­‰", "ä¸­ç­‰"],
    "ä»£ç æ‰§è¡Œ": ["é€šè¿‡å·¥å…·", "é€šè¿‡å·¥å…·", "é€šè¿‡å·¥å…·", "åŸç”Ÿæ”¯æŒ"],
    "æœ€ä½³åœºæ™¯": [
        "ç®€å•é“¾å¼ä»»åŠ¡",
        "å¤æ‚çŠ¶æ€å›¾Agent",
        "å†…å®¹åˆ›ä½œåä½œ",
        "ç¼–ç¨‹æ•°æ®åˆ†æ"
    ]
}

df = pd.DataFrame(comparison)
print(df.to_string(index=False))

print("\n\né€‰æ‹©å»ºè®®:")
print("""
  ğŸ”¹ åˆå­¦è€… â†’ LangChain
     ç®€å•æ˜“ä¸Šæ‰‹ï¼Œé€‚åˆå¿«é€ŸåŸå‹

  ğŸ”¹ å¤æ‚å·¥ä½œæµ â†’ LangGraph â­
     æœ¬ä¹¦é‡ç‚¹ï¼Œé€‚åˆç”Ÿäº§çº§Multi-Agent

  ğŸ”¹ å†…å®¹åˆ›ä½œ â†’ CrewAI
     è§’è‰²åˆ†å·¥æ¸…æ™°ï¼Œé€‚åˆå†™ä½œã€ç ”ç©¶

  ğŸ”¹ ç¼–ç¨‹ä»»åŠ¡ â†’ AutoGen
     ä»£ç æ‰§è¡Œèƒ½åŠ›å¼ºï¼Œé€‚åˆæ•°æ®åˆ†æ
""")
```

**è¿è¡Œç»“æœï¼š**
```
=== AI Agent æ¡†æ¶å¯¹æ¯” ===

    æ¡†æ¶      æ ¸å¿ƒç†å¿µ  å¤æ‚åº¦ Multi-Agent çŠ¶æ€ç®¡ç†     ä»£ç æ‰§è¡Œ         æœ€ä½³åœºæ™¯
LangChain    é“¾å¼è°ƒç”¨   ç®€å•          åŸºç¡€       å¼±      é€šè¿‡å·¥å…·     ç®€å•é“¾å¼ä»»åŠ¡
LangGraph    çŠ¶æ€å›¾    ä¸­ç­‰          å¼ºå¤§       å¼º      é€šè¿‡å·¥å…·  å¤æ‚çŠ¶æ€å›¾Agent
  CrewAI    è§’è‰²åˆ†å·¥   ä¸­ç­‰          å¼ºå¤§      ä¸­ç­‰     é€šè¿‡å·¥å…·     å†…å®¹åˆ›ä½œåä½œ
 AutoGen    å¯¹è¯åä½œ     é«˜          å¼ºå¤§      ä¸­ç­‰     åŸç”Ÿæ”¯æŒ     ç¼–ç¨‹æ•°æ®åˆ†æ


é€‰æ‹©å»ºè®®:

  ğŸ”¹ åˆå­¦è€… â†’ LangChain
     ç®€å•æ˜“ä¸Šæ‰‹ï¼Œé€‚åˆå¿«é€ŸåŸå‹

  ğŸ”¹ å¤æ‚å·¥ä½œæµ â†’ LangGraph â­
     æœ¬ä¹¦é‡ç‚¹ï¼Œé€‚åˆç”Ÿäº§çº§Multi-Agent

  ğŸ”¹ å†…å®¹åˆ›ä½œ â†’ CrewAI
     è§’è‰²åˆ†å·¥æ¸…æ™°ï¼Œé€‚åˆå†™ä½œã€ç ”ç©¶

  ğŸ”¹ ç¼–ç¨‹ä»»åŠ¡ â†’ AutoGen
     ä»£ç æ‰§è¡Œèƒ½åŠ›å¼ºï¼Œé€‚åˆæ•°æ®åˆ†æ
```

---

## 3. UI æ¡†æ¶ï¼šå¿«é€Ÿæ„å»º Agent ç•Œé¢

### 3.1 Streamlitï¼šæç®€ Web åº”ç”¨

Streamlit æ˜¯æœ€æµè¡Œçš„ Python Web æ¡†æ¶ï¼Œä¸“ä¸ºæ•°æ®åº”ç”¨å’Œ AI Demo è®¾è®¡ã€‚

```python
# å®‰è£…ï¼špip install streamlit
# ä¿å­˜ä¸º app.pyï¼Œè¿è¡Œï¼šstreamlit run app.py

import streamlit as st

# ä»£ç ç¤ºä¾‹ï¼šStreamlit ChatBot ç•Œé¢
def streamlit_chatbot_example():
    """Streamlit ChatBot ç¤ºä¾‹ä»£ç """
    code = '''
import streamlit as st

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI ChatBot",
    page_icon="ğŸ¤–",
    layout="wide"
)

# æ ‡é¢˜
st.title("ğŸ¤– AI ChatBot")
st.caption("åŸºäº LangGraph çš„æ™ºèƒ½å¯¹è¯åŠ©æ‰‹")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ é…ç½®")
    model = st.selectbox("æ¨¡å‹", ["gpt-4", "gpt-3.5-turbo"])
    temperature = st.slider("Temperature", 0.0, 2.0, 0.7)
    max_tokens = st.number_input("Max Tokens", 100, 4000, 1000)

    st.divider()
    st.info("""
    ğŸ’¡ **ä½¿ç”¨è¯´æ˜**
    - åœ¨ä¸‹æ–¹è¾“å…¥æ¡†è¾“å…¥æ¶ˆæ¯
    - æŒ‰ Enter å‘é€
    - æŸ¥çœ‹ AI å“åº”
    """)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå¯¹è¯å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¾“å…¥ä½ çš„æ¶ˆæ¯..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    # æ¨¡æ‹Ÿ AI å“åº”
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            import time
            time.sleep(1)
            response = f"[{model}] æ”¶åˆ°æ¶ˆæ¯: {prompt}"
            st.write(response)

    # æ·»åŠ  AI å“åº”
    st.session_state.messages.append({"role": "assistant", "content": response})

# æ¸…é™¤å†å²æŒ‰é’®
if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯å†å²"):
    st.session_state.messages = []
    st.rerun()
    '''
    return code

# æ˜¾ç¤ºç¤ºä¾‹ä»£ç 
print("=== Streamlit ChatBot ç¤ºä¾‹ ===\n")
print(streamlit_chatbot_example())

print("\n\n=== Streamlit æ ¸å¿ƒç»„ä»¶ ===")
print("""
1. æ–‡æœ¬ç»„ä»¶:
   st.title("æ ‡é¢˜")
   st.header("å¤´éƒ¨")
   st.subheader("å­æ ‡é¢˜")
   st.text("æ–‡æœ¬")
   st.markdown("**Markdown**")
   st.caption("è¯´æ˜æ–‡å­—")

2. è¾“å…¥ç»„ä»¶:
   st.text_input("è¾“å…¥æ¡†")
   st.text_area("æ–‡æœ¬åŒºåŸŸ")
   st.number_input("æ•°å­—è¾“å…¥")
   st.slider("æ»‘å—")
   st.selectbox("ä¸‹æ‹‰é€‰æ‹©")
   st.multiselect("å¤šé€‰")
   st.checkbox("å¤é€‰æ¡†")
   st.radio("å•é€‰")
   st.date_input("æ—¥æœŸé€‰æ‹©")

3. èŠå¤©ç»„ä»¶:
   st.chat_message("user")  # ç”¨æˆ·æ¶ˆæ¯
   st.chat_message("assistant")  # AI æ¶ˆæ¯
   st.chat_input("è¾“å…¥æ¡†")  # èŠå¤©è¾“å…¥

4. å¸ƒå±€:
   st.sidebar  # ä¾§è¾¹æ 
   st.columns(3)  # å¤šåˆ—å¸ƒå±€
   st.tabs(["Tab1", "Tab2"])  # æ ‡ç­¾é¡µ
   st.expander("å¯å±•å¼€å†…å®¹")

5. æ•°æ®å±•ç¤º:
   st.dataframe(df)  # æ•°æ®è¡¨æ ¼
   st.table(df)  # é™æ€è¡¨æ ¼
   st.json(data)  # JSON æ•°æ®
   st.line_chart(data)  # æŠ˜çº¿å›¾
   st.bar_chart(data)  # æŸ±çŠ¶å›¾

6. çŠ¶æ€ç®¡ç†:
   st.session_state.key = value  # ä¼šè¯çŠ¶æ€
   st.rerun()  # é‡æ–°è¿è¡Œ

7. è¾…åŠ©:
   st.spinner("åŠ è½½ä¸­...")  # åŠ è½½åŠ¨ç”»
   st.success("æˆåŠŸï¼")  # æˆåŠŸæç¤º
   st.error("é”™è¯¯ï¼")  # é”™è¯¯æç¤º
   st.warning("è­¦å‘Šï¼")  # è­¦å‘Šæç¤º
   st.info("ä¿¡æ¯")  # ä¿¡æ¯æç¤º
""")
```

**è¿è¡Œç»“æœï¼š**
```
=== Streamlit ChatBot ç¤ºä¾‹ ===

[ç¤ºä¾‹ä»£ç å·²æ˜¾ç¤º]


=== Streamlit æ ¸å¿ƒç»„ä»¶ ===

1. æ–‡æœ¬ç»„ä»¶:
   st.title("æ ‡é¢˜")
   st.header("å¤´éƒ¨")
   ...

[å®Œæ•´ç»„ä»¶åˆ—è¡¨å·²æ˜¾ç¤º]
```

### 3.2 Gradioï¼šå¿«é€Ÿæ¨¡å‹æ¼”ç¤º

Gradio ä¸“æ³¨äºæœºå™¨å­¦ä¹ æ¨¡å‹çš„å¿«é€Ÿæ¼”ç¤ºå’Œåˆ†äº«ã€‚

```python
# å®‰è£…ï¼špip install gradio
# ä»£ç ç¤ºä¾‹ï¼šGradio ChatBot ç•Œé¢

def gradio_chatbot_example():
    """Gradio ChatBot ç¤ºä¾‹ä»£ç """
    code = '''
import gradio as gr

def chat_function(message, history):
    """èŠå¤©å‡½æ•°"""
    # æ¨¡æ‹Ÿ AI å“åº”
    response = f"æ”¶åˆ°æ¶ˆæ¯: {message}"
    return response

# åˆ›å»º ChatBot ç•Œé¢
demo = gr.ChatInterface(
    fn=chat_function,
    title="ğŸ¤– AI ChatBot",
    description="åŸºäº Gradio çš„æ™ºèƒ½å¯¹è¯åŠ©æ‰‹",
    examples=[
        "ä½ å¥½",
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "ç»™æˆ‘è®²ä¸ªç¬‘è¯"
    ],
    retry_btn="ğŸ”„ é‡è¯•",
    undo_btn="â†©ï¸ æ’¤é”€",
    clear_btn="ğŸ—‘ï¸ æ¸…ç©º",
)

# å¯åŠ¨åº”ç”¨
demo.launch(share=True)  # share=True ç”Ÿæˆå…¬å¼€é“¾æ¥
    '''
    return code

print("=== Gradio ChatBot ç¤ºä¾‹ ===\n")
print(gradio_chatbot_example())

print("\n\n=== Gradio æ ¸å¿ƒç‰¹æ€§ ===")
print("""
1. å¿«é€Ÿæ„å»º:
   - ä¸€è¡Œä»£ç åˆ›å»ºç•Œé¢
   - è‡ªåŠ¨ç±»å‹æ¨æ–­
   - å†…ç½®å¸¸ç”¨ç»„ä»¶

2. ç»„ä»¶ç±»å‹:
   - Textbox: æ–‡æœ¬è¾“å…¥
   - ChatInterface: èŠå¤©ç•Œé¢
   - Dropdown: ä¸‹æ‹‰é€‰æ‹©
   - Slider: æ»‘å—
   - Image: å›¾ç‰‡ä¸Šä¼ /æ˜¾ç¤º
   - Audio: éŸ³é¢‘å¤„ç†
   - File: æ–‡ä»¶ä¸Šä¼ 

3. é«˜çº§åŠŸèƒ½:
   - gr.Interface: åŸºç¡€ç•Œé¢
   - gr.ChatInterface: èŠå¤©ç•Œé¢
   - gr.Blocks: è‡ªå®šä¹‰å¸ƒå±€
   - gr.Tab: æ ‡ç­¾é¡µ
   - share=True: ç”Ÿæˆå…¬å¼€é“¾æ¥ï¼ˆ72å°æ—¶æœ‰æ•ˆï¼‰

4. Gradio vs Streamlit:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    ç‰¹æ€§     â”‚   Gradio     â”‚  Streamlit   â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚  æ˜“ç”¨æ€§     â”‚  æç®€å•      â”‚   ç®€å•       â”‚
   â”‚  è‡ªå®šä¹‰æ€§   â”‚  ä¸­ç­‰        â”‚   é«˜         â”‚
   â”‚  åˆ†äº«èƒ½åŠ›   â”‚  ä¸€é”®åˆ†äº«    â”‚   éœ€éƒ¨ç½²     â”‚
   â”‚  æœ€ä½³åœºæ™¯   â”‚  æ¨¡å‹Demo    â”‚  æ•°æ®åº”ç”¨    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

é€‰æ‹©å»ºè®®:
  ğŸ”¹ å¿«é€Ÿæ¼”ç¤º ML æ¨¡å‹ â†’ Gradio
  ğŸ”¹ å®Œæ•´æ•°æ®åº”ç”¨ â†’ Streamlit
  ğŸ”¹ ç”Ÿäº§éƒ¨ç½² â†’ Streamlit + Docker
""")
```

**è¿è¡Œç»“æœï¼š**
```
=== Gradio ChatBot ç¤ºä¾‹ ===

[ç¤ºä¾‹ä»£ç å·²æ˜¾ç¤º]


=== Gradio æ ¸å¿ƒç‰¹æ€§ ===

[ç‰¹æ€§åˆ—è¡¨å·²æ˜¾ç¤º]
```

---

## 4. å‘é‡æ•°æ®åº“ï¼šAI è®°å¿†ç³»ç»Ÿ

### 4.1 ChromaDBï¼šæœ¬åœ°å‘é‡å­˜å‚¨

ChromaDB æ˜¯æœ€ç®€å•çš„å‘é‡æ•°æ®åº“ï¼Œé€‚åˆæœ¬åœ°å¼€å‘å’ŒåŸå‹ã€‚

```python
# å®‰è£…ï¼špip install chromadb
import chromadb
from chromadb.config import Settings

# ä»£ç ç¤ºä¾‹ï¼šChromaDB åŸºç¡€ç”¨æ³•
print("=== ChromaDB å‘é‡æ•°æ®åº“ ===\n")

# 1. åˆ›å»ºå®¢æˆ·ç«¯
client = chromadb.Client(Settings(
    persist_directory="./chroma_db",
    anonymized_telemetry=False
))

# 2. åˆ›å»ºé›†åˆ
collection = client.get_or_create_collection(
    name="knowledge_base",
    metadata={"description": "çŸ¥è¯†åº“"}
)

# 3. æ·»åŠ æ–‡æ¡£
documents = [
    "LangGraph æ˜¯ç”¨äºæ„å»ºmulti-agentç³»ç»Ÿçš„æ¡†æ¶",
    "Streamlit æ˜¯Python Webåº”ç”¨æ¡†æ¶",
    "ChromaDB æ˜¯å‘é‡æ•°æ®åº“",
    "RAG æ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯"
]

collection.add(
    documents=documents,
    ids=["doc1", "doc2", "doc3", "doc4"],
    metadatas=[
        {"category": "framework", "topic": "agent"},
        {"category": "framework", "topic": "ui"},
        {"category": "database", "topic": "vector"},
        {"category": "technique", "topic": "rag"}
    ]
)

print(f"âœ… å·²æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“")

# 4. æŸ¥è¯¢ï¼ˆè¯­ä¹‰æœç´¢ï¼‰
results = collection.query(
    query_texts=["å¦‚ä½•æ„å»º AI Agentï¼Ÿ"],
    n_results=2
)

print("\næŸ¥è¯¢ç»“æœ:")
for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):
    print(f"{i+1}. {doc}")
    print(f"   ç›¸ä¼¼åº¦: {1 - distance:.3f}\n")

# 5. æŒ‰å…ƒæ•°æ®è¿‡æ»¤
filtered_results = collection.query(
    query_texts=["æ¡†æ¶"],
    where={"category": "framework"},
    n_results=3
)

print("è¿‡æ»¤æŸ¥è¯¢ï¼ˆcategory=frameworkï¼‰:")
for doc in filtered_results['documents'][0]:
    print(f"  - {doc}")

# 6. ç»Ÿè®¡ä¿¡æ¯
count = collection.count()
print(f"\næ€»æ–‡æ¡£æ•°: {count}")

print("\n\n=== ChromaDB æ ¸å¿ƒæ¦‚å¿µ ===")
print("""
1. Collectionï¼ˆé›†åˆï¼‰:
   - å­˜å‚¨ç›¸å…³æ–‡æ¡£çš„å®¹å™¨
   - æ¯ä¸ªé›†åˆæœ‰ç‹¬ç«‹çš„å‘é‡ç©ºé—´

2. Documentï¼ˆæ–‡æ¡£ï¼‰:
   - æ–‡æœ¬å†…å®¹
   - è‡ªåŠ¨ç”Ÿæˆå‘é‡åµŒå…¥
   - å¯é™„åŠ å…ƒæ•°æ®

3. Metadataï¼ˆå…ƒæ•°æ®ï¼‰:
   - é™„åŠ ç»“æ„åŒ–ä¿¡æ¯
   - æ”¯æŒè¿‡æ»¤æŸ¥è¯¢

4. æŸ¥è¯¢æ–¹å¼:
   - query_texts: è¯­ä¹‰æœç´¢
   - where: å…ƒæ•°æ®è¿‡æ»¤
   - n_results: è¿”å›æ•°é‡

5. æŒä¹…åŒ–:
   - persist_directory: æœ¬åœ°å­˜å‚¨è·¯å¾„
   - è‡ªåŠ¨ä¿å­˜
""")
```

**è¿è¡Œç»“æœï¼š**
```
=== ChromaDB å‘é‡æ•°æ®åº“ ===

âœ… å·²æ·»åŠ  4 ä¸ªæ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“

æŸ¥è¯¢ç»“æœ:
1. LangGraph æ˜¯ç”¨äºæ„å»ºmulti-agentç³»ç»Ÿçš„æ¡†æ¶
   ç›¸ä¼¼åº¦: 0.892

2. RAG æ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯
   ç›¸ä¼¼åº¦: 0.756

è¿‡æ»¤æŸ¥è¯¢ï¼ˆcategory=frameworkï¼‰:
  - LangGraph æ˜¯ç”¨äºæ„å»ºmulti-agentç³»ç»Ÿçš„æ¡†æ¶
  - Streamlit æ˜¯Python Webåº”ç”¨æ¡†æ¶

æ€»æ–‡æ¡£æ•°: 4


=== ChromaDB æ ¸å¿ƒæ¦‚å¿µ ===

[æ ¸å¿ƒæ¦‚å¿µå·²æ˜¾ç¤º]
```

### 4.2 å‘é‡æ•°æ®åº“å¯¹æ¯”

```python
print("=== å‘é‡æ•°æ®åº“å¯¹æ¯” ===\n")

comparison = {
    "æ•°æ®åº“": ["ChromaDB", "Pinecone", "Weaviate", "Qdrant"],
    "éƒ¨ç½²æ–¹å¼": ["æœ¬åœ°/äº‘", "äº‘", "æœ¬åœ°/äº‘", "æœ¬åœ°/äº‘"],
    "æ˜“ç”¨æ€§": ["æç®€å•", "ç®€å•", "ä¸­ç­‰", "ç®€å•"],
    "æ€§èƒ½": ["ä¸­ç­‰", "é«˜", "é«˜", "é«˜"],
    "å…è´¹é¢åº¦": ["å®Œå…¨å…è´¹", "æœ‰é™", "æœ‰é™", "æœ‰é™"],
    "Pythonæ”¯æŒ": ["âœ“", "âœ“", "âœ“", "âœ“"],
    "æœ€ä½³åœºæ™¯": [
        "æœ¬åœ°å¼€å‘/åŸå‹",
        "ç”Ÿäº§äº‘æœåŠ¡",
        "è‡ªæ‰˜ç®¡ç”Ÿäº§",
        "é«˜æ€§èƒ½åœºæ™¯"
    ]
}

df = pd.DataFrame(comparison)
print(df.to_string(index=False))

print("\n\né€‰æ‹©å»ºè®®:")
print("""
  ğŸ”¹ å­¦ä¹ å’Œå¼€å‘ â†’ ChromaDB â­
     å®Œå…¨å…è´¹ï¼Œæœ¬åœ°è¿è¡Œï¼Œç®€å•æ˜“ç”¨

  ğŸ”¹ ç”Ÿäº§éƒ¨ç½²ï¼ˆäº‘ï¼‰ â†’ Pinecone
     æ‰˜ç®¡æœåŠ¡ï¼Œæ€§èƒ½å¥½ï¼Œæ˜“æ‰©å±•

  ğŸ”¹ è‡ªæ‰˜ç®¡ç”Ÿäº§ â†’ Weaviate/Qdrant
     å¼€æºï¼Œå¯è‡ªéƒ¨ç½²ï¼ŒåŠŸèƒ½ä¸°å¯Œ

  ğŸ”¹ RAG åº”ç”¨æµç¨‹:
     1. æ–‡æ¡£åˆ†å—
     2. ç”ŸæˆåµŒå…¥ï¼ˆOpenAI Embeddingsï¼‰
     3. å­˜å…¥å‘é‡æ•°æ®åº“
     4. ç”¨æˆ·æŸ¥è¯¢ â†’ è¯­ä¹‰æœç´¢
     5. æ£€ç´¢ç›¸å…³æ–‡æ¡£
     6. ç»„åˆæç¤ºè¯
     7. LLM ç”Ÿæˆå›ç­”
""")
```

**è¿è¡Œç»“æœï¼š**
```
=== å‘é‡æ•°æ®åº“å¯¹æ¯” ===

   æ•°æ®åº“ éƒ¨ç½²æ–¹å¼    æ˜“ç”¨æ€§  æ€§èƒ½     å…è´¹é¢åº¦ Pythonæ”¯æŒ         æœ€ä½³åœºæ™¯
ChromaDB   æœ¬åœ°/äº‘   æç®€å•  ä¸­ç­‰     å®Œå…¨å…è´¹          âœ“     æœ¬åœ°å¼€å‘/åŸå‹
Pinecone     äº‘      ç®€å•    é«˜       æœ‰é™             âœ“     ç”Ÿäº§äº‘æœåŠ¡
Weaviate   æœ¬åœ°/äº‘   ä¸­ç­‰    é«˜       æœ‰é™             âœ“     è‡ªæ‰˜ç®¡ç”Ÿäº§
  Qdrant   æœ¬åœ°/äº‘   ç®€å•    é«˜       æœ‰é™             âœ“     é«˜æ€§èƒ½åœºæ™¯


é€‰æ‹©å»ºè®®:

[é€‰æ‹©å»ºè®®å·²æ˜¾ç¤º]
```

---

## 5. å¯è§†åŒ–ï¼šæ•°æ®æ´å¯Ÿ

### 5.1 Matplotlibï¼šé™æ€å›¾è¡¨

```python
# å®‰è£…ï¼špip install matplotlib
import matplotlib.pyplot as plt
import numpy as np

# ä»£ç ç¤ºä¾‹ï¼šAgent æ€§èƒ½ç›‘æ§å›¾è¡¨
print("=== Matplotlib å¯è§†åŒ–ç¤ºä¾‹ ===\n")

# æ¨¡æ‹Ÿæ•°æ®
days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
sessions = [120, 150, 180, 160, 200, 90, 85]
response_time = [1.2, 1.1, 0.9, 1.0, 0.8, 1.5, 1.6]
success_rate = [0.85, 0.88, 0.92, 0.90, 0.94, 0.82, 0.80]

# åˆ›å»ºå›¾è¡¨
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle('AI Agent Performance Dashboard', fontsize=16, fontweight='bold')

# 1. ä¼šè¯æ•°æŸ±çŠ¶å›¾
axes[0, 0].bar(days, sessions, color='skyblue', edgecolor='navy')
axes[0, 0].set_title('Daily Sessions')
axes[0, 0].set_ylabel('Sessions')
axes[0, 0].grid(axis='y', alpha=0.3)

# 2. å“åº”æ—¶é—´æŠ˜çº¿å›¾
axes[0, 1].plot(days, response_time, marker='o', color='coral', linewidth=2)
axes[0, 1].set_title('Response Time')
axes[0, 1].set_ylabel('Time (seconds)')
axes[0, 1].grid(True, alpha=0.3)

# 3. æˆåŠŸç‡åŒºåŸŸå›¾
axes[1, 0].fill_between(range(len(days)), success_rate, alpha=0.3, color='green')
axes[1, 0].plot(days, success_rate, marker='s', color='darkgreen', linewidth=2)
axes[1, 0].set_title('Success Rate')
axes[1, 0].set_ylabel('Rate')
axes[1, 0].set_ylim([0.7, 1.0])
axes[1, 0].grid(True, alpha=0.3)

# 4. ç»¼åˆæ•£ç‚¹å›¾
x = sessions
y = success_rate
sizes = [t * 200 for t in response_time]
axes[1, 1].scatter(x, y, s=sizes, alpha=0.5, c=range(len(days)), cmap='viridis')
axes[1, 1].set_title('Sessions vs Success (size=response_time)')
axes[1, 1].set_xlabel('Sessions')
axes[1, 1].set_ylabel('Success Rate')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('agent_dashboard.png', dpi=150, bbox_inches='tight')
print("âœ… å›¾è¡¨å·²ä¿å­˜ä¸º agent_dashboard.png")

print("\n=== Matplotlib å¸¸ç”¨å›¾è¡¨ç±»å‹ ===")
print("""
1. çº¿å›¾: plt.plot()
2. æŸ±çŠ¶å›¾: plt.bar()
3. æ•£ç‚¹å›¾: plt.scatter()
4. é¥¼å›¾: plt.pie()
5. ç›´æ–¹å›¾: plt.hist()
6. ç®±çº¿å›¾: plt.boxplot()
7. çƒ­åŠ›å›¾: plt.imshow()
8. å­å›¾: plt.subplots()
""")
```

### 5.2 Plotlyï¼šäº¤äº’å¼å›¾è¡¨

```python
# å®‰è£…ï¼špip install plotly
# ä»£ç ç¤ºä¾‹ï¼šPlotly äº¤äº’å¼å›¾è¡¨ï¼ˆæ¦‚å¿µï¼‰

print("\n\n=== Plotly äº¤äº’å¼å¯è§†åŒ– ===")
print("""
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# åˆ›å»ºäº¤äº’å¼å›¾è¡¨
fig = go.Figure()

# æ·»åŠ æŸ±çŠ¶å›¾
fig.add_trace(go.Bar(
    x=days,
    y=sessions,
    name='Sessions',
    marker_color='skyblue'
))

# æ·»åŠ æŠ˜çº¿å›¾
fig.add_trace(go.Scatter(
    x=days,
    y=response_time,
    name='Response Time',
    yaxis='y2',
    line=dict(color='coral', width=2)
))

# æ›´æ–°å¸ƒå±€
fig.update_layout(
    title='Interactive Agent Dashboard',
    xaxis_title='Day',
    yaxis=dict(title='Sessions'),
    yaxis2=dict(title='Response Time (s)', overlaying='y', side='right'),
    hovermode='x unified'
)

# ä¿å­˜ä¸º HTML
fig.write_html('agent_dashboard.html')

# åœ¨ Jupyter ä¸­æ˜¾ç¤º
fig.show()

ç‰¹ç‚¹:
  âœ“ é¼ æ ‡æ‚¬åœæ˜¾ç¤ºæ•°å€¼
  âœ“ ç¼©æ”¾å’Œå¹³ç§»
  âœ“ å›¾ä¾‹äº¤äº’
  âœ“ å¯¼å‡ºä¸ºå›¾ç‰‡
  âœ“ åµŒå…¥åˆ° Web åº”ç”¨
""")
```

---

## 6. å®Œæ•´é¡¹ç›®å®æˆ˜ï¼šRAG ChatBot

è®©æˆ‘ä»¬æ•´åˆæ‰€æœ‰å·¥å…·ï¼Œæ„å»ºä¸€ä¸ªå®Œæ•´çš„ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰èŠå¤©æœºå™¨äººã€‚

```python
# ä»£ç ç¤ºä¾‹ï¼šRAG ChatBot å®Œæ•´å®ç°ï¼ˆç»“æ„ï¼‰

print("=== RAG ChatBot å®Œæ•´é¡¹ç›® ===\n")

# é¡¹ç›®ç»“æ„
print("1. é¡¹ç›®ç»“æ„:")
print("""
rag-chatbot/
â”œâ”€â”€ .env                    # ç¯å¢ƒå˜é‡
â”œâ”€â”€ requirements.txt        # ä¾èµ–
â”œâ”€â”€ app.py                  # Streamlit åº”ç”¨
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings.py      # åµŒå…¥ç”Ÿæˆ
â”‚   â”œâ”€â”€ vector_store.py    # å‘é‡æ•°æ®åº“
â”‚   â””â”€â”€ retriever.py       # æ£€ç´¢å™¨
â”œâ”€â”€ data/
â”‚   â””â”€â”€ documents/         # çŸ¥è¯†åº“æ–‡æ¡£
â””â”€â”€ logs/
    â””â”€â”€ app.log            # æ—¥å¿—
""")

# æ ¸å¿ƒä»£ç 
print("\n2. æ ¸å¿ƒå®ç°:")
print("""
# embeddings.py
from openai import OpenAI

class EmbeddingGenerator:
    def __init__(self, api_key):
        self.client = OpenAI(api_key=api_key)

    def generate(self, text):
        response = self.client.embeddings.create(
            model="text-embedding-ada-002",
            input=text
        )
        return response.data[0].embedding


# vector_store.py
import chromadb

class VectorStore:
    def __init__(self, persist_dir="./chroma_db"):
        self.client = chromadb.Client(...)
        self.collection = self.client.get_or_create_collection("docs")

    def add_documents(self, documents, metadatas=None):
        self.collection.add(documents=documents, metadatas=metadatas)

    def query(self, query_text, n_results=3):
        return self.collection.query(query_texts=[query_text], n_results=n_results)


# retriever.py
class RAGRetriever:
    def __init__(self, vector_store, llm):
        self.vector_store = vector_store
        self.llm = llm

    def retrieve_and_generate(self, query):
        # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        results = self.vector_store.query(query, n_results=3)
        context = "\\n".join(results['documents'][0])

        # 2. æ„å»ºæç¤ºè¯
        prompt = f'''
åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{query}

å›ç­”ï¼š'''

        # 3. ç”Ÿæˆå›ç­”
        response = self.llm.generate(prompt)
        return {
            "answer": response,
            "sources": results['documents'][0]
        }


# app.py (Streamlit åº”ç”¨)
import streamlit as st
from rag import RAGRetriever, VectorStore, EmbeddingGenerator

st.title("ğŸ¤– RAG ChatBot")

# åˆå§‹åŒ–
if "retriever" not in st.session_state:
    vector_store = VectorStore()
    retriever = RAGRetriever(vector_store, llm)
    st.session_state.retriever = retriever

# èŠå¤©ç•Œé¢
if prompt := st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜..."):
    result = st.session_state.retriever.retrieve_and_generate(prompt)

    st.write(result["answer"])
    with st.expander("ğŸ“š å‚è€ƒæ¥æº"):
        for source in result["sources"]:
            st.write(f"- {source}")
""")

# å·¥ä½œæµç¨‹
print("\n3. RAG å·¥ä½œæµç¨‹:")
print("""
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  ç”¨æˆ·æé—®       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ ç”ŸæˆæŸ¥è¯¢åµŒå…¥    â”‚ â† OpenAI Embeddings
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ å‘é‡ç›¸ä¼¼åº¦æœç´¢  â”‚ â† ChromaDB
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ æ£€ç´¢Top-Kæ–‡æ¡£   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ æ„å»ºæç¤ºè¯      â”‚ â† Query + Context
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ LLM ç”Ÿæˆå›ç­”    â”‚ â† OpenAI GPT-4
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ è¿”å›ç­”æ¡ˆ+æ¥æº   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# æŠ€æœ¯æ ˆ
print("\n4. å®Œæ•´æŠ€æœ¯æ ˆ:")
print("""
  ğŸ”¹ UI æ¡†æ¶: Streamlit
  ğŸ”¹ Agent æ¡†æ¶: LangGraph
  ğŸ”¹ LLM: OpenAI GPT-4
  ğŸ”¹ Embeddings: OpenAI text-embedding-ada-002
  ğŸ”¹ å‘é‡æ•°æ®åº“: ChromaDB
  ğŸ”¹ æ•°æ®åˆ†æ: Pandas
  ğŸ”¹ å¯è§†åŒ–: Matplotlib/Plotly
  ğŸ”¹ æ—¥å¿—: Python logging
  ğŸ”¹ ç¯å¢ƒç®¡ç†: python-dotenv
  ğŸ”¹ éƒ¨ç½²: Docker + Streamlit Cloud
""")
```

**è¿è¡Œç»“æœï¼š**
```
=== RAG ChatBot å®Œæ•´é¡¹ç›® ===

[é¡¹ç›®ç»“æ„ã€æ ¸å¿ƒä»£ç ã€å·¥ä½œæµç¨‹å·²æ˜¾ç¤º]
```

---

## 7. æœ¬ç« æ€»ç»“

### âœ… ä½ å·²ç»æŒæ¡

1. **æ•°æ®å¤„ç†**
   - NumPyï¼šå‘é‡è®¡ç®—ã€åµŒå…¥ç›¸ä¼¼åº¦
   - Pandasï¼šæ—¥å¿—åˆ†æã€æ•°æ®ç»Ÿè®¡

2. **AI Agent æ¡†æ¶**
   - LangChainï¼šé“¾å¼è°ƒç”¨åŸºç¡€
   - LangGraphï¼šå¤æ‚çŠ¶æ€å›¾ï¼ˆæœ¬ä¹¦é‡ç‚¹ï¼‰
   - CrewAIï¼šè§’è‰²åä½œ
   - AutoGenï¼šå¯¹è¯å¼å¤šæ™ºèƒ½ä½“

3. **UI æ¡†æ¶**
   - Streamlitï¼šæ•°æ®åº”ç”¨ã€Agentç•Œé¢
   - Gradioï¼šå¿«é€Ÿæ¨¡å‹æ¼”ç¤º

4. **å‘é‡æ•°æ®åº“**
   - ChromaDBï¼šæœ¬åœ°å¼€å‘
   - Pinecone/Weaviateï¼šç”Ÿäº§éƒ¨ç½²

5. **å¯è§†åŒ–**
   - Matplotlibï¼šé™æ€å›¾è¡¨
   - Plotlyï¼šäº¤äº’å¼å¯è§†åŒ–

6. **å®Œæ•´é¡¹ç›®**
   - RAG ChatBot å…¨æ ˆå®ç°

### ğŸ“š å­¦ä¹ è·¯å¾„

```
Module 0 å®Œæˆï¼ä½ å·²ç»æŒæ¡ï¼š
  âœ… 0.1 Python æ ¸å¿ƒåŸºç¡€
  âœ… 0.2 é¢å‘å¯¹è±¡ä¸å·¥ç¨‹å®è·µ
  âœ… 0.3 AI å¼€å‘å·¥å…·é“¾

ä¸‹ä¸€æ­¥ â†’ Module 1: LangGraph åŸºç¡€æ¦‚å¿µ
  - 1.1 LangGraph å¿«é€Ÿä¸Šæ‰‹
  - 1.2 State Schema çŠ¶æ€ç®¡ç†
  - 1.3 Nodes & Edges èŠ‚ç‚¹ä¸è¾¹
  - ...
```

### ğŸ’¡ å®æˆ˜å»ºè®®

1. **é€‰æ‹©ä¸€ä¸ªé¡¹ç›®å¼€å§‹**ï¼š
   - ç®€å•ï¼šStreamlit + OpenAI ChatBot
   - è¿›é˜¶ï¼šRAG çŸ¥è¯†åº“é—®ç­”
   - é«˜çº§ï¼šMulti-Agent åä½œç³»ç»Ÿ

2. **æ¨èå­¦ä¹ é¡ºåº**ï¼š
   - Week 1: LangChain åŸºç¡€
   - Week 2: LangGraph æ ¸å¿ƒæ¦‚å¿µ
   - Week 3: æ„å»ºå®Œæ•´ RAG ç³»ç»Ÿ
   - Week 4: Multi-Agent å®æˆ˜

3. **å·¥å…·ç»„åˆå»ºè®®**ï¼š
   - åŸå‹å¼€å‘ï¼šStreamlit + ChromaDB + LangChain
   - ç”Ÿäº§éƒ¨ç½²ï¼šLangGraph + Pinecone + FastAPI
   - æ•°æ®åˆ†æï¼šPandas + Matplotlib + Jupyter

---

**ğŸ¯ æ­å–œï¼ä½ å·²å®Œæˆ Module 0ï¼ŒæŒæ¡äº†æ„å»º AI Agent æ‰€éœ€çš„å®Œæ•´å·¥å…·é“¾ã€‚ç°åœ¨ï¼Œå‡†å¤‡å¥½è¿›å…¥ LangGraph çš„ç²¾å½©ä¸–ç•Œäº†å—ï¼Ÿ**

---

## é™„å½•ï¼šå¿«é€Ÿå‚è€ƒ

### å®‰è£…å‘½ä»¤é€ŸæŸ¥

```bash
# æ•°æ®å¤„ç†
pip install numpy pandas matplotlib seaborn plotly

# AI æ¡†æ¶
pip install langchain langgraph openai anthropic

# å¤šæ™ºèƒ½ä½“æ¡†æ¶
pip install crewai pyautogen

# å‘é‡æ•°æ®åº“
pip install chromadb pinecone-client weaviate-client

# UI æ¡†æ¶
pip install streamlit gradio

# è¾…åŠ©å·¥å…·
pip install python-dotenv python-multipart

# å®Œæ•´å®‰è£…
pip install -r requirements.txt
```

### èµ„æºé“¾æ¥

- **LangChain å®˜æ–¹æ–‡æ¡£**: https://python.langchain.com/
- **LangGraph å®˜æ–¹æ–‡æ¡£**: https://langchain-ai.github.io/langgraph/
- **Streamlit å®˜æ–¹æ–‡æ¡£**: https://docs.streamlit.io/
- **Gradio å®˜æ–¹æ–‡æ¡£**: https://gradio.app/docs/
- **ChromaDB å®˜æ–¹æ–‡æ¡£**: https://docs.trychroma.com/
- **OpenAI API æ–‡æ¡£**: https://platform.openai.com/docs/

---

**ğŸš€ å‡†å¤‡å¥½äº†å—ï¼Ÿè®©æˆ‘ä»¬è¿›å…¥ Module 1ï¼Œå¼€å§‹ LangGraph çš„å­¦ä¹ ä¹‹æ—…ï¼**
