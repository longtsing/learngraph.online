# LangGraph æ¶ˆæ¯è¿‡æ»¤ä¸è£å‰ªè¯¦ç»†è§£è¯»

>  ç½‘ç«™ä½¿ç”¨è¯´æ˜
> - æœ¬ç½‘ç«™å¯ä»¥å…ç™»é™†è¿è¡Œ Python ä»£ç 
> - Python ä»£ç å¯ä»¥ç¼–è¾‘å¹¶ä¸´æ—¶ä¿å­˜ï¼Œä½†ä¸ä¼šæ°¸ä¹…ä¿å­˜ï¼Œç½‘é¡µåˆ·æ–°åä¼šè‡ªåŠ¨è¿˜åŸ
> - å¯¹ç½‘ç«™çš„ä½¿ç”¨æœ‰ä»»ä½•é—®é¢˜ï¼Œå¯ä»¥åˆ° [é—®é¢˜åé¦ˆ](http://localhost:5173/feedback.html) ï¼ˆæŒ‰é’®åœ¨æ¯ä¸ªé¡µé¢çš„å³ä¸‹è§’ï¼‰å…ç™»å½•è¿›è¡Œè¯„è®º
> - è¿è¡Œ `LangGraph/LangChain`ä»£ç ï¼Œéœ€è¦ç”¨æˆ·è¾“å…¥è‡ªå·±çš„ [API Key](http://localhost:5173/python-run.html)
> - é‡è¦å£°æ˜ï¼šæœ¬ç½‘ç«™ä¸ä¼šä¿å­˜ç”¨æˆ·çš„ API Key æ•°æ®ï¼Œè¯·æ”¾å¿ƒè¾“å…¥

## ğŸ“š æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è§£è¯» LangGraph ä¸­çš„ **æ¶ˆæ¯è¿‡æ»¤ï¼ˆMessage Filteringï¼‰** å’Œ **æ¶ˆæ¯è£å‰ªï¼ˆMessage Trimmingï¼‰** æŠ€æœ¯ã€‚è¿™ä¸¤ç§æŠ€æœ¯æ˜¯æ„å»ºé•¿æœŸè®°å¿†èŠå¤©æœºå™¨äººçš„æ ¸å¿ƒæŠ€èƒ½ï¼Œå¸®åŠ©æˆ‘ä»¬é«˜æ•ˆç®¡ç†å¯¹è¯å†å²ï¼Œé¿å… token æµªè´¹å’Œå»¶è¿Ÿé—®é¢˜ã€‚

åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒèŠå¤©æœºå™¨äººçš„å¯¹è¯å¯èƒ½ä¼šæŒç»­å¾ˆé•¿æ—¶é—´ï¼Œå¦‚æœä¸åŠ æ§åˆ¶åœ°å°†æ‰€æœ‰å†å²æ¶ˆæ¯ä¼ é€’ç»™ LLMï¼Œä¼šå¯¼è‡´ï¼š
- **Token æˆæœ¬é£™å‡**ï¼šæ¯æ¬¡è°ƒç”¨éƒ½ä¼ é€’å®Œæ•´å†å²
- **å“åº”å»¶è¿Ÿå¢åŠ **ï¼šLLM éœ€è¦å¤„ç†å¤§é‡ä¸Šä¸‹æ–‡
- **ä¸Šä¸‹æ–‡çª—å£æº¢å‡º**ï¼šè¶…è¿‡æ¨¡å‹çš„æœ€å¤§ token é™åˆ¶

æœ¬æ•™ç¨‹å°†å±•ç¤ºä¸‰ç§è§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©ä½ ä¼˜é›…åœ°ç®¡ç†å¯¹è¯çŠ¶æ€ã€‚

---

## ğŸ“š æœ¯è¯­è¡¨

| æœ¯è¯­åç§° | LangGraph å®šä¹‰å’Œè§£è¯» | Python å®šä¹‰å’Œè¯´æ˜ | é‡è¦ç¨‹åº¦ |
|---------|---------------------|------------------|---------|
| **RemoveMessage** | LangGraph ç”¨äºä»çŠ¶æ€ä¸­æ°¸ä¹…åˆ é™¤æ¶ˆæ¯çš„ç‰¹æ®Šæ¶ˆæ¯ç±»å‹ | LangChain æ¶ˆæ¯ç±»ï¼Œæ ¼å¼ `RemoveMessage(id="msg_id")`ï¼Œé…åˆ add_messages reducer | â­â­â­â­â­ |
| **trim_messages** | LangChain å·¥å…·å‡½æ•°ï¼ŒåŸºäº token æ•°é‡æ™ºèƒ½è£å‰ªæ¶ˆæ¯åˆ—è¡¨ | å‡½æ•°ç­¾å `trim_messages(messages, max_tokens, strategy, token_counter)` | â­â­â­â­â­ |
| **filter_messages** | é€šè¿‡æ¡ä»¶ç­›é€‰æ¶ˆæ¯ï¼Œä¸ä¿®æ”¹çŠ¶æ€ï¼Œåªæ”¹å˜ä¼ é€’ç»™ LLM çš„å†…å®¹ | åˆ—è¡¨åˆ‡ç‰‡æˆ–è¿‡æ»¤å‡½æ•°ï¼Œå¦‚ `messages[-5:]` åªä¿ç•™æœ€å5æ¡ | â­â­â­â­ |
| **MessagesState** | LangGraph é¢„å®šä¹‰çŠ¶æ€ç±»ï¼ŒåŒ…å«å¸¦ add_messages reducer çš„ messages å­—æ®µ | TypedDict åŸºç±»ï¼Œè‡ªåŠ¨å¤„ç†æ¶ˆæ¯è¿½åŠ å’Œ RemoveMessage åˆ é™¤ | â­â­â­â­â­ |
| **token_counter** | trim_messages å‚æ•°ï¼Œç”¨äºè®¡ç®—æ¶ˆæ¯ token æ•°é‡çš„æ¨¡å‹å®ä¾‹ | ChatOpenAI æˆ–å…¶ä»– LLM å®ä¾‹ï¼Œæä¾› `get_num_tokens_from_messages()` æ–¹æ³• | â­â­â­â­ |
| **strategy** | trim_messages çš„è£å‰ªç­–ç•¥ï¼Œå†³å®šä¿ç•™å“ªäº›æ¶ˆæ¯ | "last" ä¿ç•™æœ€åçš„æ¶ˆæ¯ï¼Œ"first" ä¿ç•™æœ€å¼€å§‹çš„æ¶ˆæ¯ | â­â­â­â­ |
| **allow_partial** | trim_messages å‚æ•°ï¼Œæ˜¯å¦å…è®¸æˆªæ–­å•æ¡æ¶ˆæ¯ä»¥è¾¾åˆ° token é™åˆ¶ | å¸ƒå°”å€¼ï¼ŒFalse æ•´æ¡ä¿ç•™æˆ–ä¸¢å¼ƒï¼ŒTrue å…è®¸éƒ¨åˆ†æˆªæ–­ | â­â­â­ |
| **æ»‘åŠ¨çª—å£** | åªä¿ç•™æœ€è¿‘ N æ¡æ¶ˆæ¯çš„å†…å­˜ç®¡ç†æ¨¡å¼ | é€šè¿‡åˆ—è¡¨åˆ‡ç‰‡ `messages[-N:]` æˆ–å®šæœŸåˆ é™¤æ—§æ¶ˆæ¯å®ç° | â­â­â­â­ |
| **SystemMessage** | LangChain æ¶ˆæ¯ç±»å‹ï¼Œè¡¨ç¤ºç³»ç»ŸæŒ‡ä»¤æˆ–æç¤º | é€šå¸¸æ”¾åœ¨æ¶ˆæ¯åˆ—è¡¨å¼€å¤´ï¼ŒåŒ…å«è§’è‰²è®¾å®šå’Œè§„åˆ™ | â­â­â­â­ |
| **æ¶ˆæ¯ ID** | æ¯æ¡æ¶ˆæ¯çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äº RemoveMessage å®šä½åˆ é™¤ | æ¶ˆæ¯å¯¹è±¡çš„ `id` å±æ€§ï¼Œè‡ªåŠ¨ç”Ÿæˆæˆ–æ‰‹åŠ¨æŒ‡å®š | â­â­â­â­â­ |

---

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### æ¶ˆæ¯ç®¡ç†çš„æŒ‘æˆ˜

åœ¨é•¿æœŸè¿è¡Œçš„å¯¹è¯ä¸­ï¼Œæˆ‘ä»¬é¢ä¸´çš„æ ¸å¿ƒé—®é¢˜æ˜¯ï¼š

```
ç”¨æˆ·: Hi
Bot: Hi! How can I help?
ç”¨æˆ·: I'm researching whales
Bot: Great! Tell me more.
ç”¨æˆ·: What are other ocean mammals?
Bot: [è¿™é‡Œéœ€è¦å®Œæ•´ä¸Šä¸‹æ–‡å—ï¼Ÿ]
ç”¨æˆ·: Tell me about dolphins
Bot: [è¿˜éœ€è¦ç¬¬ä¸€è½®å¯¹è¯å—ï¼Ÿ]
... (100 è½®å¯¹è¯å)
ç”¨æˆ·: What's the weather?
Bot: [éœ€è¦å‰é¢ 99 è½®å¯¹è¯å—ï¼ŸâŒ]
```

### ä¸‰ç§è§£å†³æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | åŸç† | ä¿®æ”¹çŠ¶æ€ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|---------|
| **RemoveMessage** | ä»çŠ¶æ€ä¸­åˆ é™¤æ—§æ¶ˆæ¯ | âœ… æ˜¯ | æ°¸ä¹…åˆ é™¤ä¸éœ€è¦çš„å†å² |
| **æ¶ˆæ¯è¿‡æ»¤** | ä¼ é€’æ¶ˆæ¯å­é›†ç»™ LLM | âŒ å¦ | ä¿ç•™å®Œæ•´å†å²ï¼Œä½†é™åˆ¶ LLM å¯è§èŒƒå›´ |
| **æ¶ˆæ¯è£å‰ª** | åŸºäº token æ•°é‡æ™ºèƒ½æˆªæ–­ | âŒ å¦ | ç²¾ç¡®æ§åˆ¶ token ä½¿ç”¨ |

---

## ğŸ­ å®æˆ˜æ¡ˆä¾‹ï¼šæµ·æ´‹å“ºä¹³åŠ¨ç‰©ç ”ç©¶åŠ©æ‰‹

æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œæ¼”ç¤ºä¸‰ç§æ¶ˆæ¯ç®¡ç†æŠ€æœ¯çš„åº”ç”¨ã€‚

### åœºæ™¯è®¾å®š

ç”¨æˆ·æ­£åœ¨ç ”ç©¶æµ·æ´‹å“ºä¹³åŠ¨ç‰©ï¼Œè¿›è¡Œäº†å¤šè½®å¯¹è¯ï¼š
1. æ‰“æ‹›å‘¼
2. è®¨è®ºé²¸é±¼
3. è¯¢é—®å…¶ä»–æµ·æ´‹å“ºä¹³åŠ¨ç‰©
4. æ·±å…¥äº†è§£ç‹¬è§’é²¸
5. è¯¢é—®è™é²¸æ –æ¯åœ°

æˆ‘ä»¬éœ€è¦åœ¨ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§çš„åŒæ—¶ï¼Œæ§åˆ¶ token ä½¿ç”¨ã€‚

---

## ğŸ”§ æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨ RemoveMessage åˆ é™¤æ¶ˆæ¯

### æ ¸å¿ƒæ€è·¯

ä½¿ç”¨ `RemoveMessage` å’Œ `add_messages` reducerï¼Œä»çŠ¶æ€ä¸­**æ°¸ä¹…åˆ é™¤**æ—§æ¶ˆæ¯ã€‚

### ä»£ç å®ç°

#### 1. åŸºç¡€å‡†å¤‡

```python
from pprint import pprint
from langchain_core.messages import AIMessage, HumanMessage
from langchain_openai import ChatOpenAI

# åˆå§‹åŒ– LLM
llm = ChatOpenAI(model="gpt-5-nano")

# åˆ›å»ºå¯¹è¯å†å²
messages = [AIMessage("So you said you were researching ocean mammals?", name="Bot")]
messages.append(HumanMessage("Yes, I know about whales. But what others should I learn about?", name="Lance"))

# æŸ¥çœ‹æ¶ˆæ¯
for m in messages:
    m.pretty_print()
```

**Python çŸ¥è¯†ç‚¹ï¼šæ¶ˆæ¯å¯¹è±¡**

LangChain ä½¿ç”¨ä¸“é—¨çš„æ¶ˆæ¯ç±»æ¥åŒºåˆ†å¯¹è¯è§’è‰²ï¼š

```python
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

# HumanMessage - ç”¨æˆ·è¾“å…¥
user_msg = HumanMessage(content="Hello!", name="Alice")

# AIMessage - AI å›å¤
ai_msg = AIMessage(content="Hi there!", name="Bot")

# SystemMessage - ç³»ç»ŸæŒ‡ä»¤
sys_msg = SystemMessage(content="You are a helpful assistant")
```

**é‡è¦å±æ€§ï¼š**
- `content`ï¼šæ¶ˆæ¯å†…å®¹
- `name`ï¼šå‘é€è€…åç§°ï¼ˆå¯é€‰ï¼‰
- `id`ï¼šå”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆç”¨äº RemoveMessageï¼‰

#### 2. å®šä¹‰è¿‡æ»¤èŠ‚ç‚¹

```python
from langchain_core.messages import RemoveMessage
from langgraph.graph import MessagesState

def filter_messages(state: MessagesState):
    """åˆ é™¤é™¤æœ€å 2 æ¡æ¶ˆæ¯å¤–çš„æ‰€æœ‰æ¶ˆæ¯"""
    # è·å–è¦åˆ é™¤çš„æ¶ˆæ¯ï¼ˆå‰ N-2 æ¡ï¼‰
    delete_messages = [RemoveMessage(id=m.id) for m in state["messages"][:-2]]
    return {"messages": delete_messages}
```

**LangGraph çŸ¥è¯†ç‚¹ï¼šRemoveMessage**

`RemoveMessage` æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„æ¶ˆæ¯ç±»å‹ï¼Œå‘Šè¯‰ `add_messages` reducer åˆ é™¤æŒ‡å®šæ¶ˆæ¯ï¼š

```python
RemoveMessage(id="message_id_123")
#             ^^^^^^^^^^^^^^^^^^^
#             è¦åˆ é™¤çš„æ¶ˆæ¯çš„ ID
```

**å·¥ä½œåŸç†ï¼š**

```python
# åˆå§‹çŠ¶æ€
state["messages"] = [msg1, msg2, msg3, msg4]

# filter_messages è¿”å›
{"messages": [RemoveMessage(id=msg1.id), RemoveMessage(id=msg2.id)]}

# add_messages reducer å¤„ç†å
state["messages"] = [msg3, msg4]  # msg1 å’Œ msg2 è¢«åˆ é™¤
```

**å…³é”®ï¼š** `add_messages` reducer ä¼šè¯†åˆ« `RemoveMessage`ï¼Œå¹¶ä»çŠ¶æ€ä¸­åˆ é™¤å¯¹åº”çš„æ¶ˆæ¯ã€‚

#### 3. å®šä¹‰èŠå¤©èŠ‚ç‚¹

```python
def chat_model_node(state: MessagesState):
    """è°ƒç”¨ LLM ç”Ÿæˆå›å¤"""
    return {"messages": [llm.invoke(state["messages"])]}
```

**æ³¨æ„ï¼š** è¿”å› `{"messages": [ai_message]}` è€Œä¸æ˜¯ `{"messages": ai_message}`ï¼Œå› ä¸º `add_messages` reducer æœŸæœ›åˆ—è¡¨ã€‚

#### 4. æ„å»ºå›¾

```python
from langgraph.graph import StateGraph, START, END

# åˆ›å»ºå›¾
builder = StateGraph(MessagesState)

# æ·»åŠ èŠ‚ç‚¹
builder.add_node("filter", filter_messages)
builder.add_node("chat_model", chat_model_node)

# æ·»åŠ è¾¹
builder.add_edge(START, "filter")
builder.add_edge("filter", "chat_model")
builder.add_edge("chat_model", END)

# ç¼–è¯‘
graph = builder.compile()

# ğŸ¨ å¯è§†åŒ–å›¾ç»“æ„
from IPython.display import Image, display
display(Image(graph.get_graph().draw_mermaid_png()))
```

**æ‰§è¡Œæµç¨‹ï¼š**

```
START â†’ filterï¼ˆåˆ é™¤æ—§æ¶ˆæ¯ï¼‰â†’ chat_modelï¼ˆLLM å›å¤ï¼‰â†’ END
```

#### 5. æ‰§è¡Œæµ‹è¯•

```python
# åˆ›å»ºå¸¦ ID çš„æ¶ˆæ¯ï¼ˆRemoveMessage éœ€è¦ IDï¼‰
messages = [
    AIMessage("Hi.", name="Bot", id="1"),
    HumanMessage("Hi.", name="Lance", id="2"),
    AIMessage("So you said you were researching ocean mammals?", name="Bot", id="3"),
    HumanMessage("Yes, I know about whales. But what others should I learn about?", name="Lance", id="4")
]

# è°ƒç”¨å›¾
output = graph.invoke({'messages': messages})

# æŸ¥çœ‹ç»“æœ
for m in output['messages']:
    m.pretty_print()
```

**é¢„æœŸç»“æœï¼š**

```
# åªä¿ç•™æœ€å 2 æ¡æ¶ˆæ¯ + LLM å›å¤
================================== Ai Message ==================================
Name: Bot

So you said you were researching ocean mammals?
================================ Human Message =================================
Name: Lance

Yes, I know about whales. But what others should I learn about?
================================== Ai Message ==================================

Here are some ocean mammals: dolphins, seals, sea lions, ...
```

**æ³¨æ„ï¼š** å‰ä¸¤æ¡æ¶ˆæ¯ï¼ˆid="1" å’Œ id="2"ï¼‰å·²è¢«æ°¸ä¹…åˆ é™¤ï¼

### Python çŸ¥è¯†ç‚¹ï¼šåˆ—è¡¨åˆ‡ç‰‡

```python
messages = [msg1, msg2, msg3, msg4, msg5]

# å–æœ€å 2 æ¡
messages[-2:]  # â†’ [msg4, msg5]

# é™¤äº†æœ€å 2 æ¡çš„æ‰€æœ‰æ¶ˆæ¯
messages[:-2]  # â†’ [msg1, msg2, msg3]

# ç¬¬ä¸€æ¡
messages[:1]   # â†’ [msg1]

# æœ€åä¸€æ¡
messages[-1:]  # â†’ [msg5]
```

---

## ğŸ”§ æ–¹æ¡ˆäºŒï¼šæ¶ˆæ¯è¿‡æ»¤ï¼ˆä¸ä¿®æ”¹çŠ¶æ€ï¼‰

### æ ¸å¿ƒæ€è·¯

ä¸ä¿®æ”¹å›¾çŠ¶æ€ï¼Œåªåœ¨ä¼ é€’ç»™ LLM æ—¶è¿‡æ»¤æ¶ˆæ¯ã€‚çŠ¶æ€ä¿ç•™å®Œæ•´å†å²ï¼Œä½† LLM åªçœ‹åˆ°éƒ¨åˆ†æ¶ˆæ¯ã€‚

### ä»£ç å®ç°

#### 1. ä¿®æ”¹èŠå¤©èŠ‚ç‚¹

```python
def chat_model_node(state: MessagesState):
    """åªä¼ é€’æœ€åä¸€æ¡æ¶ˆæ¯ç»™ LLM"""
    return {"messages": [llm.invoke(state["messages"][-1:])]}
    #                                 ^^^^^^^^^^^^^^^^^^^
    #                                 åªå–æœ€åä¸€æ¡æ¶ˆæ¯
```

#### 2. ç®€åŒ–çš„å›¾ç»“æ„

```python
# åˆ›å»ºå›¾ï¼ˆæ— éœ€ filter èŠ‚ç‚¹ï¼ï¼‰
builder = StateGraph(MessagesState)
builder.add_node("chat_model", chat_model_node)
builder.add_edge(START, "chat_model")
builder.add_edge("chat_model", END)
graph = builder.compile()

# ğŸ¨ å¯è§†åŒ–å›¾ç»“æ„
from IPython.display import Image, display
display(Image(graph.get_graph().draw_mermaid_png()))
```

**å¯¹æ¯”æ–¹æ¡ˆä¸€ï¼š**

| ç‰¹æ€§ | RemoveMessage | æ¶ˆæ¯è¿‡æ»¤ |
|------|--------------|---------|
| èŠ‚ç‚¹æ•°é‡ | 2 ä¸ªï¼ˆfilter + chatï¼‰ | 1 ä¸ªï¼ˆchatï¼‰ |
| çŠ¶æ€ä¿®æ”¹ | æ°¸ä¹…åˆ é™¤ | ä¿æŒä¸å˜ |
| å†å²å¯ç”¨æ€§ | å†å²ä¸¢å¤± | å†å²å®Œæ•´ä¿ç•™ |

#### 3. æµ‹è¯•å¤šè½®å¯¹è¯

```python
# åˆå§‹æ¶ˆæ¯
messages = [
    AIMessage("So you said you were researching ocean mammals?", name="Bot"),
    HumanMessage("Yes, I know about whales. But what others should I learn about?", name="Lance")
]

# ç¬¬ä¸€è½®è°ƒç”¨
output = graph.invoke({'messages': messages})

# è¿½åŠ  LLM å›å¤å’Œæ–°é—®é¢˜
messages.append(output['messages'][-1])
messages.append(HumanMessage("Tell me more about Narwhals!", name="Lance"))

# ç¬¬äºŒè½®è°ƒç”¨
output = graph.invoke({'messages': messages})
```

**å…³é”®è§‚å¯Ÿï¼š**

è™½ç„¶ `messages` åŒ…å«å®Œæ•´å†å²ï¼Œä½† LLM æ¯æ¬¡åªçœ‹åˆ°æœ€åä¸€æ¡æ¶ˆæ¯ï¼

```python
# messages å®é™…å†…å®¹ï¼š
[
    AIMessage("...ocean mammals?"),
    HumanMessage("...whales..."),
    AIMessage("...dolphins, seals..."),
    HumanMessage("Tell me more about Narwhals!")  # â† LLM åªçœ‹åˆ°è¿™æ¡
]
```

### åœ¨ LangSmith ä¸­éªŒè¯

æŸ¥çœ‹ LangSmith è¿½è¸ªï¼Œä½ ä¼šå‘ç° LLM è°ƒç”¨çš„ `messages` å‚æ•°åªåŒ…å«æœ€åä¸€æ¡æ¶ˆæ¯ï¼Œè€Œä¸æ˜¯å®Œæ•´å†å²ã€‚

**ä¼˜åŠ¿ï¼š**
- çŠ¶æ€å®Œæ•´ä¿ç•™ï¼ˆå¯ç”¨äºæ—¥å¿—ã€åˆ†æï¼‰
- LLM token ä½¿ç”¨å—æ§
- å®ç°ç®€å•ï¼ˆæ— éœ€é¢å¤–èŠ‚ç‚¹ï¼‰

**åŠ£åŠ¿ï¼š**
- LLM ç¼ºä¹ä¸Šä¸‹æ–‡ï¼ˆå¯èƒ½å¯¼è‡´å›ç­”ä¸è¿è´¯ï¼‰
- éœ€è¦æ‰‹åŠ¨ç®¡ç†éœ€è¦ä¼ é€’çš„æ¶ˆæ¯èŒƒå›´

---

## ğŸ”§ æ–¹æ¡ˆä¸‰ï¼šæ™ºèƒ½è£å‰ªï¼ˆåŸºäº Tokenï¼‰

### æ ¸å¿ƒæ€è·¯

ä½¿ç”¨ LangChain çš„ `trim_messages` å·¥å…·ï¼ŒåŸºäº **token æ•°é‡** æ™ºèƒ½è£å‰ªæ¶ˆæ¯ï¼Œè€Œä¸æ˜¯ç®€å•åœ°æŒ‰æ•°é‡è¿‡æ»¤ã€‚

### ä¸ºä»€ä¹ˆéœ€è¦ Token è£å‰ªï¼Ÿ

ä¸åŒæ¶ˆæ¯çš„ token æ•°é‡å·®å¼‚å¾ˆå¤§ï¼š

```python
msg1 = HumanMessage("Hi")                    # ~1 token
msg2 = AIMessage("Hello! How can I help?")   # ~5 tokens
msg3 = HumanMessage("Tell me about whales... (1000 å­—)")  # ~1500 tokens
```

å¦‚æœç®€å•è¿‡æ»¤"æœ€å 2 æ¡æ¶ˆæ¯"ï¼š
- å¯èƒ½æ˜¯ 6 tokensï¼ˆmsg1 + msg2ï¼‰
- ä¹Ÿå¯èƒ½æ˜¯ 1505 tokensï¼ˆmsg2 + msg3ï¼‰

**Token è£å‰ªç¡®ä¿ç²¾ç¡®æ§åˆ¶ï¼**

### ä»£ç å®ç°

#### 1. å¯¼å…¥è£å‰ªå·¥å…·

```python
from langchain_core.messages import trim_messages
```

#### 2. ä¿®æ”¹èŠå¤©èŠ‚ç‚¹

```python
def chat_model_node(state: MessagesState):
    """ä½¿ç”¨ token è£å‰ª"""
    # è£å‰ªæ¶ˆæ¯åˆ°æœ€å¤š 100 tokens
    messages = trim_messages(
        state["messages"],          # åŸå§‹æ¶ˆæ¯åˆ—è¡¨
        max_tokens=100,             # æœ€å¤§ token æ•°
        strategy="last",            # ä¿ç•™æœ€åçš„æ¶ˆæ¯
        token_counter=ChatOpenAI(model="gpt-5-nano"),  # Token è®¡æ•°å™¨
        allow_partial=False,        # ä¸å…è®¸æˆªæ–­æ¶ˆæ¯
    )
    return {"messages": [llm.invoke(messages)]}
```

**LangChain çŸ¥è¯†ç‚¹ï¼štrim_messages å‚æ•°è¯¦è§£**

```python
trim_messages(
    messages,                      # è¦è£å‰ªçš„æ¶ˆæ¯åˆ—è¡¨
    max_tokens=100,                # æœ€å¤§ token æ•°
    strategy="last",               # è£å‰ªç­–ç•¥ï¼ˆè§ä¸‹æ–¹ï¼‰
    token_counter=model,           # Token è®¡æ•°å™¨ï¼ˆé€šå¸¸æ˜¯æ¨¡å‹å®ä¾‹ï¼‰
    allow_partial=False,           # æ˜¯å¦å…è®¸éƒ¨åˆ†æˆªæ–­å•æ¡æ¶ˆæ¯
)
```

**è£å‰ªç­–ç•¥ï¼ˆstrategyï¼‰ï¼š**

| ç­–ç•¥ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `"last"` | ä¿ç•™æœ€åçš„æ¶ˆæ¯ | é€‚åˆèŠå¤©æœºå™¨äººï¼ˆä¿ç•™æœ€è¿‘å¯¹è¯ï¼‰ |
| `"first"` | ä¿ç•™æœ€å¼€å§‹çš„æ¶ˆæ¯ | é€‚åˆä¿ç•™ç³»ç»ŸæŒ‡ä»¤ |

**allow_partial å‚æ•°ï¼š**

```python
# allow_partial=Falseï¼ˆé»˜è®¤ï¼‰
# å¦‚æœæŸæ¡æ¶ˆæ¯è¶…è¿‡å‰©ä½™ tokenï¼Œç›´æ¥ä¸¢å¼ƒæ•´æ¡æ¶ˆæ¯
messages = [msg1(50 tokens), msg2(60 tokens), msg3(40 tokens)]
trim_messages(messages, max_tokens=100, allow_partial=False)
# â†’ [msg2, msg3]  # msg1 è¢«ä¸¢å¼ƒï¼Œå› ä¸º msg2+msg3=100 tokens

# allow_partial=True
# ä¼šæˆªæ–­æ¶ˆæ¯ä»¥ç²¾ç¡®è¾¾åˆ° max_tokens
trim_messages(messages, max_tokens=100, allow_partial=True)
# â†’ [msg1(éƒ¨åˆ†æˆªæ–­), msg2, msg3]
```

#### 3. æµ‹è¯•è£å‰ªæ•ˆæœ

```python
# å‡†å¤‡é•¿å¯¹è¯å†å²
messages = [
    AIMessage("Hi.", name="Bot", id="1"),
    HumanMessage("Hi.", name="Lance", id="2"),
    AIMessage("So you said you were researching ocean mammals?", name="Bot", id="3"),
    HumanMessage("Yes, I know about whales. But what others should I learn about?", name="Lance", id="4"),
    AIMessage("Consider dolphins, seals, sea lions...", name="Bot", id="5"),
    HumanMessage("Tell me where Orcas live!", name="Lance", id="6")
]

# æµ‹è¯•è£å‰ªï¼ˆä¸è°ƒç”¨ LLMï¼‰
trimmed = trim_messages(
    messages,
    max_tokens=100,
    strategy="last",
    token_counter=ChatOpenAI(model="gpt-5-nano"),
    allow_partial=False
)

print(f"åŸå§‹æ¶ˆæ¯æ•°: {len(messages)}")
print(f"è£å‰ªåæ¶ˆæ¯æ•°: {len(trimmed)}")
for m in trimmed:
    m.pretty_print()
```

**é¢„æœŸè¾“å‡ºï¼š**

æ ¹æ® token è®¡ç®—ï¼Œå¯èƒ½åªä¿ç•™æœ€å 2-3 æ¡æ¶ˆæ¯ï¼Œç¡®ä¿æ€»æ•°ä¸è¶…è¿‡ 100 tokensã€‚

#### 4. åœ¨å›¾ä¸­ä½¿ç”¨

```python
# æ„å»ºå›¾
builder = StateGraph(MessagesState)
builder.add_node("chat_model", chat_model_node)
builder.add_edge(START, "chat_model")
builder.add_edge("chat_model", END)
graph = builder.compile()

# ğŸ¨ å¯è§†åŒ–å›¾ç»“æ„
from IPython.display import Image, display
display(Image(graph.get_graph().draw_mermaid_png()))

# è°ƒç”¨
output = graph.invoke({'messages': messages})
```

**éªŒè¯ï¼š** åœ¨ LangSmith ä¸­æŸ¥çœ‹è¿½è¸ªï¼Œç¡®è®¤ LLM æ”¶åˆ°çš„æ¶ˆæ¯æ€» token æ•° â‰¤ 100ã€‚

### Python çŸ¥è¯†ç‚¹ï¼šå‡½æ•°å‚æ•°ä¼ é€’

```python
# trim_messages æ¥æ”¶æ¨¡å‹å®ä¾‹ä½œä¸º token_counter
token_counter=ChatOpenAI(model="gpt-5-nano")

# å†…éƒ¨è°ƒç”¨æ¨¡å‹çš„ token è®¡æ•°æ–¹æ³•
# model.get_num_tokens_from_messages(messages)
```

**ä¸ºä»€ä¹ˆéœ€è¦æ¨¡å‹å®ä¾‹ï¼Ÿ**

ä¸åŒæ¨¡å‹çš„ tokenizer ä¸åŒï¼š
- GPT-4ï¼šä½¿ç”¨ cl100k_base encoding
- GPT-3.5ï¼šä½¿ç”¨ cl100k_base encoding
- Claudeï¼šä½¿ç”¨ä¸åŒçš„ tokenizer

å¿…é¡»ä½¿ç”¨å¯¹åº”æ¨¡å‹çš„ tokenizer æ‰èƒ½å‡†ç¡®è®¡æ•°ï¼

---

## ğŸ“ æ ¸å¿ƒçŸ¥è¯†ç‚¹æ€»ç»“

### LangGraph ç‰¹æœ‰æ¦‚å¿µ

#### 1. MessagesState

é¢„å®šä¹‰çš„çŠ¶æ€æ¨¡å¼ï¼Œä¸“ä¸ºèŠå¤©åº”ç”¨è®¾è®¡ï¼š

```python
from langgraph.graph import MessagesState

class MessagesState(TypedDict):
    messages: Annotated[list, add_messages]
    #          ^^^^^^^^^^^^^^^^^^^^^^^
    #          è‡ªåŠ¨ä½¿ç”¨ add_messages reducer
```

**ä¼˜åŠ¿ï¼š**
- è‡ªåŠ¨å¤„ç†æ¶ˆæ¯è¿½åŠ 
- æ”¯æŒ `RemoveMessage`
- ç®€åŒ–çŠ¶æ€å®šä¹‰

#### 2. add_messages Reducer

å†…ç½®çš„æ™ºèƒ½æ¶ˆæ¯ reducerï¼š

```python
# æ™®é€šè¿½åŠ 
state["messages"] + [new_message]  # è¿½åŠ æ¶ˆæ¯

# è¯†åˆ« RemoveMessage
state["messages"] + [RemoveMessage(id="123")]  # åˆ é™¤æ¶ˆæ¯

# è‡ªåŠ¨å»é‡ï¼ˆåŸºäº IDï¼‰
state["messages"] + [existing_message]  # å¦‚æœ ID ç›¸åŒï¼Œä¸é‡å¤æ·»åŠ 
```

#### 3. ä¸‰ç§æ¶ˆæ¯ç®¡ç†æ¨¡å¼å¯¹æ¯”

| æ¨¡å¼ | çŠ¶æ€ä¿®æ”¹ | Token æ§åˆ¶ | å†å²ä¿ç•™ | å¤æ‚åº¦ | é€‚ç”¨åœºæ™¯ |
|------|---------|-----------|---------|--------|---------|
| **RemoveMessage** | âœ… æ°¸ä¹…åˆ é™¤ | é—´æ¥ï¼ˆåˆ é™¤æ¶ˆæ¯ï¼‰ | âŒ éƒ¨åˆ†ä¸¢å¤± | ä¸­ | ç¡®å®šä¸éœ€è¦å†å²æ—¶ |
| **æ¶ˆæ¯è¿‡æ»¤** | âŒ ä¸ä¿®æ”¹ | âœ… ç²¾ç¡®ï¼ˆæŒ‰æ•°é‡ï¼‰ | âœ… å®Œæ•´ä¿ç•™ | ä½ | ç®€å•åœºæ™¯ï¼Œå›ºå®šæ•°é‡ |
| **Token è£å‰ª** | âŒ ä¸ä¿®æ”¹ | âœ…âœ… éå¸¸ç²¾ç¡®ï¼ˆæŒ‰ tokenï¼‰ | âœ… å®Œæ•´ä¿ç•™ | ä¸­ | éœ€è¦ç²¾ç¡®æ§åˆ¶æˆæœ¬ |

### Python ç‰¹æœ‰çŸ¥è¯†ç‚¹

#### 1. æ¶ˆæ¯ç±»çš„å±‚æ¬¡ç»“æ„

```python
BaseMessage (åŸºç±»)
    â”œâ”€â”€ HumanMessage (ç”¨æˆ·æ¶ˆæ¯)
    â”œâ”€â”€ AIMessage (AI å›å¤)
    â”œâ”€â”€ SystemMessage (ç³»ç»ŸæŒ‡ä»¤)
    â”œâ”€â”€ FunctionMessage (å‡½æ•°è°ƒç”¨ç»“æœ)
    â””â”€â”€ RemoveMessage (åˆ é™¤æ ‡è®°)
```

**ç»§æ‰¿å…³ç³»ï¼š**

```python
from langchain_core.messages import BaseMessage, HumanMessage

# HumanMessage ç»§æ‰¿è‡ª BaseMessage
isinstance(HumanMessage("Hi"), BaseMessage)  # True
```

#### 2. åˆ—è¡¨åˆ‡ç‰‡çš„é«˜çº§ç”¨æ³•

```python
messages = [msg1, msg2, msg3, msg4, msg5]

# è´Ÿæ•°ç´¢å¼•
messages[-1]    # æœ€åä¸€ä¸ªå…ƒç´ 
messages[-2:]   # æœ€åä¸¤ä¸ªå…ƒç´ 

# æ­¥é•¿åˆ‡ç‰‡
messages[::2]   # æ¯éš”ä¸€ä¸ªå–ä¸€ä¸ª: [msg1, msg3, msg5]
messages[::-1]  # åè½¬åˆ—è¡¨

# çœç•¥å‚æ•°
messages[2:]    # ä»ç¬¬3ä¸ªåˆ°ç»“å°¾
messages[:3]    # ä»å¼€å¤´åˆ°ç¬¬3ä¸ªï¼ˆä¸å«ï¼‰
messages[:]     # å®Œæ•´å¤åˆ¶
```

#### 3. åˆ—è¡¨æ¨å¯¼å¼

```python
# åŸºç¡€å½¢å¼
[RemoveMessage(id=m.id) for m in messages[:-2]]

# ç­‰ä»·äºï¼š
result = []
for m in messages[:-2]:
    result.append(RemoveMessage(id=m.id))
```

**å¸¦æ¡ä»¶çš„åˆ—è¡¨æ¨å¯¼ï¼š**

```python
# åªåˆ é™¤ HumanMessage
[RemoveMessage(id=m.id) for m in messages if isinstance(m, HumanMessage)]

# åˆ é™¤è¶…è¿‡ 100 tokens çš„æ¶ˆæ¯
[RemoveMessage(id=m.id) for m in messages if get_token_count(m) > 100]
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ä½•æ—¶ä½¿ç”¨å“ªç§æ–¹æ¡ˆï¼Ÿ

#### ä½¿ç”¨ RemoveMessage çš„åœºæ™¯

âœ… **é€‚ç”¨ï¼š**
- ç¡®å®šæ—§æ¶ˆæ¯ä¸å†éœ€è¦ï¼ˆå¦‚å·²å®Œæˆçš„ä»»åŠ¡ï¼‰
- éœ€è¦æ°¸ä¹…å‡å°‘çŠ¶æ€å¤§å°ï¼ˆèŠ‚çœå†…å­˜ï¼‰
- å®ç°"å¿˜è®°"æœºåˆ¶ï¼ˆå¦‚å®šæœŸæ¸…ç† 7 å¤©å‰çš„å¯¹è¯ï¼‰

âŒ **ä¸é€‚ç”¨ï¼š**
- å¯èƒ½éœ€è¦å›æº¯å†å²
- éœ€è¦ä¿ç•™å®Œæ•´æ—¥å¿—
- è°ƒè¯•é˜¶æ®µï¼ˆåˆ é™¤åæ— æ³•æ¢å¤ï¼‰

**ç¤ºä¾‹ï¼š**

```python
def cleanup_old_messages(state: MessagesState):
    """åˆ é™¤ 7 å¤©å‰çš„æ¶ˆæ¯"""
    cutoff = datetime.now() - timedelta(days=7)
    to_remove = [
        RemoveMessage(id=m.id)
        for m in state["messages"]
        if m.timestamp < cutoff
    ]
    return {"messages": to_remove}
```

#### ä½¿ç”¨æ¶ˆæ¯è¿‡æ»¤çš„åœºæ™¯

âœ… **é€‚ç”¨ï¼š**
- å¿«é€ŸåŸå‹å¼€å‘
- ç®€å•çš„"æœ€è¿‘ N æ¡æ¶ˆæ¯"é€»è¾‘
- ä¸æƒ³ä¿®æ”¹çŠ¶æ€ï¼ˆæ–¹ä¾¿å›æ»šï¼‰

âŒ **ä¸é€‚ç”¨ï¼š**
- éœ€è¦ç²¾ç¡®æ§åˆ¶ token æˆæœ¬
- æ¶ˆæ¯é•¿åº¦å·®å¼‚å¾ˆå¤§

**ç¤ºä¾‹ï¼š**

```python
# åœºæ™¯ï¼šå®¢æœæœºå™¨äººåªéœ€è¦æœ€è¿‘ 5 è½®å¯¹è¯
def chat_node(state: MessagesState):
    recent_messages = state["messages"][-10:]  # 5 è½® = 10 æ¡æ¶ˆæ¯ï¼ˆç”¨æˆ·+AIï¼‰
    return {"messages": [llm.invoke(recent_messages)]}
```

#### ä½¿ç”¨ Token è£å‰ªçš„åœºæ™¯

âœ… **é€‚ç”¨ï¼š**
- ç”Ÿäº§ç¯å¢ƒï¼ˆéœ€è¦ä¸¥æ ¼æˆæœ¬æ§åˆ¶ï¼‰
- æ¶ˆæ¯é•¿åº¦ä¸å¯é¢„æµ‹
- éœ€è¦å……åˆ†åˆ©ç”¨ä¸Šä¸‹æ–‡çª—å£ï¼ˆå¦‚æ¥è¿‘ 4096 tokens é™åˆ¶ï¼‰

âŒ **ä¸é€‚ç”¨ï¼š**
- å¼€å‘æ—©æœŸï¼ˆå¢åŠ å¤æ‚åº¦ï¼‰
- æ¶ˆæ¯æ•°é‡å›ºå®šä¸”çŸ­

**ç¤ºä¾‹ï¼š**

```python
# åœºæ™¯ï¼šæ–‡æ¡£é—®ç­”ï¼Œç”¨æˆ·å¯èƒ½ç²˜è´´é•¿æ–‡æœ¬
def qa_node(state: MessagesState):
    # ä¿ç•™ç³»ç»ŸæŒ‡ä»¤ + å°½å¯èƒ½å¤šçš„å¯¹è¯å†å²
    messages = trim_messages(
        state["messages"],
        max_tokens=3500,  # ä¸º LLM å›å¤é¢„ç•™ 500 tokens
        strategy="last",
        token_counter=llm,
        allow_partial=False
    )
    return {"messages": [llm.invoke(messages)]}
```

### 2. ç»„åˆä½¿ç”¨å¤šç§æŠ€æœ¯

**æœ€ä½³å®è·µï¼š** åœ¨å®é™…åº”ç”¨ä¸­ï¼Œé€šå¸¸ç»„åˆä½¿ç”¨å¤šç§æŠ€æœ¯ã€‚

#### ç¤ºä¾‹ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿ

```python
def intelligent_chat_node(state: MessagesState):
    messages = state["messages"]

    # ç¬¬ 1 æ­¥ï¼šåˆ é™¤ç³»ç»Ÿæ¶ˆæ¯ä»¥å¤–çš„è¿‡æœŸæ¶ˆæ¯ï¼ˆ7 å¤©å‰ï¼‰
    # ï¼ˆåœ¨å•ç‹¬çš„ cleanup èŠ‚ç‚¹ä¸­å¤„ç†ï¼‰

    # ç¬¬ 2 æ­¥ï¼šä¿ç•™ç³»ç»ŸæŒ‡ä»¤
    system_messages = [m for m in messages if isinstance(m, SystemMessage)]
    conversation_messages = [m for m in messages if not isinstance(m, SystemMessage)]

    # ç¬¬ 3 æ­¥ï¼šToken è£å‰ªå¯¹è¯å†å²
    trimmed_conversation = trim_messages(
        conversation_messages,
        max_tokens=2000,
        strategy="last",
        token_counter=llm,
        allow_partial=False
    )

    # ç¬¬ 4 æ­¥ï¼šé‡ç»„æ¶ˆæ¯ï¼ˆç³»ç»ŸæŒ‡ä»¤ + è£å‰ªåçš„å¯¹è¯ï¼‰
    final_messages = system_messages + trimmed_conversation

    # ç¬¬ 5 æ­¥ï¼šè°ƒç”¨ LLM
    return {"messages": [llm.invoke(final_messages)]}
```

### 3. çŠ¶æ€ç®¡ç†æŠ€å·§

#### æŠ€å·§ 1ï¼šå§‹ç»ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯

```python
def trim_with_system(messages, max_tokens):
    # åˆ†ç¦»ç³»ç»Ÿæ¶ˆæ¯å’Œå¯¹è¯æ¶ˆæ¯
    system_msgs = [m for m in messages if isinstance(m, SystemMessage)]
    other_msgs = [m for m in messages if not isinstance(m, SystemMessage)]

    # è®¡ç®—ç³»ç»Ÿæ¶ˆæ¯çš„ token æ•°
    system_tokens = sum(llm.get_num_tokens(m.content) for m in system_msgs)

    # è£å‰ªå¯¹è¯æ¶ˆæ¯ï¼ˆå‡å»ç³»ç»Ÿæ¶ˆæ¯å ç”¨çš„ tokensï¼‰
    trimmed = trim_messages(
        other_msgs,
        max_tokens=max_tokens - system_tokens,
        strategy="last",
        token_counter=llm
    )

    return system_msgs + trimmed
```

#### æŠ€å·§ 2ï¼šä¿ç•™é‡è¦æ¶ˆæ¯

```python
def trim_with_pinned(state: MessagesState, max_tokens):
    messages = state["messages"]

    # æ ‡è®°é‡è¦æ¶ˆæ¯ï¼ˆå‡è®¾é€šè¿‡ metadataï¼‰
    pinned = [m for m in messages if m.additional_kwargs.get("pinned")]
    unpinned = [m for m in messages if not m.additional_kwargs.get("pinned")]

    # åªè£å‰ªéé‡è¦æ¶ˆæ¯
    pinned_tokens = sum(llm.get_num_tokens(m.content) for m in pinned)
    trimmed = trim_messages(
        unpinned,
        max_tokens=max_tokens - pinned_tokens,
        strategy="last",
        token_counter=llm
    )

    # é‡æ–°æ’åºï¼ˆä¿æŒæ—¶é—´é¡ºåºï¼‰
    all_messages = sorted(pinned + trimmed, key=lambda m: m.timestamp)
    return {"messages": all_messages}
```

#### æŠ€å·§ 3ï¼šåŠ¨æ€è°ƒæ•´è£å‰ªç­–ç•¥

```python
def adaptive_trim(state: MessagesState):
    messages = state["messages"]
    conversation_length = len(messages)

    # æ ¹æ®å¯¹è¯é•¿åº¦åŠ¨æ€è°ƒæ•´ max_tokens
    if conversation_length < 10:
        max_tokens = 1000  # çŸ­å¯¹è¯ï¼šä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡
    elif conversation_length < 50:
        max_tokens = 500   # ä¸­ç­‰å¯¹è¯ï¼šé€‚åº¦è£å‰ª
    else:
        max_tokens = 200   # é•¿å¯¹è¯ï¼šæ¿€è¿›è£å‰ª

    trimmed = trim_messages(
        messages,
        max_tokens=max_tokens,
        strategy="last",
        token_counter=llm
    )

    return {"messages": [llm.invoke(trimmed)]}
```

---

## ğŸš€ è¿›é˜¶æŠ€å·§

### 1. å®ç°æ»‘åŠ¨çª—å£

ä¿ç•™"æœ€è¿‘ N æ¡æ¶ˆæ¯ + æœ€å¼€å§‹çš„ç³»ç»ŸæŒ‡ä»¤"ï¼š

```python
def sliding_window_trim(messages, window_size=10):
    if len(messages) <= window_size:
        return messages

    # å‡è®¾ç¬¬ä¸€æ¡æ˜¯ç³»ç»ŸæŒ‡ä»¤
    system_msg = messages[0] if isinstance(messages[0], SystemMessage) else None

    if system_msg:
        # ä¿ç•™ç³»ç»ŸæŒ‡ä»¤ + æœ€å N-1 æ¡æ¶ˆæ¯
        return [system_msg] + messages[-(window_size-1):]
    else:
        # åªä¿ç•™æœ€å N æ¡
        return messages[-window_size:]
```

### 2. åŸºäºæ‘˜è¦çš„å†å²å‹ç¼©

å¯¹äºè¶…é•¿å¯¹è¯ï¼Œå¯ä»¥å®šæœŸç”Ÿæˆæ‘˜è¦ï¼š

```python
class ConversationState(TypedDict):
    messages: Annotated[list, add_messages]
    summary: str  # å¯¹è¯æ‘˜è¦

def summarize_old_messages(state: ConversationState):
    messages = state["messages"]

    # å¦‚æœæ¶ˆæ¯è¶…è¿‡ 50 æ¡ï¼Œç”Ÿæˆæ‘˜è¦
    if len(messages) > 50:
        # æ‘˜è¦å‰ 40 æ¡æ¶ˆæ¯
        to_summarize = messages[:40]
        summary_prompt = f"Summarize this conversation:\n{to_summarize}"
        summary = llm.invoke(summary_prompt).content

        # åˆ é™¤å·²æ‘˜è¦çš„æ¶ˆæ¯
        to_remove = [RemoveMessage(id=m.id) for m in to_summarize]

        return {
            "messages": to_remove,
            "summary": summary  # ä¿å­˜æ‘˜è¦
        }

    return {}

def chat_with_summary(state: ConversationState):
    # æ„å»ºä¸Šä¸‹æ–‡ï¼šæ‘˜è¦ + æœ€è¿‘æ¶ˆæ¯
    context = []
    if state.get("summary"):
        context.append(SystemMessage(f"Previous conversation summary: {state['summary']}"))
    context.extend(state["messages"])

    return {"messages": [llm.invoke(context)]}
```

### 3. æŒ‰è§’è‰²è¿‡æ»¤

åªä¿ç•™ç‰¹å®šè§’è‰²çš„æ¶ˆæ¯ï¼š

```python
def filter_by_role(messages, keep_roles=["human", "ai"]):
    """åªä¿ç•™ç”¨æˆ·å’Œ AI çš„æ¶ˆæ¯ï¼Œç§»é™¤ç³»ç»Ÿæ¶ˆæ¯"""
    return [
        m for m in messages
        if m.type in keep_roles
    ]

# ä½¿ç”¨
def chat_node(state: MessagesState):
    # åªä¼ é€’ç”¨æˆ·å’Œ AI çš„å¯¹è¯ç»™ LLM
    filtered = filter_by_role(state["messages"], keep_roles=["human", "ai"])
    return {"messages": [llm.invoke(filtered)]}
```

### 4. æ™ºèƒ½å»é‡

ç§»é™¤é‡å¤æˆ–ç›¸ä¼¼çš„æ¶ˆæ¯ï¼š

```python
def deduplicate_messages(messages):
    """ç§»é™¤å†…å®¹å®Œå…¨ç›¸åŒçš„è¿ç»­æ¶ˆæ¯"""
    if not messages:
        return messages

    deduplicated = [messages[0]]
    for msg in messages[1:]:
        if msg.content != deduplicated[-1].content:
            deduplicated.append(msg)

    return deduplicated
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### Token ä½¿ç”¨å¯¹æ¯”

å‡è®¾ 10 è½®å¯¹è¯ï¼Œæ¯è½®å¹³å‡ 100 tokensï¼š

| æ–¹æ¡ˆ | Token ä½¿ç”¨ | æˆæœ¬ï¼ˆGPT-4 è¾“å…¥ï¼‰ | å»¶è¿Ÿ |
|------|-----------|------------------|------|
| **æ— è£å‰ª** | 1000 tokens | $0.03 | é«˜ |
| **è¿‡æ»¤æœ€å 5 æ¡** | ~500 tokens | $0.015 | ä¸­ |
| **è£å‰ªåˆ° 200 tokens** | 200 tokens | $0.006 | ä½ |

### å®æµ‹ç¤ºä¾‹

```python
import time

# å‡†å¤‡é•¿å¯¹è¯ï¼ˆ100 æ¡æ¶ˆæ¯ï¼‰
long_conversation = [
    HumanMessage(f"Message {i}") if i % 2 == 0 else AIMessage(f"Response {i}")
    for i in range(100)
]

# æ–¹æ¡ˆ 1ï¼šæ— è£å‰ª
start = time.time()
response1 = llm.invoke(long_conversation)
time1 = time.time() - start

# æ–¹æ¡ˆ 2ï¼šè¿‡æ»¤æœ€å 10 æ¡
start = time.time()
response2 = llm.invoke(long_conversation[-10:])
time2 = time.time() - start

# æ–¹æ¡ˆ 3ï¼šToken è£å‰ªåˆ° 500
start = time.time()
trimmed = trim_messages(long_conversation, max_tokens=500, token_counter=llm)
response3 = llm.invoke(trimmed)
time3 = time.time() - start

print(f"æ— è£å‰ª: {time1:.2f}s")
print(f"è¿‡æ»¤: {time2:.2f}s (å¿« {(time1-time2)/time1*100:.0f}%)")
print(f"è£å‰ª: {time3:.2f}s (å¿« {(time1-time3)/time1*100:.0f}%)")
```

---

## ğŸ¯ å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹ 1ï¼šå®¢æœèŠå¤©æœºå™¨äºº

```python
class CustomerServiceState(TypedDict):
    messages: Annotated[list, add_messages]
    customer_id: str
    session_start: datetime

def customer_service_chat(state: CustomerServiceState):
    """å®¢æœæœºå™¨äººï¼šä¿ç•™å®Œæ•´å†å²ä½†é™åˆ¶ LLM å¯è§èŒƒå›´"""
    messages = state["messages"]

    # 1. å§‹ç»ˆä¿ç•™ç³»ç»ŸæŒ‡ä»¤ï¼ˆå®¢æœè§„èŒƒï¼‰
    system_msg = SystemMessage("You are a helpful customer service agent. Be polite and professional.")

    # 2. è£å‰ªå¯¹è¯å†å²åˆ° 1500 tokensï¼ˆçº¦ 10-15 è½®å¯¹è¯ï¼‰
    trimmed = trim_messages(
        messages,
        max_tokens=1500,
        strategy="last",
        token_counter=llm,
        allow_partial=False
    )

    # 3. ç»„åˆç³»ç»ŸæŒ‡ä»¤å’Œè£å‰ªåçš„å¯¹è¯
    final_messages = [system_msg] + trimmed

    return {"messages": [llm.invoke(final_messages)]}

# æ„å»ºå›¾
builder = StateGraph(CustomerServiceState)
builder.add_node("chat", customer_service_chat)
builder.add_edge(START, "chat")
builder.add_edge("chat", END)
graph = builder.compile()

# ğŸ¨ å¯è§†åŒ–å›¾ç»“æ„
from IPython.display import Image, display
display(Image(graph.get_graph().draw_mermaid_png()))
```

### æ¡ˆä¾‹ 2ï¼šæ–‡æ¡£é—®ç­”åŠ©æ‰‹

```python
def document_qa_chat(state: MessagesState):
    """æ–‡æ¡£é—®ç­”ï¼šç”¨æˆ·å¯èƒ½ç²˜è´´é•¿æ–‡æ¡£"""
    messages = state["messages"]

    # 1. è¯†åˆ«é•¿æ¶ˆæ¯ï¼ˆè¶…è¿‡ 1000 tokens çš„ï¼‰
    long_messages = []
    short_messages = []

    for m in messages:
        token_count = llm.get_num_tokens(m.content)
        if token_count > 1000:
            # æˆªæ–­é•¿æ¶ˆæ¯
            truncated_content = m.content[:2000] + "... [truncated]"
            long_messages.append(m.__class__(content=truncated_content))
        else:
            short_messages.append(m)

    # 2. è£å‰ªçŸ­æ¶ˆæ¯
    trimmed_short = trim_messages(
        short_messages,
        max_tokens=1500,
        strategy="last",
        token_counter=llm
    )

    # 3. ç»„åˆï¼ˆä¿ç•™æœ€è¿‘çš„é•¿æ¶ˆæ¯ + è£å‰ªåçš„çŸ­æ¶ˆæ¯ï¼‰
    final_messages = (long_messages[-1:] if long_messages else []) + trimmed_short

    return {"messages": [llm.invoke(final_messages)]}
```

### æ¡ˆä¾‹ 3ï¼šå®šæœŸæ¸…ç†æ—§æ¶ˆæ¯

```python
from datetime import datetime, timedelta

class TimedState(TypedDict):
    messages: Annotated[list, add_messages]
    last_cleanup: datetime

def cleanup_node(state: TimedState):
    """æ¯ 24 å°æ—¶æ¸…ç†ä¸€æ¬¡æ—§æ¶ˆæ¯"""
    now = datetime.now()
    last_cleanup = state.get("last_cleanup", now)

    # å¦‚æœè·ç¦»ä¸Šæ¬¡æ¸…ç†è¶…è¿‡ 24 å°æ—¶
    if (now - last_cleanup).total_seconds() > 86400:
        messages = state["messages"]
        cutoff = now - timedelta(days=7)

        # åˆ é™¤ 7 å¤©å‰çš„æ¶ˆæ¯
        to_remove = [
            RemoveMessage(id=m.id)
            for m in messages
            if hasattr(m, 'timestamp') and m.timestamp < cutoff
        ]

        return {
            "messages": to_remove,
            "last_cleanup": now
        }

    return {}

# åœ¨å›¾ä¸­æ·»åŠ æ¸…ç†èŠ‚ç‚¹
builder.add_node("cleanup", cleanup_node)
builder.add_node("chat", chat_node)
builder.add_edge(START, "cleanup")
builder.add_edge("cleanup", "chat")
builder.add_edge("chat", END)
```

---

## ğŸ” å¸¸è§é—®é¢˜

### Q1: RemoveMessage åˆ é™¤åèƒ½æ¢å¤å—ï¼Ÿ

**ä¸èƒ½ï¼** `RemoveMessage` æ˜¯æ°¸ä¹…æ“ä½œã€‚å¦‚æœéœ€è¦ä¿ç•™å†å²ï¼š

```python
# âŒ é”™è¯¯ï¼šç›´æ¥åˆ é™¤
return {"messages": [RemoveMessage(id=msg.id)]}

# âœ… æ­£ç¡®ï¼šå…ˆå¤‡ä»½
archived_messages = state["messages"][:-10]  # ä¿å­˜åˆ°æ•°æ®åº“
to_remove = [RemoveMessage(id=m.id) for m in archived_messages]
return {"messages": to_remove}
```

### Q2: trim_messages ä¼šä¿®æ”¹åŸå§‹æ¶ˆæ¯å—ï¼Ÿ

**ä¸ä¼šï¼** `trim_messages` è¿”å›æ–°åˆ—è¡¨ï¼Œä¸ä¿®æ”¹è¾“å…¥ï¼š

```python
original = [msg1, msg2, msg3]
trimmed = trim_messages(original, max_tokens=50, token_counter=llm)

# original ä»ç„¶æ˜¯ [msg1, msg2, msg3]
# trimmed å¯èƒ½æ˜¯ [msg2, msg3]ï¼ˆæ–°åˆ—è¡¨ï¼‰
```

### Q3: å¦‚ä½•å¤„ç†ç³»ç»Ÿæ¶ˆæ¯ï¼Ÿ

**æœ€ä½³å®è·µï¼š** å§‹ç»ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼Œå•ç‹¬å¤„ç†ï¼š

```python
def smart_trim(messages, max_tokens):
    system = [m for m in messages if isinstance(m, SystemMessage)]
    others = [m for m in messages if not isinstance(m, SystemMessage)]

    # åªè£å‰ªéç³»ç»Ÿæ¶ˆæ¯
    system_tokens = sum(llm.get_num_tokens(m.content) for m in system)
    trimmed_others = trim_messages(
        others,
        max_tokens=max_tokens - system_tokens,
        token_counter=llm
    )

    return system + trimmed_others
```

### Q4: allow_partial=True ä¼šæˆªæ–­åˆ°ä»€ä¹ˆä½ç½®ï¼Ÿ

**ç­”ï¼š** æˆªæ–­åˆ°æ°å¥½è¾¾åˆ° `max_tokens` çš„ä½ç½®ï¼š

```python
message = HumanMessage("This is a very long message with many words...")
# å‡è®¾è¿™æ¡æ¶ˆæ¯æœ‰ 150 tokens

trimmed = trim_messages(
    [message],
    max_tokens=100,
    allow_partial=True,
    token_counter=llm
)

# ç»“æœï¼šæ¶ˆæ¯è¢«æˆªæ–­åˆ°çº¦ 100 tokens
# "This is a very long message with..."
```

**æ³¨æ„ï¼š** æˆªæ–­å¯èƒ½å¯¼è‡´è¯­ä¹‰ä¸å®Œæ•´ï¼Œè°¨æ…ä½¿ç”¨ï¼

### Q5: å¦‚ä½•ç»Ÿè®¡ Token æ•°é‡ï¼Ÿ

ä½¿ç”¨æ¨¡å‹çš„ `get_num_tokens` æ–¹æ³•ï¼š

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-5-nano")

# å•æ¡æ¶ˆæ¯
message = HumanMessage("Hello, world!")
tokens = llm.get_num_tokens(message.content)
print(f"Tokens: {tokens}")

# æ¶ˆæ¯åˆ—è¡¨
messages = [HumanMessage("Hi"), AIMessage("Hello!")]
total_tokens = llm.get_num_tokens_from_messages(messages)
print(f"Total tokens: {total_tokens}")
```

---

## ğŸ“– æ‰©å±•é˜…è¯»

- [LangChain Messages å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs/modules/model_io/chat/message_types)
- [trim_messages API æ–‡æ¡£](https://python.langchain.com/docs/how_to/trim_messages/)
- [LangGraph State ç®¡ç†](https://langchain-ai.github.io/langgraph/concepts/state/)
- [Token è®¡ç®—è¯¦è§£](https://platform.openai.com/tokenizer)

---

## å®Œæ•´æ¡ˆä¾‹ä»£ç ï¼ˆå¯ç›´æ¥è¿è¡Œï¼‰

ä»¥ä¸‹æ˜¯ä¸€ä¸ªå®Œæ•´çš„æ¶ˆæ¯è¿‡æ»¤å’Œè£å‰ªç¤ºä¾‹ï¼Œæ¼”ç¤ºä¸‰ç§æ¶ˆæ¯ç®¡ç†æŠ€æœ¯ï¼š

```python
## å®Œæ•´æ¡ˆä¾‹ä»£ç ï¼ˆå¯ç›´æ¥è¿è¡Œï¼‰
from typing import Annotated
from typing_extensions import TypedDict
from IPython.display import Image, display
from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage, HumanMessage, RemoveMessage, trim_messages
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.graph.message import add_messages

# 1. åˆå§‹åŒ– LLM
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# 2. æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨ RemoveMessage åˆ é™¤æ—§æ¶ˆæ¯
def filter_messages_node(state: MessagesState):
    """åˆ é™¤é™¤æœ€å 2 æ¡æ¶ˆæ¯å¤–çš„æ‰€æœ‰æ¶ˆæ¯"""
    messages = state["messages"]
    if len(messages) > 2:
        delete_messages = [RemoveMessage(id=m.id) for m in messages[:-2]]
        return {"messages": delete_messages}
    return {}

# 3. æ–¹æ¡ˆäºŒï¼šæ¶ˆæ¯è¿‡æ»¤ï¼ˆä¸ä¿®æ”¹çŠ¶æ€ï¼‰
def chat_with_filter(state: MessagesState):
    """åªä¼ é€’æœ€å 3 æ¡æ¶ˆæ¯ç»™ LLMï¼Œä½†ä¿ç•™å®Œæ•´å†å²"""
    # åªå–æœ€å 3 æ¡æ¶ˆæ¯ä¼ ç»™ LLM
    recent_messages = state["messages"][-3:]
    response = llm.invoke(recent_messages)
    return {"messages": [response]}

# 4. æ–¹æ¡ˆä¸‰ï¼šToken è£å‰ª
def chat_with_trim(state: MessagesState):
    """ä½¿ç”¨ trim_messages åŸºäº token æ•°é‡æ™ºèƒ½è£å‰ª"""
    # è£å‰ªåˆ°æœ€å¤š 200 tokens
    trimmed = trim_messages(
        state["messages"],
        max_tokens=200,
        strategy="last",        # ä¿ç•™æœ€åçš„æ¶ˆæ¯
        token_counter=llm,      # ä½¿ç”¨ LLM è®¡æ•° tokens
        allow_partial=False     # ä¸æˆªæ–­å•æ¡æ¶ˆæ¯
    )
    response = llm.invoke(trimmed)
    return {"messages": [response]}

# 5. æ„å»ºæ¼”ç¤ºå›¾ï¼ˆä½¿ç”¨æ–¹æ¡ˆäºŒï¼šæ¶ˆæ¯è¿‡æ»¤ï¼‰
builder = StateGraph(MessagesState)
builder.add_node("chat", chat_with_filter)
builder.add_edge(START, "chat")
builder.add_edge("chat", END)

graph = builder.compile()

# 6. å¯è§†åŒ–å›¾ç»“æ„
print("=== å›¾ç»“æ„ ===")
display(Image(graph.get_graph().draw_mermaid_png()))

# 7. åˆ›å»ºæ¨¡æ‹Ÿå¯¹è¯å†å²
messages = [
    AIMessage("Hi! How can I help you today?", name="Bot", id="1"),
    HumanMessage("I'm researching ocean mammals.", name="User", id="2"),
    AIMessage("That's fascinating! What would you like to know?", name="Bot", id="3"),
    HumanMessage("Tell me about whales.", name="User", id="4"),
    AIMessage("Whales are amazing marine mammals...", name="Bot", id="5"),
    HumanMessage("What about dolphins?", name="User", id="6"),
]

# 8. æ¼”ç¤º trim_messages çš„æ•ˆæœ
print("\n=== trim_messages æ¼”ç¤º ===")
print(f"åŸå§‹æ¶ˆæ¯æ•°: {len(messages)}")

trimmed = trim_messages(
    messages,
    max_tokens=100,
    strategy="last",
    token_counter=llm,
    allow_partial=False
)
print(f"è£å‰ªåæ¶ˆæ¯æ•°: {len(trimmed)}")
print("è£å‰ªåçš„æ¶ˆæ¯:")
for m in trimmed:
    print(f"  - {m.__class__.__name__}: {m.content[:50]}...")

# 9. æ‰§è¡Œå¯¹è¯
print("\n=== æ‰§è¡Œå¯¹è¯ ===")
result = graph.invoke({"messages": messages})

print("\n=== æœ€ç»ˆç»“æœ ===")
print(f"æ¶ˆæ¯æ€»æ•°: {len(result['messages'])}")
print("æœ€æ–°å›å¤:")
result['messages'][-1].pretty_print()

print("\n=== æ¶ˆæ¯ç®¡ç†æ¼”ç¤ºæˆåŠŸï¼===")
print("é€šè¿‡æ¶ˆæ¯è¿‡æ»¤ï¼ŒLLM åªçœ‹åˆ°æœ€å 3 æ¡æ¶ˆæ¯ï¼Œä½†å®Œæ•´å†å²è¢«ä¿ç•™")
```

---

## ğŸ“ æ€»ç»“

æ¶ˆæ¯ç®¡ç†æ˜¯æ„å»ºç”Ÿäº§çº§èŠå¤©åº”ç”¨çš„å…³é”®æŠ€èƒ½ã€‚æœ¬æ•™ç¨‹ä»‹ç»äº†ä¸‰ç§æ ¸å¿ƒæŠ€æœ¯ï¼š

| æŠ€æœ¯ | æ ¸å¿ƒä»·å€¼ | ä½¿ç”¨åœºæ™¯ |
|------|---------|---------|
| **RemoveMessage** | æ°¸ä¹…åˆ é™¤ï¼ŒèŠ‚çœå†…å­˜ | ç¡®å®šä¸éœ€è¦çš„å†å² |
| **æ¶ˆæ¯è¿‡æ»¤** | ç®€å•é«˜æ•ˆï¼Œä¸ä¿®æ”¹çŠ¶æ€ | å¿«é€ŸåŸå‹ï¼Œå›ºå®šè§„åˆ™ |
| **Token è£å‰ª** | ç²¾ç¡®æ§åˆ¶æˆæœ¬ | ç”Ÿäº§ç¯å¢ƒï¼Œå˜é•¿æ¶ˆæ¯ |

**å…³é”®è¦ç‚¹ï¼š**

1. **ç†è§£åœºæ™¯**ï¼šæ ¹æ®åº”ç”¨éœ€æ±‚é€‰æ‹©åˆé€‚çš„æŠ€æœ¯
2. **ä¿ç•™çµæ´»æ€§**ï¼šçŠ¶æ€ä¿ç•™å®Œæ•´å†å²ï¼Œåªåœ¨ä¼ é€’ç»™ LLM æ—¶è£å‰ª
3. **ç»„åˆä½¿ç”¨**ï¼šå®é™…åº”ç”¨ä¸­å¸¸å¸¸éœ€è¦ç»„åˆå¤šç§æŠ€æœ¯
4. **ç›‘æ§ Token**ï¼šä½¿ç”¨ LangSmith è¿½è¸ªå®é™… token ä½¿ç”¨æƒ…å†µ
5. **æ¸è¿›ä¼˜åŒ–**ï¼šä»ç®€å•æ–¹æ¡ˆå¼€å§‹ï¼Œæ ¹æ®éœ€æ±‚é€æ­¥ä¼˜åŒ–

é€šè¿‡æŒæ¡è¿™äº›æŠ€æœ¯ï¼Œä½ å¯ä»¥æ„å»ºæ—¢é«˜æ•ˆåˆç»æµçš„é•¿æœŸè®°å¿†èŠå¤©æœºå™¨äººï¼
