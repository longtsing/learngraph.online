# LangGraph Map-Reduce è¯¦ç»†è§£è¯»

## ğŸ“š æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è§£è¯» LangGraph ä¸­çš„ **Map-Reduce** æ¨¡å¼ã€‚è¿™æ˜¯ä¸€ç§ç»å…¸çš„åˆ†å¸ƒå¼è®¡ç®—æ¨¡å¼ï¼Œåœ¨ LangGraph ä¸­ç”¨äºé«˜æ•ˆçš„ä»»åŠ¡åˆ†è§£å’Œå¹¶è¡Œå¤„ç†ã€‚é€šè¿‡ Map-Reduceï¼Œæˆ‘ä»¬å¯ä»¥å°†å¤æ‚ä»»åŠ¡æ‹†åˆ†æˆå¤šä¸ªå­ä»»åŠ¡å¹¶è¡Œæ‰§è¡Œï¼Œç„¶åèšåˆç»“æœã€‚

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ Map-Reduceï¼Ÿ

Map-Reduce æ˜¯ä¸€ç§ç¼–ç¨‹æ¨¡å‹ï¼ŒåŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼š

1. **Mapï¼ˆæ˜ å°„ï¼‰é˜¶æ®µ**
   - å°†å¤§ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå°çš„å­ä»»åŠ¡
   - å¹¶è¡Œå¤„ç†æ¯ä¸ªå­ä»»åŠ¡
   - æ¯ä¸ªå­ä»»åŠ¡ç‹¬ç«‹æ‰§è¡Œï¼Œäº’ä¸å½±å“

2. **Reduceï¼ˆå½’çº¦ï¼‰é˜¶æ®µ**
   - æ”¶é›†æ‰€æœ‰å­ä»»åŠ¡çš„ç»“æœ
   - å¯¹ç»“æœè¿›è¡Œèšåˆã€æ±‡æ€»æˆ–ç­›é€‰
   - äº§ç”Ÿæœ€ç»ˆè¾“å‡º

### ç»å…¸åº”ç”¨åœºæ™¯

- **æ–‡æ¡£å¤„ç†**ï¼šåˆ†æ®µå¤„ç†é•¿æ–‡æ¡£ï¼Œç„¶åæ±‡æ€»æ‘˜è¦
- **æ•°æ®åˆ†æ**ï¼šå¹¶è¡Œåˆ†æå¤šä¸ªæ•°æ®æºï¼Œèšåˆç»Ÿè®¡ç»“æœ
- **å†…å®¹ç”Ÿæˆ**ï¼šç”Ÿæˆå¤šä¸ªå€™é€‰å†…å®¹ï¼Œé€‰æ‹©æœ€ä½³ç»“æœ
- **å¤šæºæŸ¥è¯¢**ï¼šå¹¶è¡ŒæŸ¥è¯¢å¤šä¸ª APIï¼Œåˆå¹¶ç»“æœ

---

## ğŸ­ å®æˆ˜æ¡ˆä¾‹ï¼šç¬‘è¯ç”Ÿæˆç³»ç»Ÿ

æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªæ™ºèƒ½ç¬‘è¯ç”Ÿæˆç³»ç»Ÿï¼Œæ¼”ç¤º Map-Reduce çš„å®Œæ•´æµç¨‹ï¼š

**éœ€æ±‚ï¼š**
1. **Map é˜¶æ®µ**ï¼šæ ¹æ®ä¸€ä¸ªä¸»é¢˜ï¼ˆå¦‚"åŠ¨ç‰©"ï¼‰ï¼Œç”Ÿæˆå¤šä¸ªå­ä¸»é¢˜çš„ç¬‘è¯
2. **Reduce é˜¶æ®µ**ï¼šä»æ‰€æœ‰ç”Ÿæˆçš„ç¬‘è¯ä¸­ï¼Œé€‰å‡ºæœ€å¥½çš„ä¸€ä¸ª

### ç³»ç»Ÿæ¶æ„å›¾

```
ç”¨æˆ·è¾“å…¥ä¸»é¢˜ "animals"
        â†“
   [generate_topics] ç”Ÿæˆå­ä¸»é¢˜: [mammals, reptiles, birds]
        â†“
    (Send API åŠ¨æ€åˆ†å‘)
        â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
   â†“        â†“        â†“        â†“
[joke-1] [joke-2] [joke-3]  (Map é˜¶æ®µï¼šå¹¶è¡Œç”Ÿæˆ)
   â†“        â†“        â†“
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
        [best_joke]  (Reduce é˜¶æ®µï¼šé€‰æ‹©æœ€ä½³)
             â†“
         è¿”å›ç»“æœ
```

---

## ğŸ”§ ä»£ç å®ç°è¯¦è§£

### 1. å®šä¹‰æç¤ºè¯å’Œæ¨¡å‹

```python
from langchain_openai import ChatOpenAI

# ä¸‰ä¸ªå…³é”®æç¤ºè¯
subjects_prompt = """Generate a list of 3 sub-topics that are all related to this overall topic: {topic}."""
joke_prompt = """Generate a joke about {subject}"""
best_joke_prompt = """Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one, starting 0 as the ID for the first joke. Jokes: \n\n  {jokes}"""

# åˆå§‹åŒ– LLM
model = ChatOpenAI(model="gpt-5-nano", temperature=0)
```

**è¯´æ˜ï¼š**
- `subjects_prompt`ï¼šå°†ä¸»é¢˜æ‹†åˆ†ä¸º 3 ä¸ªå­ä¸»é¢˜
- `joke_prompt`ï¼šä¸ºå•ä¸ªå­ä¸»é¢˜ç”Ÿæˆç¬‘è¯
- `best_joke_prompt`ï¼šä»å¤šä¸ªç¬‘è¯ä¸­é€‰æ‹©æœ€å¥½çš„

---

### 2. å®šä¹‰çŠ¶æ€ï¼ˆStateï¼‰

è¿™æ˜¯ Map-Reduce çš„å…³é”®ï¼æˆ‘ä»¬éœ€è¦ä¸¤ç§çŠ¶æ€ï¼š

#### å…¨å±€çŠ¶æ€ï¼ˆOverallStateï¼‰

```python
import operator
from typing import Annotated
from typing_extensions import TypedDict
from pydantic import BaseModel

class Subjects(BaseModel):
    subjects: list[str]

class BestJoke(BaseModel):
    id: int

class OverallState(TypedDict):
    topic: str                                  # ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜
    subjects: list                               # ç”Ÿæˆçš„å­ä¸»é¢˜åˆ—è¡¨
    jokes: Annotated[list, operator.add]        # æ”¶é›†çš„ç¬‘è¯ï¼ˆæ”¯æŒå¹¶è¡Œè¿½åŠ ï¼‰
    best_selected_joke: str                     # æœ€ç»ˆé€‰å‡ºçš„æœ€ä½³ç¬‘è¯
```

**å…³é”®ç‚¹ï¼š**
- `jokes` ä½¿ç”¨ `operator.add` reducerï¼Œå…è®¸å¤šä¸ªå¹¶è¡ŒèŠ‚ç‚¹åŒæ—¶å†™å…¥
- è¿™ä¸ä¹‹å‰å­¦ä¹ çš„ parallelization çŸ¥è¯†ä¸€è‡´

#### å±€éƒ¨çŠ¶æ€ï¼ˆJokeStateï¼‰

```python
class JokeState(TypedDict):
    subject: str  # å•ä¸ªç¬‘è¯ç”ŸæˆèŠ‚ç‚¹åªéœ€è¦çŸ¥é“ä¸»é¢˜

class Joke(BaseModel):
    joke: str
```

**Python çŸ¥è¯†ç‚¹ï¼šPydantic BaseModel**

`BaseModel` æ˜¯ Pydantic åº“çš„æ ¸å¿ƒç±»ï¼Œç”¨äºï¼š
- æ•°æ®éªŒè¯
- ç±»å‹æ£€æŸ¥
- ç»“æ„åŒ–è¾“å‡º

```python
# ä½¿ç”¨ç¤ºä¾‹
class Joke(BaseModel):
    joke: str

# LLM ä¼šè¿”å›ç¬¦åˆè¿™ä¸ªç»“æ„çš„æ•°æ®
response = model.with_structured_output(Joke).invoke(prompt)
# response.joke å°±æ˜¯å­—ç¬¦ä¸²ç±»å‹çš„ç¬‘è¯å†…å®¹
```

---

### 3. Map é˜¶æ®µï¼šç”Ÿæˆå­ä¸»é¢˜

```python
def generate_topics(state: OverallState):
    prompt = subjects_prompt.format(topic=state["topic"])
    response = model.with_structured_output(Subjects).invoke(prompt)
    return {"subjects": response.subjects}
```

**åŠŸèƒ½ï¼š** å°†ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜ï¼ˆå¦‚ "animals"ï¼‰åˆ†è§£ä¸º 3 ä¸ªå­ä¸»é¢˜ï¼ˆå¦‚ ["mammals", "reptiles", "birds"]ï¼‰

---

### 4. åŠ¨æ€ä»»åŠ¡åˆ†å‘ï¼šSend API â­

è¿™æ˜¯ Map-Reduce çš„**æ ¸å¿ƒé­”æ³•**ï¼

```python
from langgraph.types import Send

def continue_to_jokes(state: OverallState):
    # ä¸ºæ¯ä¸ªå­ä¸»é¢˜åˆ›å»ºä¸€ä¸ª Send ä»»åŠ¡
    return [Send("generate_joke", {"subject": s}) for s in state["subjects"]]
```

**Send API è¯¦è§£ï¼š**

```python
Send("generate_joke", {"subject": s})
#    ^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^
#    ç›®æ ‡èŠ‚ç‚¹åç§°      å‘é€çš„çŠ¶æ€æ•°æ®
```

**é‡è¦ç‰¹æ€§ï¼š**
1. **åŠ¨æ€å¹¶è¡ŒåŒ–**ï¼šè‡ªåŠ¨ä¸ºåˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ åˆ›å»ºå¹¶è¡Œä»»åŠ¡
2. **çŠ¶æ€çµæ´»æ€§**ï¼šå¯ä»¥å‘é€ä»»æ„çŠ¶æ€ï¼Œä¸éœ€è¦ä¸ `OverallState` å®Œå…¨åŒ¹é…
3. **è‡ªåŠ¨æ‰©å±•**ï¼šæ— è®ºæœ‰ 3 ä¸ªè¿˜æ˜¯ 300 ä¸ªå­ä¸»é¢˜ï¼Œéƒ½èƒ½è‡ªåŠ¨å¹¶è¡Œå¤„ç†

**ä¸ºä»€ä¹ˆå¼ºå¤§ï¼Ÿ**

ä¼ ç»Ÿæ–¹å¼éœ€è¦é¢„å…ˆçŸ¥é“æœ‰å¤šå°‘ä¸ªå¹¶è¡Œä»»åŠ¡ï¼Œè€Œ `Send` å¯ä»¥æ ¹æ®è¿è¡Œæ—¶æ•°æ®åŠ¨æ€åˆ›å»ºä»»åŠ¡ï¼š

```python
# å¦‚æœæœ‰ 3 ä¸ªä¸»é¢˜ï¼ŒSend ä¼šåˆ›å»º 3 ä¸ªå¹¶è¡Œä»»åŠ¡
subjects = ["mammals", "reptiles", "birds"]
# ç›¸å½“äºï¼š
# - Send("generate_joke", {"subject": "mammals"})
# - Send("generate_joke", {"subject": "reptiles"})
# - Send("generate_joke", {"subject": "birds"})

# å¦‚æœæœ‰ 10 ä¸ªä¸»é¢˜ï¼Œè‡ªåŠ¨åˆ›å»º 10 ä¸ªå¹¶è¡Œä»»åŠ¡ï¼
```

---

### 5. Map é˜¶æ®µï¼šå¹¶è¡Œç”Ÿæˆç¬‘è¯

```python
def generate_joke(state: JokeState):
    prompt = joke_prompt.format(subject=state["subject"])
    response = model.with_structured_output(Joke).invoke(prompt)
    return {"jokes": [response.joke]}
```

**å…³é”®ç»†èŠ‚ï¼š**
- è¾“å…¥ï¼š`JokeState`ï¼ˆåªåŒ…å« `subject`ï¼‰
- è¾“å‡ºï¼š`{"jokes": [response.joke]}`ï¼ˆæ³¨æ„æ˜¯åˆ—è¡¨ï¼ï¼‰
- è¿”å›çš„æ•°æ®ä¼šè¢«å†™å› `OverallState` çš„ `jokes` å­—æ®µ
- ç”±äº `jokes` æœ‰ `operator.add` reducerï¼Œå¤šä¸ªå¹¶è¡ŒèŠ‚ç‚¹çš„è¾“å‡ºä¼šè‡ªåŠ¨æ‹¼æ¥

**æ‰§è¡Œæµç¨‹ç¤ºæ„ï¼š**
```
generate_joke(subject="mammals")  â†’ è¿”å› {"jokes": ["joke1"]}
generate_joke(subject="reptiles") â†’ è¿”å› {"jokes": ["joke2"]}
generate_joke(subject="birds")    â†’ è¿”å› {"jokes": ["joke3"]}

æœ€ç»ˆ OverallState.jokes = ["joke1", "joke2", "joke3"]
```

---

### 6. Reduce é˜¶æ®µï¼šé€‰æ‹©æœ€ä½³ç¬‘è¯

```python
def best_joke(state: OverallState):
    # å°†æ‰€æœ‰ç¬‘è¯åˆå¹¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²
    jokes = "\n\n".join(state["jokes"])

    # è®© LLM é€‰æ‹©æœ€å¥½çš„ç¬‘è¯
    prompt = best_joke_prompt.format(topic=state["topic"], jokes=jokes)
    response = model.with_structured_output(BestJoke).invoke(prompt)

    # è¿”å›è¢«é€‰ä¸­çš„ç¬‘è¯
    return {"best_selected_joke": state["jokes"][response.id]}
```

**åŠŸèƒ½ï¼š**
- æ¥æ”¶æ‰€æœ‰å¹¶è¡Œç”Ÿæˆçš„ç¬‘è¯
- ä½¿ç”¨ LLM è¯„ä¼°å¹¶é€‰æ‹©æœ€ä½³ç¬‘è¯
- `BestJoke` æ¨¡å‹è¿”å›æœ€ä½³ç¬‘è¯çš„ç´¢å¼•ï¼ˆidï¼‰
- æ ¹æ®ç´¢å¼•ä» `state["jokes"]` ä¸­å–å‡ºæœ€ä½³ç¬‘è¯

---

### 7. æ„å»ºå›¾

```python
from langgraph.graph import END, StateGraph, START

# åˆ›å»ºå›¾
graph = StateGraph(OverallState)

# æ·»åŠ èŠ‚ç‚¹
graph.add_node("generate_topics", generate_topics)
graph.add_node("generate_joke", generate_joke)
graph.add_node("best_joke", best_joke)

# æ·»åŠ è¾¹
graph.add_edge(START, "generate_topics")

# æ¡ä»¶è¾¹ï¼šä½¿ç”¨ Send åŠ¨æ€åˆ†å‘ä»»åŠ¡
graph.add_conditional_edges("generate_topics", continue_to_jokes, ["generate_joke"])

graph.add_edge("generate_joke", "best_joke")
graph.add_edge("best_joke", END)

# ç¼–è¯‘
app = graph.compile()
```

**LangGraph çŸ¥è¯†ç‚¹ï¼šæ¡ä»¶è¾¹ä¸ Send**

```python
graph.add_conditional_edges("generate_topics", continue_to_jokes, ["generate_joke"])
#                          ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^
#                          æºèŠ‚ç‚¹             æ¡ä»¶å‡½æ•°             å¯èƒ½çš„ç›®æ ‡èŠ‚ç‚¹
```

- `continue_to_jokes` è¿”å› `Send` å¯¹è±¡åˆ—è¡¨
- LangGraph ä¼šè‡ªåŠ¨ä¸ºæ¯ä¸ª `Send` åˆ›å»ºä¸€ä¸ªåˆ° `generate_joke` çš„å¹¶è¡Œè·¯å¾„
- æ‰€æœ‰å¹¶è¡Œä»»åŠ¡å®Œæˆåï¼Œè‡ªåŠ¨è¿›å…¥ `best_joke` èŠ‚ç‚¹

---

### 8. æ‰§è¡Œå›¾

```python
for s in app.stream({"topic": "animals"}):
    print(s)
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```python
{'generate_topics': {'subjects': ['mammals', 'reptiles', 'birds']}}

{'generate_joke': {'jokes': ["Why don't mammals ever get lost? Because they always follow their 'instincts'!"]}}
{'generate_joke': {'jokes': ["Why don't alligators like fast food? Because they can't catch it!"]}}
{'generate_joke': {'jokes': ["Why do birds fly south for the winter? Because it's too far to walk!"]}}

{'best_joke': {'best_selected_joke': "Why don't alligators like fast food? Because they can't catch it!"}}
```

**è§‚å¯Ÿè¦ç‚¹ï¼š**
1. é¦–å…ˆç”Ÿæˆ 3 ä¸ªå­ä¸»é¢˜
2. ç„¶åå¹¶è¡Œç”Ÿæˆ 3 ä¸ªç¬‘è¯ï¼ˆæ³¨æ„è¾“å‡ºé¡ºåºå¯èƒ½ä¸åŒï¼‰
3. æœ€åé€‰å‡ºæœ€ä½³ç¬‘è¯

---

## ğŸ“ æ ¸å¿ƒçŸ¥è¯†ç‚¹æ€»ç»“

### LangGraph ç‰¹æœ‰æ¦‚å¿µ

#### 1. Send API

**ä½œç”¨ï¼š** åŠ¨æ€åˆ›å»ºå¹¶è¡Œä»»åŠ¡

```python
Send(node_name, state_dict)
```

**ç‰¹ç‚¹ï¼š**
- è¿è¡Œæ—¶åŠ¨æ€å†³å®šå¹¶è¡Œæ•°é‡
- å¯ä»¥å‘é€è‡ªå®šä¹‰çŠ¶æ€ï¼ˆä¸å¿…æ˜¯å®Œæ•´çš„å›¾çŠ¶æ€ï¼‰
- è‡ªåŠ¨å¤„ç†å¹¶è¡Œæ‰§è¡Œå’Œç»“æœèšåˆ

#### 2. Map-Reduce æ¨¡å¼

| é˜¶æ®µ | ä½œç”¨ | èŠ‚ç‚¹æ•°é‡ | æ‰§è¡Œæ–¹å¼ |
|------|------|---------|---------|
| **Map** | åˆ†è§£ä»»åŠ¡ï¼Œç”Ÿæˆç»“æœ | åŠ¨æ€ï¼ˆæ ¹æ®æ•°æ®ï¼‰ | å¹¶è¡Œ |
| **Reduce** | èšåˆç»“æœ | 1 ä¸ª | ä¸²è¡Œï¼ˆç­‰å¾…æ‰€æœ‰ Map å®Œæˆï¼‰ |

#### 3. å¤šçŠ¶æ€è®¾è®¡

- **OverallState**ï¼šå…¨å±€çŠ¶æ€ï¼Œè´¯ç©¿æ•´ä¸ªå›¾
- **JokeState**ï¼šå±€éƒ¨çŠ¶æ€ï¼Œåªç”¨äºç‰¹å®šèŠ‚ç‚¹
- é€šè¿‡ `Send` å¯ä»¥åœ¨ä¸åŒçŠ¶æ€ä¹‹é—´ä¼ é€’æ•°æ®

#### 4. æ¡ä»¶è¾¹ + Send

```python
graph.add_conditional_edges(
    "source_node",           # æºèŠ‚ç‚¹
    condition_function,      # è¿”å› Send åˆ—è¡¨çš„å‡½æ•°
    ["target_node"]         # ç›®æ ‡èŠ‚ç‚¹ï¼ˆSend æŒ‡å‘çš„èŠ‚ç‚¹ï¼‰
)
```

### Python ç‰¹æœ‰çŸ¥è¯†ç‚¹

#### 1. Pydantic BaseModel

```python
from pydantic import BaseModel

class Joke(BaseModel):
    joke: str

# ç”¨äº LLM ç»“æ„åŒ–è¾“å‡º
response = model.with_structured_output(Joke).invoke(prompt)
```

**ä¼˜åŠ¿ï¼š**
- è‡ªåŠ¨ç±»å‹éªŒè¯
- æ¸…æ™°çš„æ•°æ®ç»“æ„
- ä¸ LangChain æ— ç¼é›†æˆ

#### 2. TypedDict vs BaseModel

| ç‰¹æ€§ | TypedDict | BaseModel |
|------|-----------|-----------|
| ç±»å‹æ£€æŸ¥ | é™æ€ï¼ˆIDE æç¤ºï¼‰ | è¿è¡Œæ—¶éªŒè¯ |
| éªŒè¯ | æ—  | æœ‰ |
| ç”¨é€” | çŠ¶æ€å®šä¹‰ | æ•°æ®æ¨¡å‹ã€API è¾“å‡º |
| æ€§èƒ½ | æ›´å¿«ï¼ˆæ— éªŒè¯ï¼‰ | ç¨æ…¢ï¼ˆæœ‰éªŒè¯ï¼‰ |

```python
# TypedDict - ç”¨äº State
class OverallState(TypedDict):
    topic: str

# BaseModel - ç”¨äºç»“æ„åŒ–è¾“å‡º
class Joke(BaseModel):
    joke: str
```

#### 3. åˆ—è¡¨æ¨å¯¼å¼ + Send

```python
# åˆ›å»ºå¤šä¸ª Send ä»»åŠ¡çš„ä¼˜é›…æ–¹å¼
[Send("generate_joke", {"subject": s}) for s in subjects]

# ç­‰ä»·äºï¼š
result = []
for s in subjects:
    result.append(Send("generate_joke", {"subject": s}))
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ä½•æ—¶ä½¿ç”¨ Map-Reduceï¼Ÿ

âœ… **é€‚ç”¨åœºæ™¯ï¼š**
- éœ€è¦å¯¹å¤šä¸ªæ•°æ®é¡¹æ‰§è¡Œç›¸åŒæ“ä½œï¼ˆå¦‚æ‰¹é‡ç¿»è¯‘ã€æ‰¹é‡æ‘˜è¦ï¼‰
- ä»»åŠ¡å¯ä»¥è‡ªç„¶åˆ†è§£ä¸ºç‹¬ç«‹å­ä»»åŠ¡ï¼ˆå¦‚åˆ†æ®µå¤„ç†æ–‡æ¡£ï¼‰
- éœ€è¦ä»å¤šä¸ªå€™é€‰ç»“æœä¸­ç­›é€‰ï¼ˆå¦‚ç”Ÿæˆå¤šä¸ªç­”æ¡ˆé€‰æœ€ä½³ï¼‰
- æ•°æ®é‡å¤§ï¼Œéœ€è¦å¹¶è¡ŒåŠ é€Ÿï¼ˆå¦‚åˆ†æå¤šä¸ªæ•°æ®æºï¼‰

âŒ **ä¸é€‚ç”¨åœºæ™¯ï¼š**
- å­ä»»åŠ¡ä¹‹é—´æœ‰ä¾èµ–å…³ç³»
- æ— æ³•è‡ªç„¶åˆ†è§£çš„ä»»åŠ¡
- å•ä¸€æ•°æ®æºçš„ç®€å•æŸ¥è¯¢

### 2. Send API ä½¿ç”¨æŠ€å·§

#### æŠ€å·§ 1ï¼šåŠ¨æ€æ§åˆ¶å¹¶è¡Œæ•°é‡

```python
def continue_to_jokes(state: OverallState):
    # å¯ä»¥æ ¹æ®æ¡ä»¶è¿‡æ»¤
    subjects = [s for s in state["subjects"] if len(s) > 3]
    return [Send("generate_joke", {"subject": s}) for s in subjects]
```

#### æŠ€å·§ 2ï¼šå‘é€é¢å¤–ä¸Šä¸‹æ–‡

```python
def continue_to_jokes(state: OverallState):
    return [
        Send("generate_joke", {
            "subject": s,
            "original_topic": state["topic"],  # ä¼ é€’é¢å¤–ä¿¡æ¯
            "style": "family-friendly"
        })
        for s in state["subjects"]
    ]
```

#### æŠ€å·§ 3ï¼šæ¡ä»¶æ€§å‘é€

```python
def continue_to_jokes(state: OverallState):
    sends = []
    for i, s in enumerate(state["subjects"]):
        if i < 5:  # æœ€å¤šåªå¤„ç†å‰ 5 ä¸ª
            sends.append(Send("generate_joke", {"subject": s}))
    return sends
```

### 3. çŠ¶æ€è®¾è®¡åŸåˆ™

#### åŸåˆ™ 1ï¼šæœ€å°åŒ–å±€éƒ¨çŠ¶æ€

```python
# âœ… å¥½çš„è®¾è®¡ - åªåŒ…å«å¿…éœ€å­—æ®µ
class JokeState(TypedDict):
    subject: str

# âŒ ä¸å¥½çš„è®¾è®¡ - åŒ…å«ä¸éœ€è¦çš„å­—æ®µ
class JokeState(TypedDict):
    subject: str
    topic: str  # generate_joke ä¸éœ€è¦è¿™ä¸ª
    jokes: list  # ä¹Ÿä¸éœ€è¦è¿™ä¸ª
```

#### åŸåˆ™ 2ï¼šä½¿ç”¨ Reducer èšåˆç»“æœ

```python
# Map èŠ‚ç‚¹çš„è¾“å‡ºå­—æ®µå¿…é¡»æœ‰ reducer
class OverallState(TypedDict):
    jokes: Annotated[list, operator.add]  # âœ… æ­£ç¡®
    # jokes: list  # âŒ é”™è¯¯ï¼å¹¶è¡Œæ›´æ–°ä¼šå†²çª
```

#### åŸåˆ™ 3ï¼šæ¸…æ™°çš„çŠ¶æ€æµè½¬

```python
OverallState (å®Œæ•´çŠ¶æ€)
    â†“
Send â†’ JokeState (å­é›†)
    â†“
è¿”å› â†’ OverallState.jokes (éƒ¨åˆ†æ›´æ–°)
```

---

## ğŸš€ è¿›é˜¶æŠ€å·§

### 1. å¤šå±‚ Map-Reduce

å¯ä»¥åµŒå¥—å¤šä¸ª Map-Reduce å±‚æ¬¡ï¼š

```python
ä¸»é¢˜
 â†“ Map
å­ä¸»é¢˜ (Level 1)
 â†“ Map
è¯¦ç»†ä¸»é¢˜ (Level 2)
 â†“ Reduce
æ±‡æ€»å­ä¸»é¢˜
 â†“ Reduce
æœ€ç»ˆç»“æœ
```

### 2. å¸¦é”™è¯¯å¤„ç†çš„ Map-Reduce

```python
def generate_joke(state: JokeState):
    try:
        prompt = joke_prompt.format(subject=state["subject"])
        response = model.with_structured_output(Joke).invoke(prompt)
        return {"jokes": [response.joke]}
    except Exception as e:
        # è¿”å›é”™è¯¯æ ‡è®°æˆ–é»˜è®¤å€¼
        return {"jokes": [f"Error generating joke for {state['subject']}"]}
```

### 3. é™åˆ¶å¹¶è¡Œåº¦

è™½ç„¶ `Send` ä¼šè‡ªåŠ¨å¹¶è¡Œï¼Œä½†æœ‰æ—¶éœ€è¦é™åˆ¶åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡æ•°ï¼ˆå¦‚ API é€Ÿç‡é™åˆ¶ï¼‰ï¼š

```python
# æ–¹æ³• 1ï¼šåœ¨æ¡ä»¶å‡½æ•°ä¸­é™åˆ¶
def continue_to_jokes(state: OverallState):
    # åªå‘é€å‰ N ä¸ª
    max_parallel = 5
    subjects = state["subjects"][:max_parallel]
    return [Send("generate_joke", {"subject": s}) for s in subjects]

# æ–¹æ³• 2ï¼šåˆ†æ‰¹å¤„ç†ï¼ˆéœ€è¦æ›´å¤æ‚çš„å›¾è®¾è®¡ï¼‰
```

---

## ğŸ“Š Map-Reduce vs ç®€å•å¹¶è¡Œ

| ç‰¹æ€§ | Map-Reduce (Send) | ç®€å•å¹¶è¡Œ (Fan-out) |
|------|------------------|-------------------|
| å¹¶è¡Œæ•°é‡ | åŠ¨æ€ï¼ˆè¿è¡Œæ—¶å†³å®šï¼‰ | é™æ€ï¼ˆè®¾è®¡æ—¶å›ºå®šï¼‰ |
| çŠ¶æ€ä¼ é€’ | çµæ´»ï¼ˆå¯è‡ªå®šä¹‰ï¼‰ | å›ºå®šï¼ˆä½¿ç”¨å›¾çŠ¶æ€ï¼‰ |
| é€‚ç”¨åœºæ™¯ | åˆ—è¡¨å¤„ç†ã€æ‰¹é‡ä»»åŠ¡ | å›ºå®šæ•°é‡çš„å¹¶è¡Œè·¯å¾„ |
| å¤æ‚åº¦ | ä¸­ç­‰ | ä½ |
| æ‰©å±•æ€§ | é«˜ | ä½ |

**ç¤ºä¾‹å¯¹æ¯”ï¼š**

```python
# ç®€å•å¹¶è¡Œ - å›ºå®š 3 ä¸ªè·¯å¾„
builder.add_edge("start", "task1")
builder.add_edge("start", "task2")
builder.add_edge("start", "task3")

# Map-Reduce - åŠ¨æ€ N ä¸ªä»»åŠ¡
def send_tasks(state):
    return [Send("task", {"data": d}) for d in state["data_list"]]
builder.add_conditional_edges("start", send_tasks, ["task"])
```

---

## ğŸ¯ å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹ 1ï¼šæ–‡æ¡£æ‘˜è¦

```python
# Map: ä¸ºæ¯ä¸ªæ®µè½ç”Ÿæˆæ‘˜è¦
def summarize_chunk(state: ChunkState):
    summary = llm.invoke(f"Summarize: {state['chunk']}")
    return {"summaries": [summary]}

# Reduce: åˆå¹¶æ‰€æœ‰æ®µè½æ‘˜è¦
def combine_summaries(state: OverallState):
    all_summaries = "\n".join(state["summaries"])
    final = llm.invoke(f"Create final summary: {all_summaries}")
    return {"final_summary": final}
```

### æ¡ˆä¾‹ 2ï¼šå¤šè¯­è¨€ç¿»è¯‘

```python
# Map: ç¿»è¯‘åˆ°å¤šç§è¯­è¨€
def send_to_translate(state):
    languages = ["es", "fr", "de", "zh"]
    return [Send("translate", {"lang": lang, "text": state["text"]})
            for lang in languages]

# Reduce: æ”¶é›†æ‰€æœ‰ç¿»è¯‘
def collect_translations(state):
    return {"all_translations": state["translations"]}
```

### æ¡ˆä¾‹ 3ï¼šå¤šè§’åº¦åˆ†æ

```python
# Map: ä»ä¸åŒè§’åº¦åˆ†ææ–‡æœ¬
def send_to_analyze(state):
    perspectives = ["technical", "business", "user", "security"]
    return [Send("analyze", {"perspective": p, "text": state["text"]})
            for p in perspectives]

# Reduce: ç»¼åˆæ‰€æœ‰åˆ†æ
def synthesize(state):
    combined = llm.invoke(f"Synthesize these analyses: {state['analyses']}")
    return {"final_analysis": combined}
```

---

## ğŸ“– æ‰©å±•é˜…è¯»

- [LangGraph Map-Reduce å®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/)
- [Send API è¯¦ç»†è¯´æ˜](https://langchain-ai.github.io/langgraph/concepts/low_level/#send)
- [Pydantic å®˜æ–¹æ–‡æ¡£](https://docs.pydantic.dev/)

---

## ğŸ” å¸¸è§é—®é¢˜

### Q1: Send å’Œæ™®é€šè¾¹æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**æ™®é€šè¾¹ï¼š** é™æ€è·¯ç”±ï¼Œè®¾è®¡æ—¶ç¡®å®š
```python
graph.add_edge("A", "B")  # A æ€»æ˜¯æµå‘ B
```

**Sendï¼š** åŠ¨æ€è·¯ç”±ï¼Œè¿è¡Œæ—¶ç¡®å®š
```python
# æ ¹æ®æ•°æ®åŠ¨æ€åˆ›å»ºå¤šä¸ªå¹¶è¡Œä»»åŠ¡
return [Send("B", data) for data in dynamic_data]
```

### Q2: ä¸ºä»€ä¹ˆ generate_joke è¿”å› `{"jokes": [joke]}` è€Œä¸æ˜¯ `{"jokes": joke}`ï¼Ÿ

å› ä¸º `OverallState.jokes` ä½¿ç”¨äº† `operator.add` reducerï¼Œå®ƒæœŸæœ›æ“ä½œåˆ—è¡¨ï¼š

```python
# æ­£ç¡® âœ…
operator.add(["joke1"], ["joke2"])  # â†’ ["joke1", "joke2"]

# é”™è¯¯ âŒ
operator.add("joke1", "joke2")  # â†’ "joke1joke2" (å­—ç¬¦ä¸²æ‹¼æ¥)
```

### Q3: å¯ä»¥åœ¨ Send ä¸­å‘é€å®Œå…¨ä¸åŒçš„çŠ¶æ€å—ï¼Ÿ

å¯ä»¥ï¼`Send` å‘é€çš„çŠ¶æ€ä¸éœ€è¦ä¸ `OverallState` åŒ¹é…ï¼š

```python
# OverallState æœ‰ topic, subjects, jokes
# ä½† Send å¯ä»¥å‘é€ä»»æ„ç»“æ„
Send("generate_joke", {"subject": "cats", "style": "silly"})
```

åªè¦ç›®æ ‡èŠ‚ç‚¹ï¼ˆ`generate_joke`ï¼‰èƒ½å¤„ç†è¿™ä¸ªçŠ¶æ€å³å¯ã€‚

---

**æ€»ç»“**ï¼šMap-Reduce æ˜¯ LangGraph ä¸­å¤„ç†æ‰¹é‡ã€å¹¶è¡Œä»»åŠ¡çš„å¼ºå¤§æ¨¡å¼ã€‚é€šè¿‡ `Send` APIï¼Œæˆ‘ä»¬å¯ä»¥åŠ¨æ€åˆ›å»ºä»»æ„æ•°é‡çš„å¹¶è¡Œä»»åŠ¡ï¼Œç„¶åç”¨ reducer ä¼˜é›…åœ°èšåˆç»“æœã€‚è¿™æ˜¯æ„å»ºå¯æ‰©å±•ã€é«˜æ€§èƒ½ AI åº”ç”¨çš„å…³é”®æŠ€æœ¯ï¼
