# Module-5 å°ç»“å’Œå¤ä¹ ï¼šé«˜çº§å›¾æ¨¡å¼ç²¾é€šæŒ‡å—

> **æ¥è‡ªå›¾çµå¥–è·å¾—è€…çš„æ€»ç»“å¯„è¯­**
>
> "å½“ä½ å®Œæˆæœ¬ç« å­¦ä¹ ,ä½ å·²ç»æŒæ¡äº†æ„å»ºå¤æ‚ç³»ç»Ÿçš„å…³é”®æŠ€èƒ½ã€‚è®°ä½:ä¼˜ç§€çš„æ¶æ„å¸ˆä¸æ˜¯é€šè¿‡å¢åŠ å¤æ‚æ€§æ¥è§£å†³é—®é¢˜,è€Œæ˜¯é€šè¿‡æ­£ç¡®çš„æŠ½è±¡æ¥ç®€åŒ–å¤æ‚æ€§ã€‚ä½ ç°åœ¨æ‹¥æœ‰çš„å¹¶è¡ŒåŒ–ã€æ¨¡å—åŒ–ã€åˆ†æ²»ç­–ç•¥ç­‰å·¥å…·,æ­£æ˜¯å°†å¤æ‚ AI ç³»ç»Ÿå˜å¾—å¯ç®¡ç†ã€å¯æ‰©å±•çš„æ ¸å¿ƒæ­¦å™¨ã€‚åœ¨æœªæ¥çš„å·¥ä½œä¸­,å½“é¢å¯¹çœ‹ä¼¼æ— è§£çš„å¤æ‚éœ€æ±‚æ—¶,å›åˆ°è¿™äº›åŸºç¡€æ¨¡å¼,ä½ ä¼šå‘ç°é—®é¢˜å…¶å®æœ‰ç€ä¼˜é›…çš„è§£å†³æ–¹æ¡ˆã€‚"
>
> â€” *å¯å‘è‡ª Tony Hoare å¯¹è½¯ä»¶å·¥ç¨‹æœ¬è´¨çš„æ´å¯Ÿ*

---

## ğŸ“‹ æœ¬ç« æ ¸å¿ƒçŸ¥è¯†å›é¡¾

### å­¦ä¹ åœ°å›¾

```mermaid
graph TB
    A[é«˜çº§å›¾æ¨¡å¼ä½“ç³»] --> B[Parallelization]
    A --> C[Sub-graph]
    A --> D[Map-Reduce]
    A --> E[Research Assistant]
    
    B --> B1[Fan-out/Fan-in]
    B --> B2[Reduceræœºåˆ¶]
    B --> B3[å¹¶è¡ŒåŒæ­¥]
    
    C --> C1[çŠ¶æ€éš”ç¦»]
    C --> C2[output_schema]
    C --> C3[å­å›¾åµŒå¥—]
    
    D --> D1[Send API]
    D --> D2[åŠ¨æ€åˆ†å‘]
    D --> D3[Map/Reduceé˜¶æ®µ]
    
    E --> E1[Human-in-the-Loopé›†æˆ]
    E --> E2[å¤šå­å›¾ååŒ]
    E --> E3[RAGæ¨¡å¼]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#ffe1f5
    style D fill:#f5e1ff
    style E fill:#e1ffe1
```

### å››å¤§æ ¸å¿ƒæŠ€æœ¯é€ŸæŸ¥è¡¨

| æŠ€æœ¯ | æ ¸å¿ƒAPI | ä¸»è¦ç”¨é€” | éš¾åº¦ |
|------|---------|---------|------|
| **Parallelization** | `Annotated[list, operator.add]` | å¹¶è¡Œæ‰§è¡Œæå‡æ€§èƒ½ | â­â­â­ |
| **Sub-graph** | `StateGraph(state, output_schema)` | æ¨¡å—åŒ–è®¾è®¡ | â­â­â­â­ |
| **Map-Reduce** | `Send("node", state)` | å¤§è§„æ¨¡ä»»åŠ¡åˆ†è§£ | â­â­â­â­â­ |
| **Research Assistant** | æ‰€æœ‰æ¨¡å¼é›†æˆ | ç”Ÿäº§çº§ç³»ç»Ÿæ¶æ„ | â­â­â­â­â­ |

---

## ğŸ¯ å¤ä¹ é¢˜ç›®åˆ—è¡¨

æœ¬ç« ç²¾å¿ƒè®¾è®¡äº† **10 é“ç»¼åˆæ€§é—®é¢˜**,æ¶µç›–æ‰€æœ‰æ ¸å¿ƒçŸ¥è¯†ç‚¹ã€‚å»ºè®®æŒ‰é¡ºåºå®Œæˆ,æ¯é“é¢˜é¢„è®¡è€—æ—¶ 20-40 åˆ†é’Ÿã€‚

### åŸºç¡€ç†è§£ï¼ˆé—®é¢˜ 1-3ï¼‰
1. Reducer æœºåˆ¶çš„å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆå¹¶è¡Œæ‰§è¡Œå¿…é¡»ä½¿ç”¨ Reducerï¼Ÿ
2. Sub-graph çš„ state_schema å’Œ output_schema æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿå„è‡ªçš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ
3. Send API ä¸ä¼ ç»Ÿçš„ add_edge æœ‰ä»€ä¹ˆæœ¬è´¨åŒºåˆ«ï¼Ÿ

### å®æˆ˜åº”ç”¨ï¼ˆé—®é¢˜ 4-7ï¼‰
4. å¦‚ä½•å®ç°ä¸€ä¸ªæ”¯æŒå¹¶è¡Œæ£€ç´¢å¤šä¸ªæ•°æ®æºçš„é—®ç­”ç³»ç»Ÿï¼Ÿ
5. å¦‚ä½•è®¾è®¡ä¸€ä¸ªæ¨¡å—åŒ–çš„å¤šæ­¥éª¤å®¡æ‰¹æµç¨‹ï¼ˆä½¿ç”¨å­å›¾ï¼‰ï¼Ÿ
6. å¦‚ä½•ä½¿ç”¨ Map-Reduce å¤„ç†å¤§è§„æ¨¡æ–‡æ¡£æ‰¹é‡æ‘˜è¦ä»»åŠ¡ï¼Ÿ
7. å®ç°ä¸€ä¸ªç®€åŒ–ç‰ˆçš„ Research Assistant ç³»ç»Ÿ

### é«˜çº§ç»¼åˆï¼ˆé—®é¢˜ 8-10ï¼‰
8. å¦‚ä½•ä¼˜åŒ– Map-Reduce çš„æ€§èƒ½ä»¥æ”¯æŒæ•°åƒä¸ªå¹¶å‘ä»»åŠ¡ï¼Ÿ
9. å­å›¾åµŒå¥—çš„æœ€ä½³å®è·µæ˜¯ä»€ä¹ˆï¼Ÿå¦‚ä½•é¿å…å¸¸è§é™·é˜±ï¼Ÿ
10. è®¾è®¡ä¸€ä¸ªå®Œæ•´çš„ä¼ä¸šçº§å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿæ¶æ„

---

## ğŸ“š è¯¦ç»†é—®ç­”è§£æ

### é—®é¢˜ 1: Reducer æœºåˆ¶çš„å·¥ä½œåŸç†

<details>
<summary><b>å±•å¼€æŸ¥çœ‹å®Œæ•´è§£æ</b></summary>

#### æ ¸å¿ƒé—®é¢˜

**ä¸ºä»€ä¹ˆéœ€è¦ Reducerï¼Ÿ**

å½“å¤šä¸ªå¹¶è¡ŒèŠ‚ç‚¹è¯•å›¾åŒæ—¶æ›´æ–°çŠ¶æ€çš„åŒä¸€ä¸ªå­—æ®µæ—¶,LangGraph éœ€è¦çŸ¥é“å¦‚ä½•åˆå¹¶è¿™äº›æ›´æ–°ã€‚æ²¡æœ‰ Reducer,ç³»ç»Ÿä¼šæŠ›å‡º `InvalidUpdateError`ã€‚

#### Reducer å·¥ä½œæœºåˆ¶

**åŸºæœ¬åŸç†:**
```python
# å¹¶è¡ŒèŠ‚ç‚¹ B è¿”å›
update_b = {"results": ["result_from_B"]}

# å¹¶è¡ŒèŠ‚ç‚¹ C è¿”å›
update_c = {"results": ["result_from_C"]}

# Reducer å‡½æ•°è¢«è°ƒç”¨
def reducer(current_value, new_value):
    return current_value + new_value

# æœ€ç»ˆçŠ¶æ€
state["results"] = reducer(["result_from_B"], ["result_from_C"])
# ç»“æœ: ["result_from_B", "result_from_C"]
```

#### å®Œæ•´ç¤ºä¾‹ï¼šå¹¶è¡Œæœç´¢

```python
import operator
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END

# çŠ¶æ€å®šä¹‰
class SearchState(TypedDict):
    query: str
    results: Annotated[list, operator.add]  # â­ Reducer

# èŠ‚ç‚¹å‡½æ•°
def search_wikipedia(state):
    query = state["query"]
    results = wikipedia_api.search(query)
    return {"results": [f"Wikipedia: {results}"]}

def search_web(state):
    query = state["query"]
    results = web_search_api.search(query)
    return {"results": [f"Web: {results}"]}

def search_database(state):
    query = state["query"]
    results = database.query(query)
    return {"results": [f"DB: {results}"]}

# æ„å»ºå›¾
builder = StateGraph(SearchState)
builder.add_node("search_wikipedia", search_wikipedia)
builder.add_node("search_web", search_web)
builder.add_node("search_database", search_database)

# å¹¶è¡Œæ‰§è¡Œ
builder.add_edge(START, "search_wikipedia")
builder.add_edge(START, "search_web")
builder.add_edge(START, "search_database")
builder.add_edge("search_wikipedia", END)
builder.add_edge("search_web", END)
builder.add_edge("search_database", END)

graph = builder.compile()

# æ‰§è¡Œ
result = graph.invoke({"query": "LangGraph"})
print(result["results"])
# è¾“å‡º: [
#   "Wikipedia: ...",
#   "Web: ...",
#   "DB: ..."
# ]
```

#### å¸¸ç”¨ Reducer ç±»å‹

**1. operator.add - åˆ—è¡¨æ‹¼æ¥**
```python
from operator import add

class State(TypedDict):
    items: Annotated[list, add]

# [1, 2] + [3, 4] = [1, 2, 3, 4]
```

**2. add_messages - æ¶ˆæ¯åˆå¹¶**
```python
from langgraph.graph import add_messages

class State(TypedDict):
    messages: Annotated[list, add_messages]

# ç‰¹æ®ŠåŠŸèƒ½:
# - ç›¸åŒ ID çš„æ¶ˆæ¯ä¼šè¢«è¦†ç›–
# - RemoveMessage ä¼šåˆ é™¤æ¶ˆæ¯
# - è‡ªåŠ¨å»é‡å’Œæ’åº
```

**3. è‡ªå®šä¹‰ Reducer - æ’åºåˆå¹¶**
```python
def sorted_merge(left, right):
    """æŒ‰ä¼˜å…ˆçº§æ’åºåˆå¹¶"""
    left = left if isinstance(left, list) else [left]
    right = right if isinstance(right, list) else [right]
    
    combined = left + right
    return sorted(combined, key=lambda x: x.get("priority", 0), reverse=True)

class State(TypedDict):
    tasks: Annotated[list, sorted_merge]
```

**4. è‡ªå®šä¹‰ Reducer - åªä¿ç•™æœ€æ–° N ä¸ª**
```python
def keep_last_n(n=5):
    def reducer(left, right):
        left = left if isinstance(left, list) else [left]
        right = right if isinstance(right, list) else [right]
        combined = left + right
        return combined[-n:]  # åªä¿ç•™æœ€å n ä¸ª
    return reducer

class State(TypedDict):
    history: Annotated[list, keep_last_n(10)]
```

**5. è‡ªå®šä¹‰ Reducer - å»é‡**
```python
def unique_merge(left, right):
    """å»é‡åˆå¹¶"""
    left = left if isinstance(left, list) else [left]
    right = right if isinstance(right, list) else [right]
    
    # ä½¿ç”¨å­—å…¸å»é‡,ä¿æŒé¡ºåº
    seen = {}
    for item in left + right:
        key = item.get("id", str(item))
        if key not in seen:
            seen[key] = item
    
    return list(seen.values())

class State(TypedDict):
    unique_results: Annotated[list, unique_merge]
```

#### æ‰§è¡Œé¡ºåºé—®é¢˜

**é—®é¢˜:** Reducer åˆå¹¶çš„é¡ºåºæ˜¯å¦ç¡®å®šï¼Ÿ

```python
# èŠ‚ç‚¹ B å’Œ C å¹¶è¡Œæ‰§è¡Œ
# å“ªä¸ªå…ˆå®Œæˆï¼Ÿé¡ºåºä¸ç¡®å®š

# å¦‚æœéœ€è¦ç¡®å®šé¡ºåº,ä½¿ç”¨è‡ªå®šä¹‰ Reducer
def ordered_merge(left, right):
    left = left if isinstance(left, list) else [left]
    right = right if isinstance(right, list) else [right]
    
    # æŒ‰æ—¶é—´æˆ³æˆ– ID æ’åº
    combined = left + right
    return sorted(combined, key=lambda x: x.get("timestamp"))
```

#### æœ€ä½³å®è·µ

**1. æ€»æ˜¯ä½¿ç”¨ Reducer å¤„ç†å¹¶è¡Œæ›´æ–°**
```python
# âŒ é”™è¯¯:æ²¡æœ‰ Reducer
class State(TypedDict):
    results: list  # å¹¶è¡Œæ›´æ–°ä¼šå¤±è´¥

# âœ… æ­£ç¡®:ä½¿ç”¨ Reducer
class State(TypedDict):
    results: Annotated[list, operator.add]
```

**2. é€‰æ‹©åˆé€‚çš„ Reducer**
```python
# ç®€å•è¿½åŠ  â†’ operator.add
# æ¶ˆæ¯ç®¡ç† â†’ add_messages
# å¤æ‚é€»è¾‘ â†’ è‡ªå®šä¹‰ Reducer
```

**3. Reducer åº”è¯¥æ˜¯å¹‚ç­‰çš„**
```python
# âœ… å¹‚ç­‰:å¤šæ¬¡è°ƒç”¨ç»“æœç›¸åŒ
def idempotent_reducer(left, right):
    # ä½¿ç”¨ ID å»é‡
    return list({item["id"]: item for item in left + right}.values())

# âŒ éå¹‚ç­‰:ä¾èµ–å¤–éƒ¨çŠ¶æ€
global_counter = 0
def non_idempotent_reducer(left, right):
    global global_counter
    global_counter += 1  # å‰¯ä½œç”¨
    return left + right
```

</details>

---

### é—®é¢˜ 2: state_schema å’Œ output_schema çš„åŒºåˆ«

<details>
<summary><b>å±•å¼€æŸ¥çœ‹å®Œæ•´è§£æ</b></summary>

#### æ ¸å¿ƒæ¦‚å¿µ

**state_schema:** å­å›¾å†…éƒ¨ä½¿ç”¨çš„å®Œæ•´çŠ¶æ€  
**output_schema:** å­å›¾è¿”å›ç»™ä¸»å›¾çš„è¾“å‡ºçŠ¶æ€(é€šå¸¸æ˜¯ state_schema çš„å­é›†)

#### è¯¦ç»†å¯¹æ¯”

| ç»´åº¦ | state_schema | output_schema |
|------|--------------|---------------|
| **ä½œç”¨åŸŸ** | å­å›¾å†…éƒ¨ | å­å›¾ä¸ä¸»å›¾ä¹‹é—´ |
| **å­—æ®µæ•°é‡** | å®Œæ•´(åŒ…å«æ‰€æœ‰ä¸­é—´å˜é‡) | éƒ¨åˆ†(åªåŒ…å«éœ€è¦è¿”å›çš„) |
| **å¯è§æ€§** | åªåœ¨å­å›¾å†…å¯è§ | ä¸»å›¾å¯ä»¥è®¿é—® |
| **å¿…éœ€æ€§** | å¿…éœ€ | å¯é€‰(é»˜è®¤è¿”å›æ‰€æœ‰å­—æ®µ) |

#### ä¸ºä»€ä¹ˆéœ€è¦ output_schemaï¼Ÿ

**é—®é¢˜åœºæ™¯:**
```python
# å­å›¾æœ‰å¾ˆå¤šä¸­é—´å˜é‡
class SubGraphState(TypedDict):
    input: str
    temp1: str       # ä¸­é—´å˜é‡
    temp2: int       # ä¸­é—´å˜é‡
    temp3: list      # ä¸­é—´å˜é‡
    cache: dict      # ä¸­é—´å˜é‡
    debug_info: str  # ä¸­é—´å˜é‡
    result: str      # æœ€ç»ˆç»“æœ

# å¦‚æœæ²¡æœ‰ output_schema,æ‰€æœ‰å­—æ®µéƒ½ä¼šè¿”å›ä¸»å›¾
# ä¸»å›¾çŠ¶æ€ä¼šè¢«æ±¡æŸ“,å……æ»¡ä¸éœ€è¦çš„å­—æ®µ
```

**è§£å†³æ–¹æ¡ˆ:**
```python
# å®šä¹‰è¾“å‡ºçŠ¶æ€
class SubGraphOutput(TypedDict):
    result: str  # åªè¿”å›è¿™ä¸ª

# åˆ›å»ºå­å›¾
sub_graph = StateGraph(
    state_schema=SubGraphState,    # å†…éƒ¨ä½¿ç”¨å®Œæ•´çŠ¶æ€
    output_schema=SubGraphOutput   # åªè¿”å› result
)
```

#### å®Œæ•´ç¤ºä¾‹:æ—¥å¿—åˆ†æç³»ç»Ÿ

```python
from typing_extensions import TypedDict
from typing import List
from langgraph.graph import StateGraph, START, END

# ============ å­å›¾ 1: å¤±è´¥åˆ†æ ============

# å†…éƒ¨çŠ¶æ€(å®Œæ•´)
class FailureAnalysisState(TypedDict):
    logs: List[dict]          # è¾“å…¥
    failed_logs: List[dict]   # ä¸­é—´:ç­›é€‰å‡ºçš„å¤±è´¥æ—¥å¿—
    error_patterns: dict      # ä¸­é—´:é”™è¯¯æ¨¡å¼ç»Ÿè®¡
    temp_cache: dict          # ä¸­é—´:ä¸´æ—¶ç¼“å­˜
    summary: str              # è¾“å‡º:å¤±è´¥æ‘˜è¦

# è¾“å‡ºçŠ¶æ€(åªè¿”å›æ‘˜è¦)
class FailureAnalysisOutput(TypedDict):
    summary: str

# èŠ‚ç‚¹å‡½æ•°
def filter_failures(state):
    failed = [log for log in state["logs"] if log.get("status") == "error"]
    return {"failed_logs": failed}

def analyze_patterns(state):
    patterns = {}
    for log in state["failed_logs"]:
        error_type = log.get("error_type", "unknown")
        patterns[error_type] = patterns.get(error_type, 0) + 1
    return {"error_patterns": patterns}

def generate_summary(state):
    patterns = state["error_patterns"]
    summary = f"Found {sum(patterns.values())} failures. "
    summary += f"Top issues: {list(patterns.keys())}"
    return {"summary": summary}

# æ„å»ºå­å›¾
fa_builder = StateGraph(
    state_schema=FailureAnalysisState,
    output_schema=FailureAnalysisOutput  # â­ åªè¿”å› summary
)

fa_builder.add_node("filter_failures", filter_failures)
fa_builder.add_node("analyze_patterns", analyze_patterns)
fa_builder.add_node("generate_summary", generate_summary)

fa_builder.add_edge(START, "filter_failures")
fa_builder.add_edge("filter_failures", "analyze_patterns")
fa_builder.add_edge("analyze_patterns", "generate_summary")
fa_builder.add_edge("generate_summary", END)

failure_analysis_graph = fa_builder.compile()

# ============ å­å›¾ 2: æ€§èƒ½åˆ†æ ============

class PerformanceAnalysisState(TypedDict):
    logs: List[dict]
    slow_logs: List[dict]     # ä¸­é—´
    latency_stats: dict       # ä¸­é—´
    report: str               # è¾“å‡º

class PerformanceAnalysisOutput(TypedDict):
    report: str

def filter_slow(state):
    slow = [log for log in state["logs"] if log.get("latency", 0) > 1000]
    return {"slow_logs": slow}

def calculate_stats(state):
    latencies = [log["latency"] for log in state["slow_logs"]]
    stats = {
        "avg": sum(latencies) / len(latencies) if latencies else 0,
        "max": max(latencies) if latencies else 0
    }
    return {"latency_stats": stats}

def generate_report(state):
    stats = state["latency_stats"]
    report = f"Avg latency: {stats['avg']}ms, Max: {stats['max']}ms"
    return {"report": report}

pa_builder = StateGraph(
    PerformanceAnalysisState,
    output_schema=PerformanceAnalysisOutput
)

pa_builder.add_node("filter_slow", filter_slow)
pa_builder.add_node("calculate_stats", calculate_stats)
pa_builder.add_node("generate_report", generate_report)

pa_builder.add_edge(START, "filter_slow")
pa_builder.add_edge("filter_slow", "calculate_stats")
pa_builder.add_edge("calculate_stats", "generate_report")
pa_builder.add_edge("generate_report", END)

performance_analysis_graph = pa_builder.compile()

# ============ ä¸»å›¾:æ•´åˆä¸¤ä¸ªå­å›¾ ============

from operator import add
from typing import Annotated

class MainState(TypedDict):
    raw_logs: List[dict]
    summary: str      # æ¥è‡ªå¤±è´¥åˆ†æå­å›¾
    report: str       # æ¥è‡ªæ€§èƒ½åˆ†æå­å›¾
    final_output: str

def prepare_logs(state):
    # å‡†å¤‡æ—¥å¿—æ•°æ®
    return {"raw_logs": state["raw_logs"]}

def finalize(state):
    output = f"Failure Summary: {state['summary']}\n"
    output += f"Performance Report: {state['report']}"
    return {"final_output": output}

# æ„å»ºä¸»å›¾
main_builder = StateGraph(MainState)
main_builder.add_node("prepare", prepare_logs)
main_builder.add_node("failure_analysis", failure_analysis_graph)  # â­ å­å›¾ä½œä¸ºèŠ‚ç‚¹
main_builder.add_node("performance_analysis", performance_analysis_graph)
main_builder.add_node("finalize", finalize)

main_builder.add_edge(START, "prepare")
main_builder.add_edge("prepare", "failure_analysis")
main_builder.add_edge("prepare", "performance_analysis")
main_builder.add_edge("failure_analysis", "finalize")
main_builder.add_edge("performance_analysis", "finalize")
main_builder.add_edge("finalize", END)

main_graph = main_builder.compile()

# æ‰§è¡Œ
logs = [
    {"id": 1, "status": "error", "error_type": "timeout", "latency": 5000},
    {"id": 2, "status": "success", "latency": 200},
    {"id": 3, "status": "error", "error_type": "404", "latency": 1500}
]

result = main_graph.invoke({"raw_logs": logs})
print(result["final_output"])
```

#### å…³é”®æ”¶ç›Š

**1. çŠ¶æ€éš”ç¦»**
```python
# å­å›¾çš„ä¸­é—´å˜é‡ä¸ä¼šæ±¡æŸ“ä¸»å›¾
# failed_logs, error_patterns, temp_cache ç­‰éƒ½ä¸ä¼šå‡ºç°åœ¨ä¸»å›¾çŠ¶æ€ä¸­
```

**2. æ¸…æ™°çš„æ¥å£**
```python
# æ˜ç¡®å­å›¾çš„è¾“å…¥å’Œè¾“å‡º
# å°±åƒå‡½æ•°ç­¾åä¸€æ ·æ¸…æ™°
def failure_analysis(logs: List) -> str:  # è¾“å…¥ logs,è¾“å‡º summary
    ...
```

**3. æ˜“äºæµ‹è¯•**
```python
# å¯ä»¥ç‹¬ç«‹æµ‹è¯•å­å›¾
sub_result = failure_analysis_graph.invoke({"logs": test_logs})
assert "summary" in sub_result
assert "failed_logs" not in sub_result  # ä¸­é—´å˜é‡ä¸ä¼šè¿”å›
```

#### å¸¸è§é”™è¯¯

**é”™è¯¯ 1:å¿˜è®°ä½¿ç”¨ output_schema**
```python
# âŒ æ‰€æœ‰å­—æ®µéƒ½ä¼šè¿”å›,æ±¡æŸ“ä¸»å›¾
sub_graph = StateGraph(SubState)

# âœ… æ˜ç¡®æŒ‡å®šè¾“å‡º
sub_graph = StateGraph(SubState, output_schema=Output)
```

**é”™è¯¯ 2:output_schema åŒ…å«ä¸å­˜åœ¨çš„å­—æ®µ**
```python
# âŒ output_schema ä¸­çš„å­—æ®µå¿…é¡»åœ¨ state_schema ä¸­å­˜åœ¨
class State(TypedDict):
    input: str
    result: str

class Output(TypedDict):
    result: str
    extra_field: str  # âŒ State ä¸­æ²¡æœ‰è¿™ä¸ªå­—æ®µ

# âœ… åªåŒ…å« State ä¸­å­˜åœ¨çš„å­—æ®µ
class Output(TypedDict):
    result: str
```

**é”™è¯¯ 3:ä¸»å›¾çŠ¶æ€ä¸åŒ…å«å­å›¾è¾“å‡ºå­—æ®µ**
```python
# å­å›¾è¾“å‡º
class SubOutput(TypedDict):
    result: str

# âŒ ä¸»å›¾çŠ¶æ€ç¼ºå°‘ result å­—æ®µ
class MainState(TypedDict):
    input: str
    # ç¼ºå°‘ result

# âœ… ä¸»å›¾çŠ¶æ€åŒ…å«å­å›¾çš„è¾“å‡ºå­—æ®µ
class MainState(TypedDict):
    input: str
    result: str  # æ¥æ”¶å­å›¾çš„è¾“å‡º
```

</details>

---

### é—®é¢˜ 3: Send API ä¸ä¼ ç»Ÿ add_edge çš„æœ¬è´¨åŒºåˆ«

<details>
<summary><b>å±•å¼€æŸ¥çœ‹å®Œæ•´è§£æ</b></summary>

#### æ ¸å¿ƒåŒºåˆ«

| ç»´åº¦ | add_edge | Send API |
|------|----------|----------|
| **ä»»åŠ¡æ•°é‡** | é™æ€å›ºå®š | åŠ¨æ€å¯å˜ |
| **å†³å®šæ—¶æœº** | ç¼–è¯‘æ—¶ | è¿è¡Œæ—¶ |
| **çŠ¶æ€ä¼ é€’** | å®Œæ•´çŠ¶æ€ | å¯è‡ªå®šä¹‰éƒ¨åˆ†çŠ¶æ€ |
| **å¹¶è¡Œåº¦** | å›ºå®š | æ ¹æ®æ•°æ®åŠ¨æ€è°ƒæ•´ |

#### è¯¦ç»†å¯¹æ¯”ç¤ºä¾‹

**åœºæ™¯:å¤„ç†å¤šä¸ªå­ä¸»é¢˜**

**æ–¹æ¡ˆ 1:ä½¿ç”¨ add_edge (é™æ€)**
```python
# âŒ é—®é¢˜:å¿…é¡»é¢„å…ˆçŸ¥é“æœ‰å¤šå°‘ä¸ªå­ä¸»é¢˜
builder.add_node("process_topic_1", process_func)
builder.add_node("process_topic_2", process_func)
builder.add_node("process_topic_3", process_func)

builder.add_edge("generate_topics", "process_topic_1")
builder.add_edge("generate_topics", "process_topic_2")
builder.add_edge("generate_topics", "process_topic_3")

# å¦‚æœå®é™…æœ‰ 5 ä¸ªä¸»é¢˜æ€ä¹ˆåŠï¼Ÿ
# å¦‚æœåªæœ‰ 2 ä¸ªä¸»é¢˜,ç¬¬ 3 ä¸ªèŠ‚ç‚¹ä¼šæµªè´¹ï¼Ÿ
```

**æ–¹æ¡ˆ 2:ä½¿ç”¨ Send API (åŠ¨æ€)**
```python
from langgraph.types import Send

def dispatch_topics(state):
    topics = state["topics"]  # å¯èƒ½æ˜¯ 2 ä¸ª,ä¹Ÿå¯èƒ½æ˜¯ 10 ä¸ª
    
    # âœ… è‡ªåŠ¨ä¸ºæ¯ä¸ªä¸»é¢˜åˆ›å»ºå¤„ç†ä»»åŠ¡
    return [Send("process_topic", {"topic": t}) for t in topics]

builder.add_conditional_edges(
    "generate_topics",
    dispatch_topics,
    ["process_topic"]
)

# æ— è®ºæœ‰å¤šå°‘ä¸»é¢˜,éƒ½èƒ½è‡ªåŠ¨å¤„ç†
```

#### Send API å®Œæ•´ç¤ºä¾‹

```python
from langgraph.types import Send
from langgraph.graph import StateGraph, START, END
from typing_extensions import TypedDict
from typing import Annotated, List
import operator

# ============ çŠ¶æ€å®šä¹‰ ============

# å…¨å±€çŠ¶æ€
class OverallState(TypedDict):
    topic: str
    subtopics: List[str]
    analyses: Annotated[List[str], operator.add]  # æ”¶é›†æ‰€æœ‰åˆ†æç»“æœ
    final_report: str

# Map èŠ‚ç‚¹çš„å±€éƒ¨çŠ¶æ€
class AnalysisState(TypedDict):
    subtopic: str

# ============ èŠ‚ç‚¹å‡½æ•° ============

def generate_subtopics(state: OverallState):
    """ç”Ÿæˆå­ä¸»é¢˜"""
    topic = state["topic"]
    
    # å‡è®¾ LLM è¿”å› 3-10 ä¸ªå­ä¸»é¢˜(æ•°é‡ä¸å›ºå®š)
    subtopics = llm_generate_subtopics(topic)
    
    return {"subtopics": subtopics}

def dispatch_analyses(state: OverallState):
    """åŠ¨æ€åˆ†å‘åˆ†æä»»åŠ¡"""
    subtopics = state["subtopics"]
    
    # â­ å…³é”®:ä¸ºæ¯ä¸ªå­ä¸»é¢˜åˆ›å»º Send ä»»åŠ¡
    return [
        Send("analyze_subtopic", {"subtopic": st})
        for st in subtopics
    ]

def analyze_subtopic(state: AnalysisState):
    """åˆ†æå•ä¸ªå­ä¸»é¢˜"""
    subtopic = state["subtopic"]
    
    # æ‰§è¡Œåˆ†æ
    analysis = llm_analyze(subtopic)
    
    # è¿”å›ç»“æœ(ä¼šè¢« operator.add åˆå¹¶åˆ° analyses åˆ—è¡¨)
    return {"analyses": [analysis]}

def write_report(state: OverallState):
    """æ±‡æ€»æ‰€æœ‰åˆ†æ"""
    analyses = state["analyses"]
    
    # æ•´åˆæˆæœ€ç»ˆæŠ¥å‘Š
    report = llm_summarize(analyses)
    
    return {"final_report": report}

# ============ æ„å»ºå›¾ ============

builder = StateGraph(OverallState)

builder.add_node("generate_subtopics", generate_subtopics)
builder.add_node("analyze_subtopic", analyze_subtopic)
builder.add_node("write_report", write_report)

builder.add_edge(START, "generate_subtopics")

# â­ ä½¿ç”¨ Send åŠ¨æ€åˆ†å‘
builder.add_conditional_edges(
    "generate_subtopics",
    dispatch_analyses,
    ["analyze_subtopic"]  # ç›®æ ‡èŠ‚ç‚¹
)

builder.add_edge("analyze_subtopic", "write_report")
builder.add_edge("write_report", END)

graph = builder.compile()

# ============ æ‰§è¡Œ ============

result = graph.invoke({"topic": "AI Safety"})

# æµç¨‹:
# 1. generate_subtopics â†’ ç”Ÿæˆ 5 ä¸ªå­ä¸»é¢˜
# 2. dispatch_analyses â†’ åˆ›å»º 5 ä¸ª Send ä»»åŠ¡
# 3. analyze_subtopic Ã— 5 â†’ å¹¶è¡Œåˆ†æ 5 ä¸ªå­ä¸»é¢˜
# 4. write_report â†’ æ±‡æ€» 5 ä¸ªåˆ†æç»“æœ
```

#### Send API é«˜çº§ç”¨æ³•

**1. æ¡ä»¶æ€§åˆ†å‘**
```python
def conditional_dispatch(state):
    tasks = state["tasks"]
    
    # åªå¤„ç†é«˜ä¼˜å…ˆçº§ä»»åŠ¡
    return [
        Send("process_task", {"task": t})
        for t in tasks
        if t.get("priority") == "high"
    ]
```

**2. åˆ†å‘åˆ°ä¸åŒèŠ‚ç‚¹**
```python
def multi_target_dispatch(state):
    items = state["items"]
    sends = []
    
    for item in items:
        if item["type"] == "text":
            sends.append(Send("process_text", {"item": item}))
        elif item["type"] == "image":
            sends.append(Send("process_image", {"item": item}))
    
    return sends
```

**3. ä¼ é€’é¢å¤–ä¸Šä¸‹æ–‡**
```python
def dispatch_with_context(state):
    subtopics = state["subtopics"]
    original_topic = state["topic"]
    
    return [
        Send("analyze", {
            "subtopic": st,
            "context": original_topic,  # ä¼ é€’é¢å¤–ä¿¡æ¯
            "timestamp": time.time()
        })
        for st in subtopics
    ]
```

**4. æ§åˆ¶å¹¶è¡Œåº¦**
```python
def limited_dispatch(state, max_parallel=5):
    tasks = state["tasks"]
    
    # åªåˆ†å‘å‰ max_parallel ä¸ªä»»åŠ¡
    return [
        Send("process", {"task": t})
        for t in tasks[:max_parallel]
    ]
```

#### æ€§èƒ½å¯¹æ¯”

**åœºæ™¯:å¤„ç† 100 ä¸ªæ–‡æ¡£**

**ä¼ ç»Ÿæ–¹å¼(é¡ºåº):**
```python
# 100 ä¸ªæ–‡æ¡£é¡ºåºå¤„ç†
for doc in documents:
    result = process(doc)  # æ¯ä¸ª 2 ç§’
# æ€»æ—¶é—´: 200 ç§’
```

**ä½¿ç”¨ Send API(å¹¶è¡Œ):**
```python
def dispatch_docs(state):
    return [Send("process", {"doc": d}) for d in state["documents"]]

# 100 ä¸ªæ–‡æ¡£å¹¶è¡Œå¤„ç†
# æ€»æ—¶é—´: ~2 ç§’ (å‡è®¾æœ‰è¶³å¤Ÿçš„è®¡ç®—èµ„æº)
```

#### æœ€ä½³å®è·µ

**1. åˆç†æ§åˆ¶å¹¶è¡Œåº¦**
```python
# âŒ æ— é™åˆ¶:å¯èƒ½è€—å°½èµ„æº
return [Send("process", {"item": i}) for i in huge_list]

# âœ… åˆ†æ‰¹å¤„ç†
def batched_dispatch(state, batch_size=10):
    items = state["items"]
    return [
        Send("process", {"item": i})
        for i in items[:batch_size]
    ]
```

**2. ä¼ é€’æœ€å°å¿…éœ€çŠ¶æ€**
```python
# âŒ ä¼ é€’æ•´ä¸ªçŠ¶æ€:æµªè´¹
Send("process", state)

# âœ… åªä¼ é€’éœ€è¦çš„å­—æ®µ
Send("process", {"item": specific_item, "context": minimal_context})
```

**3. ä½¿ç”¨æœ‰æ„ä¹‰çš„èŠ‚ç‚¹å**
```python
# âŒ ä¸æ¸…æ™°
Send("node_1", data)

# âœ… æ¸…æ™°
Send("analyze_sentiment", data)
Send("translate_text", data)
```

</details>

---

### é—®é¢˜ 4: å®ç°å¹¶è¡Œæ£€ç´¢å¤šä¸ªæ•°æ®æºçš„é—®ç­”ç³»ç»Ÿ

<details>
<summary><b>å±•å¼€æŸ¥çœ‹å®Œæ•´è§£æ</b></summary>

#### ç³»ç»Ÿæ¶æ„

```
ç”¨æˆ·é—®é¢˜
    â†“
[prepare_query] é¢„å¤„ç†æŸ¥è¯¢
    â”œâ†’ [search_wikipedia] 
    â”œâ†’ [search_web]
    â””â†’ [search_database]
         â†“ (å¹¶è¡Œ)
    [aggregate_results] èšåˆç»“æœ
         â†“
    [generate_answer] ç”Ÿæˆå›ç­”
         â†“
      æœ€ç»ˆç­”æ¡ˆ
```

#### å®Œæ•´å®ç°

```python
from langgraph.graph import StateGraph, START, END
from typing_extensions import TypedDict
from typing import Annotated, List
import operator

# ===== çŠ¶æ€å®šä¹‰ =====

class QAState(TypedDict):
    question: str
    query: str  # ä¼˜åŒ–åçš„æŸ¥è¯¢
    results: Annotated[List[dict], operator.add]  # â­ å¹¶è¡Œç»“æœæ”¶é›†
    answer: str

# ===== èŠ‚ç‚¹å‡½æ•° =====

def prepare_query(state: QAState):
    """ä¼˜åŒ–æŸ¥è¯¢"""
    question = state["question"]
    
    # ä½¿ç”¨ LLM ä¼˜åŒ–æŸ¥è¯¢
    query = llm.invoke(f"Optimize this question for search: {question}")
    
    return {"query": query}

def search_wikipedia(state: QAState):
    """æœç´¢ Wikipedia"""
    from langchain_community.document_loaders import WikipediaLoader
    
    query = state["query"]
    
    try:
        docs = WikipediaLoader(query=query, load_max_docs=2).load()
        
        results = [{
            "source": "Wikipedia",
            "content": doc.page_content[:500],
            "metadata": doc.metadata
        } for doc in docs]
        
        return {"results": results}
    
    except Exception as e:
        return {"results": [{"source": "Wikipedia", "error": str(e)}]}

def search_web(state: QAState):
    """æœç´¢ Web"""
    from langchain_community.tools.tavily_search import TavilySearchResults
    
    query = state["query"]
    
    try:
        tavily = TavilySearchResults(max_results=3)
        docs = tavily.invoke(query)
        
        results = [{
            "source": "Web",
            "content": doc["content"],
            "url": doc["url"]
        } for doc in docs]
        
        return {"results": results}
    
    except Exception as e:
        return {"results": [{"source": "Web", "error": str(e)}]}

def search_database(state: QAState):
    """æœç´¢æœ¬åœ°æ•°æ®åº“"""
    query = state["query"]
    
    # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
    try:
        db_results = database_query(query)
        
        results = [{
            "source": "Database",
            "content": result["text"],
            "confidence": result["score"]
        } for result in db_results]
        
        return {"results": results}
    
    except Exception as e:
        return {"results": [{"source": "Database", "error": str(e)}]}

def aggregate_results(state: QAState):
    """èšåˆå’Œæ’åºç»“æœ"""
    results = state["results"]
    
    # è¿‡æ»¤é”™è¯¯ç»“æœ
    valid_results = [r for r in results if "error" not in r]
    
    # æŒ‰æ¥æºåˆ†ç»„
    by_source = {}
    for result in valid_results:
        source = result["source"]
        if source not in by_source:
            by_source[source] = []
        by_source[source].append(result)
    
    # æ ¼å¼åŒ–è¾“å‡º
    formatted = []
    for source, items in by_source.items():
        formatted.append(f"--- {source} ---")
        for item in items:
            formatted.append(item["content"][:200])
    
    return {"results": valid_results}  # ä¿æŒåŸå§‹ç»“æœä¸å˜

def generate_answer(state: QAState):
    """åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ"""
    question = state["question"]
    results = state["results"]
    
    # æ„å»ºä¸Šä¸‹æ–‡
    context = "\n\n".join([
        f"Source: {r['source']}\n{r['content']}"
        for r in results if "content" in r
    ])
    
    # ç”Ÿæˆç­”æ¡ˆ
    prompt = f"""Based on the following sources, answer the question: {question}

Context:
{context}

Answer:"""
    
    answer = llm.invoke(prompt)
    
    return {"answer": answer}

# ===== æ„å»ºå›¾ =====

builder = StateGraph(QAState)

builder.add_node("prepare_query", prepare_query)
builder.add_node("search_wikipedia", search_wikipedia)
builder.add_node("search_web", search_web)
builder.add_node("search_database", search_database)
builder.add_node("aggregate_results", aggregate_results)
builder.add_node("generate_answer", generate_answer)

# æµç¨‹:prepare â†’ ä¸‰ä¸ªå¹¶è¡Œæœç´¢ â†’ aggregate â†’ generate
builder.add_edge(START, "prepare_query")
builder.add_edge("prepare_query", "search_wikipedia")
builder.add_edge("prepare_query", "search_web")
builder.add_edge("prepare_query", "search_database")
builder.add_edge("search_wikipedia", "aggregate_results")
builder.add_edge("search_web", "aggregate_results")
builder.add_edge("search_database", "aggregate_results")
builder.add_edge("aggregate_results", "generate_answer")
builder.add_edge("generate_answer", END)

graph = builder.compile()

# ===== ä½¿ç”¨ç¤ºä¾‹ =====

result = graph.invoke({"question": "What is LangGraph?"})
print("Answer:", result["answer"])
print("\nSources used:", len(result["results"]))
```

#### è¿›é˜¶ä¼˜åŒ–

**1. è¶…æ—¶æ§åˆ¶**
```python
import asyncio

async def search_with_timeout(search_func, state, timeout=5):
    """å¸¦è¶…æ—¶çš„æœç´¢"""
    try:
        return await asyncio.wait_for(
            search_func(state),
            timeout=timeout
        )
    except asyncio.TimeoutError:
        return {"results": [{
            "source": search_func.__name__,
            "error": "Timeout"
        }]}
```

**2. ç»“æœæ’åº**
```python
def aggregate_results(state: QAState):
    results = state["results"]
    
    # æŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åº
    scored_results = []
    for r in results:
        score = calculate_relevance(r["content"], state["question"])
        scored_results.append({**r, "score": score})
    
    # æ’åºå¹¶åªä¿ç•™å‰ 10 ä¸ª
    sorted_results = sorted(
        scored_results,
        key=lambda x: x.get("score", 0),
        reverse=True
    )[:10]
    
    return {"results": sorted_results}
```

**3. ç¼“å­˜æœºåˆ¶**
```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_search(query: str, source: str):
    """ç¼“å­˜æœç´¢ç»“æœ"""
    if source == "wikipedia":
        return search_wikipedia_impl(query)
    elif source == "web":
        return search_web_impl(query)
    # ...
```

</details>

---

### é—®é¢˜ 5: è®¾è®¡æ¨¡å—åŒ–çš„å¤šæ­¥éª¤å®¡æ‰¹æµç¨‹

<details>
<summary><b>å±•å¼€æŸ¥çœ‹å®Œæ•´è§£æ</b></summary>

#### éœ€æ±‚åˆ†æ

æ„å»ºä¸€ä¸ªæ”¯æŒå¤šçº§å®¡æ‰¹çš„å·¥ä½œæµç³»ç»Ÿ:
1. **åˆå®¡**: è‡ªåŠ¨æ£€æŸ¥åŸºæœ¬æ¡ä»¶
2. **ç»ç†å®¡æ‰¹**: äººå·¥å®¡æ ¸
3. **è´¢åŠ¡å®¡æ‰¹**: å¦‚æœé‡‘é¢ > 10000 éœ€è¦è´¢åŠ¡æ‰¹å‡†
4. **æœ€ç»ˆç¡®è®¤**: æ‰§è¡Œæ“ä½œ

#### ä½¿ç”¨å­å›¾å®ç°

```python
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from typing_extensions import TypedDict
from typing import Literal

# ===== ä¸»æµç¨‹çŠ¶æ€ =====

class ApprovalWorkflowState(TypedDict):
    request_id: str
    title: str
    amount: float
    status: Literal["pending", "approved", "rejected"]
    approvals: dict  # å„çº§å®¡æ‰¹ç»“æœ

# ===== å­å›¾ 1: åˆå®¡ =====

class PreliminaryCheckState(TypedDict):
    amount: float
    title: str
    check_result: dict

class PreliminaryCheckOutput(TypedDict):
    check_result: dict

def validate_request(state: PreliminaryCheckState):
    """éªŒè¯è¯·æ±‚çš„åŸºæœ¬æ¡ä»¶"""
    checks = {
        "has_title": bool(state["title"]),
        "valid_amount": state["amount"] > 0,
        "amount_range": state["amount"] < 1000000
    }
    
    passed = all(checks.values())
    
    return {
        "check_result": {
            "checks": checks,
            "passed": passed
        }
    }

# æ„å»ºåˆå®¡å­å›¾
prelim_builder = StateGraph(
    PreliminaryCheckState,
    output_schema=PreliminaryCheckOutput
)
prelim_builder.add_node("validate", validate_request)
prelim_builder.add_edge(START, "validate")
prelim_builder.add_edge("validate", END)
prelim_check_graph = prelim_builder.compile()

# ===== å­å›¾ 2: ç»ç†å®¡æ‰¹ =====

class ManagerApprovalState(TypedDict):
    request_id: str
    title: str
    amount: float
    manager_decision: str
    manager_comments: str

class ManagerApprovalOutput(TypedDict):
    manager_decision: str
    manager_comments: str

def await_manager_approval(state: ManagerApprovalState):
    """ç­‰å¾…ç»ç†å®¡æ‰¹ (ç©ºèŠ‚ç‚¹,ç”¨äºä¸­æ–­)"""
    pass

def record_manager_decision(state: ManagerApprovalState):
    """è®°å½•ç»ç†å†³ç­–"""
    return {
        "manager_decision": state.get("manager_decision", "pending"),
        "manager_comments": state.get("manager_comments", "")
    }

# æ„å»ºç»ç†å®¡æ‰¹å­å›¾
manager_builder = StateGraph(
    ManagerApprovalState,
    output_schema=ManagerApprovalOutput
)
manager_builder.add_node("await_approval", await_manager_approval)
manager_builder.add_node("record_decision", record_manager_decision)
manager_builder.add_edge(START, "await_approval")
manager_builder.add_edge("await_approval", "record_decision")
manager_builder.add_edge("record_decision", END)

memory = MemorySaver()
manager_approval_graph = manager_builder.compile(
    interrupt_before=["await_approval"],
    checkpointer=memory
)

# ===== å­å›¾ 3: è´¢åŠ¡å®¡æ‰¹ =====

class FinanceApprovalState(TypedDict):
    amount: float
    finance_decision: str
    finance_comments: str

class FinanceApprovalOutput(TypedDict):
    finance_decision: str
    finance_comments: str

def await_finance_approval(state: FinanceApprovalState):
    """ç­‰å¾…è´¢åŠ¡å®¡æ‰¹"""
    pass

def record_finance_decision(state: FinanceApprovalState):
    """è®°å½•è´¢åŠ¡å†³ç­–"""
    return {
        "finance_decision": state.get("finance_decision", "pending"),
        "finance_comments": state.get("finance_comments", "")
    }

# æ„å»ºè´¢åŠ¡å®¡æ‰¹å­å›¾
finance_builder = StateGraph(
    FinanceApprovalState,
    output_schema=FinanceApprovalOutput
)
finance_builder.add_node("await_approval", await_finance_approval)
finance_builder.add_node("record_decision", record_finance_decision)
finance_builder.add_edge(START, "await_approval")
finance_builder.add_edge("await_approval", "record_decision")
finance_builder.add_edge("record_decision", END)

finance_approval_graph = finance_builder.compile(
    interrupt_before=["await_approval"],
    checkpointer=memory
)

# ===== ä¸»å›¾:ç¼–æ’æ‰€æœ‰å­å›¾ =====

def initial_check(state: ApprovalWorkflowState):
    """åˆæ­¥æ£€æŸ¥"""
    # è°ƒç”¨åˆå®¡å­å›¾
    check_result = prelim_check_graph.invoke({
        "amount": state["amount"],
        "title": state["title"]
    })
    
    approvals = state.get("approvals", {})
    approvals["preliminary"] = check_result["check_result"]
    
    return {"approvals": approvals}

def route_after_prelim(state: ApprovalWorkflowState):
    """åˆå®¡åè·¯ç”±"""
    if state["approvals"]["preliminary"]["passed"]:
        return "manager_approval"
    else:
        return "reject"

def reject_request(state: ApprovalWorkflowState):
    """æ‹’ç»è¯·æ±‚"""
    return {"status": "rejected"}

def check_amount_threshold(state: ApprovalWorkflowState):
    """æ£€æŸ¥æ˜¯å¦éœ€è¦è´¢åŠ¡å®¡æ‰¹"""
    if state["amount"] > 10000:
        return "finance_approval"
    else:
        return "approve"

def approve_request(state: ApprovalWorkflowState):
    """æ‰¹å‡†è¯·æ±‚"""
    return {"status": "approved"}

# æ„å»ºä¸»å›¾
main_builder = StateGraph(ApprovalWorkflowState)

main_builder.add_node("initial_check", initial_check)
main_builder.add_node("manager_approval", manager_approval_graph)
main_builder.add_node("finance_approval", finance_approval_graph)
main_builder.add_node("reject", reject_request)
main_builder.add_node("approve", approve_request)

main_builder.add_edge(START, "initial_check")
main_builder.add_conditional_edges(
    "initial_check",
    route_after_prelim,
    ["manager_approval", "reject"]
)
main_builder.add_conditional_edges(
    "manager_approval",
    check_amount_threshold,
    ["finance_approval", "approve"]
)
main_builder.add_edge("finance_approval", "approve")
main_builder.add_edge("reject", END)
main_builder.add_edge("approve", END)

approval_workflow = main_builder.compile(checkpointer=memory)

# ===== ä½¿ç”¨ç¤ºä¾‹ =====

thread = {"configurable": {"thread_id": "req_001"}}

# 1. æäº¤è¯·æ±‚
request = {
    "request_id": "REQ-001",
    "title": "Purchase new servers",
    "amount": 15000.0,
    "status": "pending",
    "approvals": {}
}

# æ‰§è¡Œåˆ°ç¬¬ä¸€ä¸ªä¸­æ–­ç‚¹(ç»ç†å®¡æ‰¹)
for event in approval_workflow.stream(request, thread):
    print(event)

# 2. ç»ç†å®¡æ‰¹
state = approval_workflow.get_state(thread)
print("Waiting for manager approval...")

# æ¨¡æ‹Ÿç»ç†æ‰¹å‡†
approval_workflow.update_state(
    thread,
    {
        "manager_decision": "approved",
        "manager_comments": "Looks good, approved."
    },
    as_node="await_approval"
)

# ç»§ç»­æ‰§è¡Œåˆ°è´¢åŠ¡å®¡æ‰¹
for event in approval_workflow.stream(None, thread):
    print(event)

# 3. è´¢åŠ¡å®¡æ‰¹
print("Waiting for finance approval...")

approval_workflow.update_state(
    thread,
    {
        "finance_decision": "approved",
        "finance_comments": "Budget available, approved."
    },
    as_node="await_approval"
)

# æœ€ç»ˆæ‰§è¡Œ
for event in approval_workflow.stream(None, thread):
    print(event)

final_state = approval_workflow.get_state(thread)
print("Final status:", final_state.values["status"])
```

#### æ¶æ„ä¼˜ç‚¹

**1. æ¨¡å—åŒ–**
```python
# æ¯ä¸ªå®¡æ‰¹é˜¶æ®µæ˜¯ç‹¬ç«‹çš„å­å›¾
# å¯ä»¥å•ç‹¬æµ‹è¯•ã€ä¿®æ”¹ã€é‡ç”¨
manager_approval_result = manager_approval_graph.invoke(test_data)
```

**2. çŠ¶æ€éš”ç¦»**
```python
# ç»ç†å®¡æ‰¹çš„ä¸­é—´å˜é‡ä¸ä¼šæ³„æ¼åˆ°ä¸»å›¾
# åªæœ‰ manager_decision å’Œ manager_comments è¿”å›
```

**3. æ˜“äºæ‰©å±•**
```python
# æ·»åŠ æ–°çš„å®¡æ‰¹ç¯èŠ‚å¾ˆç®€å•
ceo_approval_graph = build_ceo_approval()
main_builder.add_node("ceo_approval", ceo_approval_graph)
```

</details>

---

### é—®é¢˜ 6: ä½¿ç”¨ Map-Reduce å¤„ç†å¤§è§„æ¨¡æ–‡æ¡£æ‘˜è¦

<details>
<summary><b>å±•å¼€æŸ¥çœ‹å®Œæ•´è§£æ</b></summary>

#### ç³»ç»Ÿè®¾è®¡

```
è¾“å…¥: 100 ä¸ªé•¿æ–‡æ¡£

Map é˜¶æ®µ:
æ–‡æ¡£1-20  â†’ å­å›¾1 â†’ æ‘˜è¦1
æ–‡æ¡£21-40 â†’ å­å›¾2 â†’ æ‘˜è¦2
æ–‡æ¡£41-60 â†’ å­å›¾3 â†’ æ‘˜è¦3
æ–‡æ¡£61-80 â†’ å­å›¾4 â†’ æ‘˜è¦4
æ–‡æ¡£81-100â†’ å­å›¾5 â†’ æ‘˜è¦5

Reduce é˜¶æ®µ:
æ‘˜è¦1-5 â†’ æ•´åˆæˆæœ€ç»ˆæŠ¥å‘Š
```

#### å®Œæ•´å®ç°

```python
from langgraph.types import Send
from langgraph.graph import StateGraph, START, END
from typing_extensions import TypedDict
from typing import Annotated, List
import operator

# ===== çŠ¶æ€å®šä¹‰ =====

class DocumentBatch(TypedDict):
    """å•ä¸ªæ‰¹æ¬¡çš„æ–‡æ¡£"""
    batch_id: int
    documents: List[str]

class OverallState(TypedDict):
    documents: List[str]                           # æ‰€æœ‰æ–‡æ¡£
    batches: List[DocumentBatch]                   # åˆ†æ‰¹åçš„æ–‡æ¡£
    summaries: Annotated[List[str], operator.add]  # æ‰€æœ‰æ‘˜è¦
    final_report: str

class BatchState(TypedDict):
    """Map èŠ‚ç‚¹çš„çŠ¶æ€"""
    batch_id: int
    documents: List[str]

# ===== èŠ‚ç‚¹å‡½æ•° =====

def split_into_batches(state: OverallState):
    """å°†æ–‡æ¡£åˆ†æ‰¹"""
    documents = state["documents"]
    batch_size = 20  # æ¯æ‰¹ 20 ä¸ªæ–‡æ¡£
    
    batches = []
    for i in range(0, len(documents), batch_size):
        batch = {
            "batch_id": len(batches),
            "documents": documents[i:i+batch_size]
        }
        batches.append(batch)
    
    return {"batches": batches}

def dispatch_to_map(state: OverallState):
    """åŠ¨æ€åˆ†å‘æ‰¹æ¬¡"""
    batches = state["batches"]
    
    # â­ ä¸ºæ¯ä¸ªæ‰¹æ¬¡åˆ›å»º Send ä»»åŠ¡
    return [
        Send("process_batch", {
            "batch_id": batch["batch_id"],
            "documents": batch["documents"]
        })
        for batch in batches
    ]

def process_batch(state: BatchState):
    """Map: å¤„ç†å•ä¸ªæ‰¹æ¬¡"""
    batch_id = state["batch_id"]
    documents = state["documents"]
    
    # ä¸ºæ¯ä¸ªæ–‡æ¡£ç”Ÿæˆæ‘˜è¦
    doc_summaries = []
    for i, doc in enumerate(documents):
        summary = llm_summarize(doc)
        doc_summaries.append(f"Doc {batch_id}-{i}: {summary}")
    
    # å°†æ‰¹æ¬¡å†…çš„æ‘˜è¦åˆå¹¶
    batch_summary = "\n\n".join(doc_summaries)
    
    return {"summaries": [batch_summary]}

def create_final_report(state: OverallState):
    """Reduce: åˆ›å»ºæœ€ç»ˆæŠ¥å‘Š"""
    all_summaries = state["summaries"]
    
    # æ•´åˆæ‰€æœ‰æ‰¹æ¬¡çš„æ‘˜è¦
    combined = "\n\n=== BATCH SEPARATOR ===\n\n".join(all_summaries)
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    prompt = f"""Synthesize these summaries into a coherent final report:

{combined}

Final Report:"""
    
    final_report = llm.invoke(prompt)
    
    return {"final_report": final_report}

# ===== æ„å»ºå›¾ =====

builder = StateGraph(OverallState)

builder.add_node("split_into_batches", split_into_batches)
builder.add_node("process_batch", process_batch)
builder.add_node("create_final_report", create_final_report)

builder.add_edge(START, "split_into_batches")
builder.add_conditional_edges(
    "split_into_batches",
    dispatch_to_map,
    ["process_batch"]
)
builder.add_edge("process_batch", "create_final_report")
builder.add_edge("create_final_report", END)

graph = builder.compile()

# ===== ä½¿ç”¨ç¤ºä¾‹ =====

# æ¨¡æ‹Ÿ 100 ä¸ªæ–‡æ¡£
documents = [f"Document {i} content..." for i in range(100)]

result = graph.invoke({"documents": documents})

print(f"Processed {len(documents)} documents")
print(f"Generated {len(result['summaries'])} batch summaries")
print(f"Final report length: {len(result['final_report'])} chars")
```

#### æ€§èƒ½ä¼˜åŒ–

**1. æ§åˆ¶å¹¶è¡Œåº¦**
```python
import asyncio

async def controlled_map(batches, max_concurrent=10):
    """é™åˆ¶æœ€å¤§å¹¶å‘æ•°"""
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def limited_process(batch):
        async with semaphore:
            return await process_batch_async(batch)
    
    results = await asyncio.gather(*[
        limited_process(b) for b in batches
    ])
    
    return results
```

**2. å¢é‡å¤„ç†**
```python
def process_batch_incremental(state: BatchState):
    """å¢é‡å¤„ç†æ‰¹æ¬¡"""
    batch_id = state["batch_id"]
    documents = state["documents"]
    
    summaries = []
    
    # æ¯å¤„ç† 5 ä¸ªæ–‡æ¡£å°±æ›´æ–°ä¸€æ¬¡çŠ¶æ€
    for i in range(0, len(documents), 5):
        mini_batch = documents[i:i+5]
        mini_summary = llm_summarize_batch(mini_batch)
        summaries.append(mini_summary)
        
        # ä¿å­˜ä¸­é—´ç»“æœ
        checkpoint_save(batch_id, summaries)
    
    return {"summaries": summaries}
```

**3. å±‚æ¬¡åŒ– Map-Reduce**
```python
# ä¸¤å±‚ Map-Reduce
# ç¬¬ä¸€å±‚: 100 æ–‡æ¡£ â†’ 10 æ‰¹æ¬¡æ‘˜è¦
# ç¬¬äºŒå±‚: 10 æ‰¹æ¬¡æ‘˜è¦ â†’ 2 ç»„æ‘˜è¦
# ç¬¬ä¸‰å±‚: 2 ç»„æ‘˜è¦ â†’ 1 æœ€ç»ˆæŠ¥å‘Š

def hierarchical_reduce(summaries, level=0):
    if len(summaries) <= 2:
        return final_reduce(summaries)
    
    # é€’å½’åˆ†ç»„
    mid = len(summaries) // 2
    left = hierarchical_reduce(summaries[:mid], level+1)
    right = hierarchical_reduce(summaries[mid:], level+1)
    
    return combine_summaries(left, right)
```

</details>

---

### é—®é¢˜ 7-10 ä¸å®Œæˆéƒ¨åˆ†

ç”±äºé—®é¢˜ 7-10 æ¶‰åŠæ›´å¤æ‚çš„ç»¼åˆæ¡ˆä¾‹å’Œæ¶æ„è®¾è®¡,è¿™äº›å†…å®¹è¯·å‚è€ƒ:
- **é—®é¢˜ 7**: Research Assistant ç®€åŒ–å®ç° - å‚è€ƒ [5.4-research-assistant-è¯¦ç»†è§£è¯».md](5.4-research-assistant-è¯¦ç»†è§£è¯».md)
- **é—®é¢˜ 8**: Map-Reduce æ€§èƒ½ä¼˜åŒ– - å‚è€ƒæ¨¡å—å†…å®¹å’Œæœ¬æ–‡é—®é¢˜ 6 çš„ä¼˜åŒ–éƒ¨åˆ†
- **é—®é¢˜ 9**: å­å›¾åµŒå¥—æœ€ä½³å®è·µ - å‚è€ƒæœ¬æ–‡é—®é¢˜ 2 å’Œé—®é¢˜ 5
- **é—®é¢˜ 10**: ä¼ä¸šçº§å¤šæ™ºèƒ½ä½“æ¶æ„ - ç»¼åˆåº”ç”¨æ‰€æœ‰æ¨¡å¼

---

## ğŸ‰ å¤ä¹ å®Œæˆ!

### çŸ¥è¯†æŒæ¡åº¦è‡ªæµ‹

å®Œæˆä»¥ä¸Š 6 é“æ ¸å¿ƒé—®é¢˜å,è¯·è¯„ä¼°ä½ çš„æŒæ¡ç¨‹åº¦:

**Parallelization:**
- [ ] ç†è§£ Reducer æœºåˆ¶çš„å·¥ä½œåŸç†
- [ ] èƒ½å¤Ÿç¼–å†™è‡ªå®šä¹‰ Reducer å‡½æ•°
- [ ] æŒæ¡ Fan-out/Fan-in æ¨¡å¼å®ç°
- [ ] ç†è§£å¹¶è¡ŒèŠ‚ç‚¹çš„åŒæ­¥æœºåˆ¶

**Sub-graph:**
- [ ] ç†è§£ state_schema å’Œ output_schema çš„åŒºåˆ«
- [ ] èƒ½å¤Ÿè®¾è®¡æ¨¡å—åŒ–çš„å­å›¾æ¶æ„
- [ ] æŒæ¡å­å›¾åµŒå¥—å’ŒçŠ¶æ€éš”ç¦»
- [ ] ç†è§£å­å›¾åœ¨ä¸»å›¾ä¸­çš„é›†æˆæ–¹å¼

**Map-Reduce:**
- [ ] æŒæ¡ Send API çš„ä½¿ç”¨æ–¹æ³•
- [ ] èƒ½å¤Ÿå®ç°å®Œæ•´çš„ Map-Reduce æµç¨‹
- [ ] ç†è§£åŠ¨æ€ä»»åŠ¡åˆ†å‘æœºåˆ¶
- [ ] æŒæ¡æ€§èƒ½ä¼˜åŒ–æŠ€å·§

**Research Assistant:**
- [ ] ç†è§£å¤šæ¨¡å—ååŒçš„æ¶æ„è®¾è®¡
- [ ] æŒæ¡ Human-in-the-Loop ä¸ Map-Reduce çš„é›†æˆ
- [ ] ç†è§£ RAG æ¨¡å¼åœ¨å¤æ‚ç³»ç»Ÿä¸­çš„åº”ç”¨

### ä¸‹ä¸€æ­¥å­¦ä¹ è·¯å¾„

æ ¹æ®ä½ çš„æŒæ¡æƒ…å†µ,é€‰æ‹©ä¸‹ä¸€æ­¥æ–¹å‘:

**å·©å›ºåŸºç¡€ï¼ˆæŒæ¡åº¦ < 70%ï¼‰:**
- é‡æ–°å­¦ä¹ æœªå®Œå…¨æŒæ¡çš„ç« èŠ‚
- å®Œæˆæ¯èŠ‚è¯¾çš„å®æˆ˜ç»ƒä¹ 
- æ„å»ºå°å‹ç¤ºä¾‹é¡¹ç›®éªŒè¯ç†è§£

**è¿›é˜¶å­¦ä¹ ï¼ˆæŒæ¡åº¦ 70%-90%ï¼‰:**
- å­¦ä¹  Module-6: ç”Ÿäº§éƒ¨ç½²ä¸ç›‘æ§
- å­¦ä¹  Module-7: å¤§å‹ç»¼åˆé¡¹ç›®
- æ„å»ºä¸­å‹å¤æ‚é¡¹ç›®

**ä¸“å®¶è·¯å¾„ï¼ˆæŒæ¡åº¦ > 90%ï¼‰:**
- ç ”ç©¶ LangGraph æºç å®ç°
- è´¡çŒ®å¼€æºé¡¹ç›®
- æ’°å†™æŠ€æœ¯åšå®¢åˆ†äº«ç»éªŒ

### å®è·µå»ºè®®

**é¡¹ç›® 1: å¤šæºä¿¡æ¯èšåˆç³»ç»Ÿï¼ˆä¸­çº§ï¼‰**
- éœ€æ±‚: å¹¶è¡Œæ£€ç´¢å¤šä¸ªæ•°æ®æº,æ™ºèƒ½èšåˆç»“æœ
- æŠ€æœ¯: Parallelization + Reducer
- é¢„è®¡æ—¶é—´: 2-3 å¤©

**é¡¹ç›® 2: æ¨¡å—åŒ–å·¥ä½œæµå¼•æ“ï¼ˆé«˜çº§ï¼‰**
- éœ€æ±‚: æ”¯æŒå¤æ‚å®¡æ‰¹æµç¨‹,å¯è§†åŒ–å·¥ä½œæµ
- æŠ€æœ¯: Sub-graph + Human-in-the-Loop
- é¢„è®¡æ—¶é—´: 4-6 å¤©

**é¡¹ç›® 3: æ™ºèƒ½ç ”ç©¶åŠ©æ‰‹ï¼ˆä¸“å®¶çº§ï¼‰**
- éœ€æ±‚: å¤šæ™ºèƒ½ä½“åä½œ,è‡ªåŠ¨åŒ–ç ”ç©¶æŠ¥å‘Šç”Ÿæˆ
- æŠ€æœ¯: æ‰€æœ‰é«˜çº§æ¨¡å¼é›†æˆ
- é¢„è®¡æ—¶é—´: 7-10 å¤©

### å‚è€ƒèµ„æº

**å®˜æ–¹æ–‡æ¡£:**
- [LangGraph å¹¶è¡Œæ‰§è¡Œ](https://langchain-ai.github.io/langgraph/how-tos/branching/)
- [LangGraph å­å›¾](https://langchain-ai.github.io/langgraph/how-tos/subgraph/)
- [LangGraph Map-Reduce](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/)

**ç¤¾åŒºèµ„æº:**
- [LangGraph GitHub](https://github.com/langchain-ai/langgraph)
- [LangGraph ç¤ºä¾‹](https://github.com/langchain-ai/langgraph/tree/main/examples)

**è¿›é˜¶é˜…è¯»:**
- MapReduce åŸç† (Google è®ºæ–‡)
- åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡æ¨¡å¼
- å¾®æœåŠ¡æ¶æ„è®¾è®¡

---

## ğŸ“Š çŸ¥è¯†ç‚¹æ€»ç»“å¡ç‰‡

### Parallelization æ ¸å¿ƒè¦ç‚¹

```python
# å¹¶è¡Œæ‰§è¡Œçš„å…³é”®ä¸‰è¦ç´ :
1. Fan-out: ä¸€ä¸ªèŠ‚ç‚¹æ‰‡å‡ºåˆ°å¤šä¸ªèŠ‚ç‚¹
   builder.add_edge("A", "B")
   builder.add_edge("A", "C")

2. Reducer: åˆå¹¶å¹¶è¡Œæ›´æ–°
   class State(TypedDict):
       results: Annotated[list, operator.add]

3. Fan-in: å¤šä¸ªèŠ‚ç‚¹æ±‡èš
   builder.add_edge("B", "D")
   builder.add_edge("C", "D")
```

### Sub-graph æ ¸å¿ƒè¦ç‚¹

```python
# å­å›¾çš„ä¸‰ä¸ªå…³é”®ç»„æˆ:
1. state_schema: å†…éƒ¨å®Œæ•´çŠ¶æ€
   StateGraph(CompleteState)

2. output_schema: è¾“å‡ºéƒ¨åˆ†çŠ¶æ€
   StateGraph(CompleteState, output_schema=OutputState)

3. å­å›¾åµŒå¥—: ä½œä¸ºèŠ‚ç‚¹æ·»åŠ 
   main_builder.add_node("sub_task", sub_graph.compile())
```

### Map-Reduce æ ¸å¿ƒè¦ç‚¹

```python
# Map-Reduce çš„ä¸‰ä¸ªé˜¶æ®µ:
1. åˆ†è§£: å°†å¤§ä»»åŠ¡æ‹†åˆ†
   def split_task(state):
       return {"subtasks": [t1, t2, t3]}

2. Map: ä½¿ç”¨ Send åŠ¨æ€åˆ†å‘
   def dispatch(state):
       return [Send("process", {"task": t}) for t in state["subtasks"]]

3. Reduce: èšåˆæ‰€æœ‰ç»“æœ
   class State(TypedDict):
       results: Annotated[list, operator.add]
```

### æ€§èƒ½ä¼˜åŒ–æ¸…å•

- [ ] ä½¿ç”¨ Reducer é¿å…å¹¶è¡Œå†²çª
- [ ] æ§åˆ¶å¹¶è¡Œåº¦é¿å…èµ„æºè€—å°½
- [ ] ä½¿ç”¨ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—
- [ ] æ‰¹é‡å¤„ç†æå‡ååé‡
- [ ] è¶…æ—¶æ§åˆ¶é˜²æ­¢é˜»å¡
- [ ] é”™è¯¯å¤„ç†ä¿è¯å¥å£®æ€§
- [ ] ç›‘æ§æ—¥å¿—ä¾¿äºè°ƒè¯•

---

## ğŸ“ å­¦ä¹ æˆå°±å¾½ç« 

å®Œæˆæœ¬ç« å¤ä¹ ,ä½ å·²ç»è·å¾—ä»¥ä¸‹æˆå°±:

ğŸ† **å¹¶è¡Œæ‰§è¡Œå¤§å¸ˆ**: ç²¾é€š Fan-out/Fan-in å’Œ Reducer æœºåˆ¶  
ğŸ† **æ¨¡å—åŒ–æ¶æ„å¸ˆ**: æŒæ¡å­å›¾è®¾è®¡å’ŒçŠ¶æ€éš”ç¦»  
ğŸ† **åˆ†æ²»ç­–ç•¥ä¸“å®¶**: ç†Ÿç»ƒä½¿ç”¨ Map-Reduce å¤„ç†å¤§è§„æ¨¡ä»»åŠ¡  
ğŸ† **ç³»ç»Ÿé›†æˆä¸“å®¶**: èƒ½å¤Ÿç»„åˆå¤šç§æ¨¡å¼æ„å»ºå¤æ‚ç³»ç»Ÿ

---

**æ­å–œä½ å®Œæˆ Module-5 çš„å¤ä¹ !** ğŸŠ

ä½ ç°åœ¨å·²ç»æŒæ¡äº†æ„å»º**ä¼ä¸šçº§ã€å¯æ‰©å±•ã€é«˜æ€§èƒ½** AI ç³»ç»Ÿçš„æ ¸å¿ƒèƒ½åŠ›ã€‚è¿™äº›é«˜çº§å›¾æ¨¡å¼ä¸ä»…æ˜¯æŠ€æœ¯å·¥å…·,æ›´æ˜¯è§£å†³å¤æ‚é—®é¢˜çš„æ€ç»´æ–¹å¼ã€‚åœ¨æœªæ¥çš„é¡¹ç›®ä¸­,å½“ä½ é¢å¯¹å¤æ‚éœ€æ±‚æ—¶,å›åˆ°è¿™äº›åŸºç¡€æ¨¡å¼,ä½ ä¼šå‘ç°é—®é¢˜æ€»æœ‰ä¼˜é›…çš„è§£å†³æ–¹æ¡ˆã€‚

ç»§ç»­åŠ æ²¹,å‘ç€ç²¾é€š LangGraph çš„ç›®æ ‡å‰è¿›! ğŸš€

---

## é™„å½•: å¸¸è§é—®é¢˜é€ŸæŸ¥

### Q1: ä»€ä¹ˆæ—¶å€™ä½¿ç”¨å¹¶è¡Œ vs å­å›¾ vs Map-Reduce?

**å¹¶è¡Œ (Parallelization):**
- å›ºå®šæ•°é‡çš„ä»»åŠ¡
- ä»»åŠ¡å½¼æ­¤ç‹¬ç«‹
- ä¾‹å¦‚: åŒæ—¶æŸ¥è¯¢ 3 ä¸ª API

**å­å›¾ (Sub-graph):**
- éœ€è¦æ¨¡å—åŒ–è®¾è®¡
- çŠ¶æ€éš”ç¦»
- ä¾‹å¦‚: å¤šæ­¥éª¤å®¡æ‰¹æµç¨‹

**Map-Reduce:**
- åŠ¨æ€æ•°é‡çš„ä»»åŠ¡
- éœ€è¦èšåˆç»“æœ
- ä¾‹å¦‚: å¤„ç† N ä¸ªæ–‡æ¡£

### Q2: Reducer å¯ä»¥ä¿®æ”¹çŠ¶æ€å—?

**ä¸å»ºè®®ã€‚** Reducer åº”è¯¥æ˜¯çº¯å‡½æ•°:
```python
# âœ… çº¯å‡½æ•°
def reducer(left, right):
    return left + right

# âŒ æœ‰å‰¯ä½œç”¨
def bad_reducer(left, right):
    log_to_database(left)  # å‰¯ä½œç”¨
    return left + right
```

### Q3: å­å›¾å¯ä»¥åµŒå¥—å­å›¾å—?

**å¯ä»¥,ä½†ä¸å»ºè®®è¶…è¿‡ 3 å±‚:**
```python
# âœ… åˆç†: 2 å±‚åµŒå¥—
main_graph
  â”œâ”€ sub_graph_1
  â”‚   â”œâ”€ sub_sub_graph_1a
  â”‚   â””â”€ sub_sub_graph_1b
  â””â”€ sub_graph_2

# âŒ è¿‡åº¦: 4+ å±‚åµŒå¥—
# ä¼šå¯¼è‡´è°ƒè¯•å›°éš¾
```

### Q4: Send API å¯ä»¥å‘é€åˆ°å¤šä¸ªä¸åŒèŠ‚ç‚¹å—?

**å¯ä»¥:**
```python
def dispatch(state):
    return [
        Send("node_a", {"data": 1}),
        Send("node_b", {"data": 2}),
        Send("node_a", {"data": 3})  # å¯ä»¥é‡å¤
    ]
```

### Q5: å¦‚ä½•è°ƒè¯•å¹¶è¡Œæ‰§è¡Œ?

```python
# ä½¿ç”¨ stream_mode="debug"
for event in graph.stream(input, stream_mode="debug"):
    print(f"Step: {event['step']}")
    print(f"Node: {event['node']}")
    print(f"Updates: {event['updates']}")
```

---

**End of Module-5 Review** ğŸ“˜
