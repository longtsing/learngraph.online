# LangGraph Map-Reduce è¯¦ç»†è§£è¯»

## ğŸ“š æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è§£è¯» LangGraph ä¸­çš„ **Map-Reduce** æ¨¡å¼ã€‚è¿™æ˜¯ä¸€ç§ç»å…¸çš„åˆ†å¸ƒå¼è®¡ç®—æ¨¡å¼ï¼Œåœ¨ LangGraph ä¸­ç”¨äºé«˜æ•ˆçš„ä»»åŠ¡åˆ†è§£å’Œå¹¶è¡Œå¤„ç†ã€‚é€šè¿‡ Map-Reduceï¼Œæˆ‘ä»¬å¯ä»¥å°†å¤æ‚ä»»åŠ¡æ‹†åˆ†æˆå¤šä¸ªå­ä»»åŠ¡å¹¶è¡Œæ‰§è¡Œï¼Œç„¶åèšåˆç»“æœã€‚

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ Map-Reduceï¼Ÿ

Map-Reduce æ˜¯ä¸€ç§ç¼–ç¨‹æ¨¡å‹ï¼ŒåŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼š

1. **Mapï¼ˆæ˜ å°„ï¼‰é˜¶æ®µ**
   - å°†å¤§ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå°çš„å­ä»»åŠ¡
   - å¹¶è¡Œå¤„ç†æ¯ä¸ªå­ä»»åŠ¡
   - æ¯ä¸ªå­ä»»åŠ¡ç‹¬ç«‹æ‰§è¡Œï¼Œäº’ä¸å½±å“

2. **Reduceï¼ˆå½’çº¦ï¼‰é˜¶æ®µ**
   - æ”¶é›†æ‰€æœ‰å­ä»»åŠ¡çš„ç»“æœ
   - å¯¹ç»“æœè¿›è¡Œèšåˆã€æ±‡æ€»æˆ–ç­›é€‰
   - äº§ç”Ÿæœ€ç»ˆè¾“å‡º

---

## ğŸ“š æœ¯è¯­è¡¨

| æœ¯è¯­åç§° | LangGraph å®šä¹‰å’Œè§£è¯» | Python å®šä¹‰å’Œè¯´æ˜ | é‡è¦ç¨‹åº¦ |
|---------|---------------------|------------------|---------|
| **Map-Reduce** | åˆ†è§£ä»»åŠ¡å¹¶è¡Œå¤„ç†ï¼ˆMapï¼‰ï¼Œç„¶åèšåˆç»“æœï¼ˆReduceï¼‰çš„ç¼–ç¨‹æ¨¡å¼ | ç»å…¸åˆ†å¸ƒå¼è®¡ç®—æ¨¡å¼ï¼ŒGoogle MapReduce è®ºæ–‡æå‡º | â­â­â­â­â­ |
| **Send API** | åŠ¨æ€åˆ›å»ºå¹¶è¡Œä»»åŠ¡çš„æ ¸å¿ƒ APIï¼Œæ ¼å¼ï¼š`Send(èŠ‚ç‚¹å, çŠ¶æ€å­—å…¸)` | `from langgraph.types import Send`ï¼Œè¿è¡Œæ—¶å†³å®šå¹¶è¡Œæ•°é‡ | â­â­â­â­â­ |
| **Map é˜¶æ®µ** | å°†å¤§ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå°ä»»åŠ¡å¹¶å¹¶è¡Œå¤„ç†çš„é˜¶æ®µ | æ¯ä¸ªå­ä»»åŠ¡ç‹¬ç«‹æ‰§è¡Œï¼Œäº’ä¸å½±å“ï¼Œæ•°é‡åŠ¨æ€å¯å˜ | â­â­â­â­â­ |
| **Reduce é˜¶æ®µ** | æ”¶é›†æ‰€æœ‰å­ä»»åŠ¡ç»“æœå¹¶èšåˆã€æ±‡æ€»çš„é˜¶æ®µ | ä½¿ç”¨ reducerï¼ˆå¦‚ `operator.add`ï¼‰åˆå¹¶å¹¶è¡Œç»“æœ | â­â­â­â­â­ |
| **åŠ¨æ€åˆ†å‘** | æ ¹æ®è¿è¡Œæ—¶æ•°æ®å†³å®šå¹¶è¡Œä»»åŠ¡æ•°é‡çš„æœºåˆ¶ | é€šè¿‡ Send è¿”å›åˆ—è¡¨å®ç°ï¼Œåˆ—è¡¨é•¿åº¦å³å¹¶è¡Œä»»åŠ¡æ•° | â­â­â­â­â­ |
| **æ¡ä»¶è¾¹ + Send** | `add_conditional_edges(æºèŠ‚ç‚¹, è¿”å›Sendåˆ—è¡¨çš„å‡½æ•°, [ç›®æ ‡èŠ‚ç‚¹])` | LangGraph å®ç°åŠ¨æ€å¹¶è¡Œçš„å…³é”®ï¼Œè‡ªåŠ¨å¤„ç†å¹¶è¡Œå’Œèšåˆ | â­â­â­â­â­ |
| **Pydantic BaseModel** | å®šä¹‰æ•°æ®æ¨¡å‹å¹¶æ”¯æŒè‡ªåŠ¨éªŒè¯çš„ç±» | `from pydantic import BaseModel`ï¼Œç”¨äº LLM ç»“æ„åŒ–è¾“å‡º | â­â­â­â­ |
| **with_structured_output()** | LangChain æ–¹æ³•ï¼Œå¼ºåˆ¶ LLM è¿”å›ç¬¦åˆæŒ‡å®šæ¨¡å‹çš„ JSON | `llm.with_structured_output(Model).invoke(prompt)` | â­â­â­â­ |
| **OverallState vs å±€éƒ¨State** | å…¨å±€çŠ¶æ€è´¯ç©¿æ•´ä¸ªå›¾ï¼Œå±€éƒ¨çŠ¶æ€ä»…ç”¨äºç‰¹å®šèŠ‚ç‚¹ | OverallState æ”¶é›†æ‰€æœ‰ç»“æœï¼Œå±€éƒ¨State åªåŒ…å«å¿…éœ€å­—æ®µ | â­â­â­â­ |
| **operator.add** | Python å†…ç½®å‡½æ•°ï¼Œç”¨ä½œåˆ—è¡¨æ‹¼æ¥çš„ reducer | `operator.add([1,2], [3,4])` è¿”å› `[1,2,3,4]` | â­â­â­â­ |

---

### ç»å…¸åº”ç”¨åœºæ™¯

- **æ–‡æ¡£å¤„ç†**ï¼šåˆ†æ®µå¤„ç†é•¿æ–‡æ¡£ï¼Œç„¶åæ±‡æ€»æ‘˜è¦
- **æ•°æ®åˆ†æ**ï¼šå¹¶è¡Œåˆ†æå¤šä¸ªæ•°æ®æºï¼Œèšåˆç»Ÿè®¡ç»“æœ
- **å†…å®¹ç”Ÿæˆ**ï¼šç”Ÿæˆå¤šä¸ªå€™é€‰å†…å®¹ï¼Œé€‰æ‹©æœ€ä½³ç»“æœ
- **å¤šæºæŸ¥è¯¢**ï¼šå¹¶è¡ŒæŸ¥è¯¢å¤šä¸ª APIï¼Œåˆå¹¶ç»“æœ

---

## ğŸ­ å®æˆ˜æ¡ˆä¾‹ï¼šç¬‘è¯ç”Ÿæˆç³»ç»Ÿ

æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªæ™ºèƒ½ç¬‘è¯ç”Ÿæˆç³»ç»Ÿï¼Œæ¼”ç¤º Map-Reduce çš„å®Œæ•´æµç¨‹ï¼š

**éœ€æ±‚ï¼š**
1. **Map é˜¶æ®µ**ï¼šæ ¹æ®ä¸€ä¸ªä¸»é¢˜ï¼ˆå¦‚"åŠ¨ç‰©"ï¼‰ï¼Œç”Ÿæˆå¤šä¸ªå­ä¸»é¢˜çš„ç¬‘è¯
2. **Reduce é˜¶æ®µ**ï¼šä»æ‰€æœ‰ç”Ÿæˆçš„ç¬‘è¯ä¸­ï¼Œé€‰å‡ºæœ€å¥½çš„ä¸€ä¸ª

### ç³»ç»Ÿæ¶æ„å›¾

```
ç”¨æˆ·è¾“å…¥ä¸»é¢˜ "animals"
        â†“
   [generate_topics] ç”Ÿæˆå­ä¸»é¢˜: [mammals, reptiles, birds]
        â†“
    (Send API åŠ¨æ€åˆ†å‘)
        â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
   â†“        â†“        â†“        â†“
[joke-1] [joke-2] [joke-3]  (Map é˜¶æ®µï¼šå¹¶è¡Œç”Ÿæˆ)
   â†“        â†“        â†“
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
        [best_joke]  (Reduce é˜¶æ®µï¼šé€‰æ‹©æœ€ä½³)
             â†“
         è¿”å›ç»“æœ
```

---

## ğŸ”§ ä»£ç å®ç°è¯¦è§£

### 1. å®šä¹‰æç¤ºè¯å’Œæ¨¡å‹

```python
from langchain_openai import ChatOpenAI

# ä¸‰ä¸ªå…³é”®æç¤ºè¯
subjects_prompt = """Generate a list of 3 sub-topics that are all related to this overall topic: {topic}."""
joke_prompt = """Generate a joke about {subject}"""
best_joke_prompt = """Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one, starting 0 as the ID for the first joke. Jokes: \n\n  {jokes}"""

# åˆå§‹åŒ– LLM
model = ChatOpenAI(model="gpt-5-nano", temperature=0)
```

**è¯´æ˜ï¼š**
- `subjects_prompt`ï¼šå°†ä¸»é¢˜æ‹†åˆ†ä¸º 3 ä¸ªå­ä¸»é¢˜
- `joke_prompt`ï¼šä¸ºå•ä¸ªå­ä¸»é¢˜ç”Ÿæˆç¬‘è¯
- `best_joke_prompt`ï¼šä»å¤šä¸ªç¬‘è¯ä¸­é€‰æ‹©æœ€å¥½çš„

---

### 2. å®šä¹‰çŠ¶æ€ï¼ˆStateï¼‰

è¿™æ˜¯ Map-Reduce çš„å…³é”®ï¼æˆ‘ä»¬éœ€è¦ä¸¤ç§çŠ¶æ€ï¼š

#### å…¨å±€çŠ¶æ€ï¼ˆOverallStateï¼‰

```python
import operator
from typing import Annotated
from typing_extensions import TypedDict
from pydantic import BaseModel

class Subjects(BaseModel):
    subjects: list[str]

class BestJoke(BaseModel):
    id: int

class OverallState(TypedDict):
    topic: str                                  # ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜
    subjects: list                               # ç”Ÿæˆçš„å­ä¸»é¢˜åˆ—è¡¨
    jokes: Annotated[list, operator.add]        # æ”¶é›†çš„ç¬‘è¯ï¼ˆæ”¯æŒå¹¶è¡Œè¿½åŠ ï¼‰
    best_selected_joke: str                     # æœ€ç»ˆé€‰å‡ºçš„æœ€ä½³ç¬‘è¯
```

**å…³é”®ç‚¹ï¼š**
- `jokes` ä½¿ç”¨ `operator.add` reducerï¼Œå…è®¸å¤šä¸ªå¹¶è¡ŒèŠ‚ç‚¹åŒæ—¶å†™å…¥
- è¿™ä¸ä¹‹å‰å­¦ä¹ çš„ parallelization çŸ¥è¯†ä¸€è‡´

#### å±€éƒ¨çŠ¶æ€ï¼ˆJokeStateï¼‰

```python
class JokeState(TypedDict):
    subject: str  # å•ä¸ªç¬‘è¯ç”ŸæˆèŠ‚ç‚¹åªéœ€è¦çŸ¥é“ä¸»é¢˜

class Joke(BaseModel):
    joke: str
```

**Python çŸ¥è¯†ç‚¹ï¼šPydantic BaseModel**

`BaseModel` æ˜¯ Pydantic åº“çš„æ ¸å¿ƒç±»ï¼Œç”¨äºï¼š
- æ•°æ®éªŒè¯
- ç±»å‹æ£€æŸ¥
- ç»“æ„åŒ–è¾“å‡º

```python
# ä½¿ç”¨ç¤ºä¾‹
class Joke(BaseModel):
    joke: str

# LLM ä¼šè¿”å›ç¬¦åˆè¿™ä¸ªç»“æ„çš„æ•°æ®
response = model.with_structured_output(Joke).invoke(prompt)
# response.joke å°±æ˜¯å­—ç¬¦ä¸²ç±»å‹çš„ç¬‘è¯å†…å®¹
```

---

### 3. Map é˜¶æ®µï¼šç”Ÿæˆå­ä¸»é¢˜

```python
def generate_topics(state: OverallState):
    prompt = subjects_prompt.format(topic=state["topic"])
    response = model.with_structured_output(Subjects).invoke(prompt)
    return {"subjects": response.subjects}
```

**åŠŸèƒ½ï¼š** å°†ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜ï¼ˆå¦‚ "animals"ï¼‰åˆ†è§£ä¸º 3 ä¸ªå­ä¸»é¢˜ï¼ˆå¦‚ ["mammals", "reptiles", "birds"]ï¼‰

---

### 4. åŠ¨æ€ä»»åŠ¡åˆ†å‘ï¼šSend API â­

è¿™æ˜¯ Map-Reduce çš„**æ ¸å¿ƒé­”æ³•**ï¼

```python
from langgraph.types import Send

def continue_to_jokes(state: OverallState):
    # ä¸ºæ¯ä¸ªå­ä¸»é¢˜åˆ›å»ºä¸€ä¸ª Send ä»»åŠ¡
    return [Send("generate_joke", {"subject": s}) for s in state["subjects"]]
```

**Send API è¯¦è§£ï¼š**

```python
Send("generate_joke", {"subject": s})
#    ^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^
#    ç›®æ ‡èŠ‚ç‚¹åç§°      å‘é€çš„çŠ¶æ€æ•°æ®
```

**é‡è¦ç‰¹æ€§ï¼š**
1. **åŠ¨æ€å¹¶è¡ŒåŒ–**ï¼šè‡ªåŠ¨ä¸ºåˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ åˆ›å»ºå¹¶è¡Œä»»åŠ¡
2. **çŠ¶æ€çµæ´»æ€§**ï¼šå¯ä»¥å‘é€ä»»æ„çŠ¶æ€ï¼Œä¸éœ€è¦ä¸ `OverallState` å®Œå…¨åŒ¹é…
3. **è‡ªåŠ¨æ‰©å±•**ï¼šæ— è®ºæœ‰ 3 ä¸ªè¿˜æ˜¯ 300 ä¸ªå­ä¸»é¢˜ï¼Œéƒ½èƒ½è‡ªåŠ¨å¹¶è¡Œå¤„ç†

**ä¸ºä»€ä¹ˆå¼ºå¤§ï¼Ÿ**

ä¼ ç»Ÿæ–¹å¼éœ€è¦é¢„å…ˆçŸ¥é“æœ‰å¤šå°‘ä¸ªå¹¶è¡Œä»»åŠ¡ï¼Œè€Œ `Send` å¯ä»¥æ ¹æ®è¿è¡Œæ—¶æ•°æ®åŠ¨æ€åˆ›å»ºä»»åŠ¡ï¼š

```python
# å¦‚æœæœ‰ 3 ä¸ªä¸»é¢˜ï¼ŒSend ä¼šåˆ›å»º 3 ä¸ªå¹¶è¡Œä»»åŠ¡
subjects = ["mammals", "reptiles", "birds"]
# ç›¸å½“äºï¼š
# - Send("generate_joke", {"subject": "mammals"})
# - Send("generate_joke", {"subject": "reptiles"})
# - Send("generate_joke", {"subject": "birds"})

# å¦‚æœæœ‰ 10 ä¸ªä¸»é¢˜ï¼Œè‡ªåŠ¨åˆ›å»º 10 ä¸ªå¹¶è¡Œä»»åŠ¡ï¼
```

---

### 5. Map é˜¶æ®µï¼šå¹¶è¡Œç”Ÿæˆç¬‘è¯

```python
def generate_joke(state: JokeState):
    prompt = joke_prompt.format(subject=state["subject"])
    response = model.with_structured_output(Joke).invoke(prompt)
    return {"jokes": [response.joke]}
```

**å…³é”®ç»†èŠ‚ï¼š**
- è¾“å…¥ï¼š`JokeState`ï¼ˆåªåŒ…å« `subject`ï¼‰
- è¾“å‡ºï¼š`{"jokes": [response.joke]}`ï¼ˆæ³¨æ„æ˜¯åˆ—è¡¨ï¼ï¼‰
- è¿”å›çš„æ•°æ®ä¼šè¢«å†™å› `OverallState` çš„ `jokes` å­—æ®µ
- ç”±äº `jokes` æœ‰ `operator.add` reducerï¼Œå¤šä¸ªå¹¶è¡ŒèŠ‚ç‚¹çš„è¾“å‡ºä¼šè‡ªåŠ¨æ‹¼æ¥

**æ‰§è¡Œæµç¨‹ç¤ºæ„ï¼š**
```
generate_joke(subject="mammals")  â†’ è¿”å› {"jokes": ["joke1"]}
generate_joke(subject="reptiles") â†’ è¿”å› {"jokes": ["joke2"]}
generate_joke(subject="birds")    â†’ è¿”å› {"jokes": ["joke3"]}

æœ€ç»ˆ OverallState.jokes = ["joke1", "joke2", "joke3"]
```

---

### 6. Reduce é˜¶æ®µï¼šé€‰æ‹©æœ€ä½³ç¬‘è¯

```python
def best_joke(state: OverallState):
    # å°†æ‰€æœ‰ç¬‘è¯åˆå¹¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²
    jokes = "\n\n".join(state["jokes"])

    # è®© LLM é€‰æ‹©æœ€å¥½çš„ç¬‘è¯
    prompt = best_joke_prompt.format(topic=state["topic"], jokes=jokes)
    response = model.with_structured_output(BestJoke).invoke(prompt)

    # è¿”å›è¢«é€‰ä¸­çš„ç¬‘è¯
    return {"best_selected_joke": state["jokes"][response.id]}
```

**åŠŸèƒ½ï¼š**
- æ¥æ”¶æ‰€æœ‰å¹¶è¡Œç”Ÿæˆçš„ç¬‘è¯
- ä½¿ç”¨ LLM è¯„ä¼°å¹¶é€‰æ‹©æœ€ä½³ç¬‘è¯
- `BestJoke` æ¨¡å‹è¿”å›æœ€ä½³ç¬‘è¯çš„ç´¢å¼•ï¼ˆidï¼‰
- æ ¹æ®ç´¢å¼•ä» `state["jokes"]` ä¸­å–å‡ºæœ€ä½³ç¬‘è¯

---

### 7. æ„å»ºå›¾

```python
from langgraph.graph import END, StateGraph, START

# åˆ›å»ºå›¾
graph = StateGraph(OverallState)

# æ·»åŠ èŠ‚ç‚¹
graph.add_node("generate_topics", generate_topics)
graph.add_node("generate_joke", generate_joke)
graph.add_node("best_joke", best_joke)

# æ·»åŠ è¾¹
graph.add_edge(START, "generate_topics")

# æ¡ä»¶è¾¹ï¼šä½¿ç”¨ Send åŠ¨æ€åˆ†å‘ä»»åŠ¡
graph.add_conditional_edges("generate_topics", continue_to_jokes, ["generate_joke"])

graph.add_edge("generate_joke", "best_joke")
graph.add_edge("best_joke", END)

# ç¼–è¯‘
app = graph.compile()

# ğŸ¨ å¯è§†åŒ–å›¾ç»“æ„
from IPython.display import Image, display
display(Image(app.get_graph().draw_mermaid_png()))
```

**LangGraph çŸ¥è¯†ç‚¹ï¼šæ¡ä»¶è¾¹ä¸ Send**

```python
graph.add_conditional_edges("generate_topics", continue_to_jokes, ["generate_joke"])
#                          ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^
#                          æºèŠ‚ç‚¹             æ¡ä»¶å‡½æ•°             å¯èƒ½çš„ç›®æ ‡èŠ‚ç‚¹
```

- `continue_to_jokes` è¿”å› `Send` å¯¹è±¡åˆ—è¡¨
- LangGraph ä¼šè‡ªåŠ¨ä¸ºæ¯ä¸ª `Send` åˆ›å»ºä¸€ä¸ªåˆ° `generate_joke` çš„å¹¶è¡Œè·¯å¾„
- æ‰€æœ‰å¹¶è¡Œä»»åŠ¡å®Œæˆåï¼Œè‡ªåŠ¨è¿›å…¥ `best_joke` èŠ‚ç‚¹

---

### 8. æ‰§è¡Œå›¾

```python
for s in app.stream({"topic": "animals"}):
    print(s)
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```python
{'generate_topics': {'subjects': ['mammals', 'reptiles', 'birds']}}

{'generate_joke': {'jokes': ["Why don't mammals ever get lost? Because they always follow their 'instincts'!"]}}
{'generate_joke': {'jokes': ["Why don't alligators like fast food? Because they can't catch it!"]}}
{'generate_joke': {'jokes': ["Why do birds fly south for the winter? Because it's too far to walk!"]}}

{'best_joke': {'best_selected_joke': "Why don't alligators like fast food? Because they can't catch it!"}}
```

**è§‚å¯Ÿè¦ç‚¹ï¼š**
1. é¦–å…ˆç”Ÿæˆ 3 ä¸ªå­ä¸»é¢˜
2. ç„¶åå¹¶è¡Œç”Ÿæˆ 3 ä¸ªç¬‘è¯ï¼ˆæ³¨æ„è¾“å‡ºé¡ºåºå¯èƒ½ä¸åŒï¼‰
3. æœ€åé€‰å‡ºæœ€ä½³ç¬‘è¯

---

## ğŸ“ æ ¸å¿ƒçŸ¥è¯†ç‚¹æ€»ç»“

### LangGraph ç‰¹æœ‰æ¦‚å¿µ

#### 1. Send API

**ä½œç”¨ï¼š** åŠ¨æ€åˆ›å»ºå¹¶è¡Œä»»åŠ¡

```python
Send(node_name, state_dict)
```

**ç‰¹ç‚¹ï¼š**
- è¿è¡Œæ—¶åŠ¨æ€å†³å®šå¹¶è¡Œæ•°é‡
- å¯ä»¥å‘é€è‡ªå®šä¹‰çŠ¶æ€ï¼ˆä¸å¿…æ˜¯å®Œæ•´çš„å›¾çŠ¶æ€ï¼‰
- è‡ªåŠ¨å¤„ç†å¹¶è¡Œæ‰§è¡Œå’Œç»“æœèšåˆ

#### 2. Map-Reduce æ¨¡å¼

| é˜¶æ®µ | ä½œç”¨ | èŠ‚ç‚¹æ•°é‡ | æ‰§è¡Œæ–¹å¼ |
|------|------|---------|---------|
| **Map** | åˆ†è§£ä»»åŠ¡ï¼Œç”Ÿæˆç»“æœ | åŠ¨æ€ï¼ˆæ ¹æ®æ•°æ®ï¼‰ | å¹¶è¡Œ |
| **Reduce** | èšåˆç»“æœ | 1 ä¸ª | ä¸²è¡Œï¼ˆç­‰å¾…æ‰€æœ‰ Map å®Œæˆï¼‰ |

#### 3. å¤šçŠ¶æ€è®¾è®¡

- **OverallState**ï¼šå…¨å±€çŠ¶æ€ï¼Œè´¯ç©¿æ•´ä¸ªå›¾
- **JokeState**ï¼šå±€éƒ¨çŠ¶æ€ï¼Œåªç”¨äºç‰¹å®šèŠ‚ç‚¹
- é€šè¿‡ `Send` å¯ä»¥åœ¨ä¸åŒçŠ¶æ€ä¹‹é—´ä¼ é€’æ•°æ®

#### 4. æ¡ä»¶è¾¹ + Send

```python
graph.add_conditional_edges(
    "source_node",           # æºèŠ‚ç‚¹
    condition_function,      # è¿”å› Send åˆ—è¡¨çš„å‡½æ•°
    ["target_node"]         # ç›®æ ‡èŠ‚ç‚¹ï¼ˆSend æŒ‡å‘çš„èŠ‚ç‚¹ï¼‰
)
```

### Python ç‰¹æœ‰çŸ¥è¯†ç‚¹

#### 1. Pydantic BaseModel

```python
from pydantic import BaseModel

class Joke(BaseModel):
    joke: str

# ç”¨äº LLM ç»“æ„åŒ–è¾“å‡º
response = model.with_structured_output(Joke).invoke(prompt)
```

**ä¼˜åŠ¿ï¼š**
- è‡ªåŠ¨ç±»å‹éªŒè¯
- æ¸…æ™°çš„æ•°æ®ç»“æ„
- ä¸ LangChain æ— ç¼é›†æˆ

#### 2. TypedDict vs BaseModel

| ç‰¹æ€§ | TypedDict | BaseModel |
|------|-----------|-----------|
| ç±»å‹æ£€æŸ¥ | é™æ€ï¼ˆIDE æç¤ºï¼‰ | è¿è¡Œæ—¶éªŒè¯ |
| éªŒè¯ | æ—  | æœ‰ |
| ç”¨é€” | çŠ¶æ€å®šä¹‰ | æ•°æ®æ¨¡å‹ã€API è¾“å‡º |
| æ€§èƒ½ | æ›´å¿«ï¼ˆæ— éªŒè¯ï¼‰ | ç¨æ…¢ï¼ˆæœ‰éªŒè¯ï¼‰ |

```python
# TypedDict - ç”¨äº State
class OverallState(TypedDict):
    topic: str

# BaseModel - ç”¨äºç»“æ„åŒ–è¾“å‡º
class Joke(BaseModel):
    joke: str
```

#### 3. åˆ—è¡¨æ¨å¯¼å¼ + Send

```python
# åˆ›å»ºå¤šä¸ª Send ä»»åŠ¡çš„ä¼˜é›…æ–¹å¼
[Send("generate_joke", {"subject": s}) for s in subjects]

# ç­‰ä»·äºï¼š
result = []
for s in subjects:
    result.append(Send("generate_joke", {"subject": s}))
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ä½•æ—¶ä½¿ç”¨ Map-Reduceï¼Ÿ

âœ… **é€‚ç”¨åœºæ™¯ï¼š**
- éœ€è¦å¯¹å¤šä¸ªæ•°æ®é¡¹æ‰§è¡Œç›¸åŒæ“ä½œï¼ˆå¦‚æ‰¹é‡ç¿»è¯‘ã€æ‰¹é‡æ‘˜è¦ï¼‰
- ä»»åŠ¡å¯ä»¥è‡ªç„¶åˆ†è§£ä¸ºç‹¬ç«‹å­ä»»åŠ¡ï¼ˆå¦‚åˆ†æ®µå¤„ç†æ–‡æ¡£ï¼‰
- éœ€è¦ä»å¤šä¸ªå€™é€‰ç»“æœä¸­ç­›é€‰ï¼ˆå¦‚ç”Ÿæˆå¤šä¸ªç­”æ¡ˆé€‰æœ€ä½³ï¼‰
- æ•°æ®é‡å¤§ï¼Œéœ€è¦å¹¶è¡ŒåŠ é€Ÿï¼ˆå¦‚åˆ†æå¤šä¸ªæ•°æ®æºï¼‰

âŒ **ä¸é€‚ç”¨åœºæ™¯ï¼š**
- å­ä»»åŠ¡ä¹‹é—´æœ‰ä¾èµ–å…³ç³»
- æ— æ³•è‡ªç„¶åˆ†è§£çš„ä»»åŠ¡
- å•ä¸€æ•°æ®æºçš„ç®€å•æŸ¥è¯¢

### 2. Send API ä½¿ç”¨æŠ€å·§

#### æŠ€å·§ 1ï¼šåŠ¨æ€æ§åˆ¶å¹¶è¡Œæ•°é‡

```python
def continue_to_jokes(state: OverallState):
    # å¯ä»¥æ ¹æ®æ¡ä»¶è¿‡æ»¤
    subjects = [s for s in state["subjects"] if len(s) > 3]
    return [Send("generate_joke", {"subject": s}) for s in subjects]
```

#### æŠ€å·§ 2ï¼šå‘é€é¢å¤–ä¸Šä¸‹æ–‡

```python
def continue_to_jokes(state: OverallState):
    return [
        Send("generate_joke", {
            "subject": s,
            "original_topic": state["topic"],  # ä¼ é€’é¢å¤–ä¿¡æ¯
            "style": "family-friendly"
        })
        for s in state["subjects"]
    ]
```

#### æŠ€å·§ 3ï¼šæ¡ä»¶æ€§å‘é€

```python
def continue_to_jokes(state: OverallState):
    sends = []
    for i, s in enumerate(state["subjects"]):
        if i < 5:  # æœ€å¤šåªå¤„ç†å‰ 5 ä¸ª
            sends.append(Send("generate_joke", {"subject": s}))
    return sends
```

### 3. çŠ¶æ€è®¾è®¡åŸåˆ™

#### åŸåˆ™ 1ï¼šæœ€å°åŒ–å±€éƒ¨çŠ¶æ€

```python
# âœ… å¥½çš„è®¾è®¡ - åªåŒ…å«å¿…éœ€å­—æ®µ
class JokeState(TypedDict):
    subject: str

# âŒ ä¸å¥½çš„è®¾è®¡ - åŒ…å«ä¸éœ€è¦çš„å­—æ®µ
class JokeState(TypedDict):
    subject: str
    topic: str  # generate_joke ä¸éœ€è¦è¿™ä¸ª
    jokes: list  # ä¹Ÿä¸éœ€è¦è¿™ä¸ª
```

#### åŸåˆ™ 2ï¼šä½¿ç”¨ Reducer èšåˆç»“æœ

```python
# Map èŠ‚ç‚¹çš„è¾“å‡ºå­—æ®µå¿…é¡»æœ‰ reducer
class OverallState(TypedDict):
    jokes: Annotated[list, operator.add]  # âœ… æ­£ç¡®
    # jokes: list  # âŒ é”™è¯¯ï¼å¹¶è¡Œæ›´æ–°ä¼šå†²çª
```

#### åŸåˆ™ 3ï¼šæ¸…æ™°çš„çŠ¶æ€æµè½¬

```python
OverallState (å®Œæ•´çŠ¶æ€)
    â†“
Send â†’ JokeState (å­é›†)
    â†“
è¿”å› â†’ OverallState.jokes (éƒ¨åˆ†æ›´æ–°)
```

---

## ğŸš€ è¿›é˜¶æŠ€å·§

### 1. å¤šå±‚ Map-Reduce

å¯ä»¥åµŒå¥—å¤šä¸ª Map-Reduce å±‚æ¬¡ï¼š

```python
ä¸»é¢˜
 â†“ Map
å­ä¸»é¢˜ (Level 1)
 â†“ Map
è¯¦ç»†ä¸»é¢˜ (Level 2)
 â†“ Reduce
æ±‡æ€»å­ä¸»é¢˜
 â†“ Reduce
æœ€ç»ˆç»“æœ
```

### 2. å¸¦é”™è¯¯å¤„ç†çš„ Map-Reduce

```python
def generate_joke(state: JokeState):
    try:
        prompt = joke_prompt.format(subject=state["subject"])
        response = model.with_structured_output(Joke).invoke(prompt)
        return {"jokes": [response.joke]}
    except Exception as e:
        # è¿”å›é”™è¯¯æ ‡è®°æˆ–é»˜è®¤å€¼
        return {"jokes": [f"Error generating joke for {state['subject']}"]}
```

### 3. é™åˆ¶å¹¶è¡Œåº¦

è™½ç„¶ `Send` ä¼šè‡ªåŠ¨å¹¶è¡Œï¼Œä½†æœ‰æ—¶éœ€è¦é™åˆ¶åŒæ—¶æ‰§è¡Œçš„ä»»åŠ¡æ•°ï¼ˆå¦‚ API é€Ÿç‡é™åˆ¶ï¼‰ï¼š

```python
# æ–¹æ³• 1ï¼šåœ¨æ¡ä»¶å‡½æ•°ä¸­é™åˆ¶
def continue_to_jokes(state: OverallState):
    # åªå‘é€å‰ N ä¸ª
    max_parallel = 5
    subjects = state["subjects"][:max_parallel]
    return [Send("generate_joke", {"subject": s}) for s in subjects]

# æ–¹æ³• 2ï¼šåˆ†æ‰¹å¤„ç†ï¼ˆéœ€è¦æ›´å¤æ‚çš„å›¾è®¾è®¡ï¼‰
```

---

## ğŸ“Š Map-Reduce vs ç®€å•å¹¶è¡Œ

| ç‰¹æ€§ | Map-Reduce (Send) | ç®€å•å¹¶è¡Œ (Fan-out) |
|------|------------------|-------------------|
| å¹¶è¡Œæ•°é‡ | åŠ¨æ€ï¼ˆè¿è¡Œæ—¶å†³å®šï¼‰ | é™æ€ï¼ˆè®¾è®¡æ—¶å›ºå®šï¼‰ |
| çŠ¶æ€ä¼ é€’ | çµæ´»ï¼ˆå¯è‡ªå®šä¹‰ï¼‰ | å›ºå®šï¼ˆä½¿ç”¨å›¾çŠ¶æ€ï¼‰ |
| é€‚ç”¨åœºæ™¯ | åˆ—è¡¨å¤„ç†ã€æ‰¹é‡ä»»åŠ¡ | å›ºå®šæ•°é‡çš„å¹¶è¡Œè·¯å¾„ |
| å¤æ‚åº¦ | ä¸­ç­‰ | ä½ |
| æ‰©å±•æ€§ | é«˜ | ä½ |

**ç¤ºä¾‹å¯¹æ¯”ï¼š**

```python
# ç®€å•å¹¶è¡Œ - å›ºå®š 3 ä¸ªè·¯å¾„
builder.add_edge("start", "task1")
builder.add_edge("start", "task2")
builder.add_edge("start", "task3")

# Map-Reduce - åŠ¨æ€ N ä¸ªä»»åŠ¡
def send_tasks(state):
    return [Send("task", {"data": d}) for d in state["data_list"]]
builder.add_conditional_edges("start", send_tasks, ["task"])
```

---

## ğŸ¯ å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹ 1ï¼šæ–‡æ¡£æ‘˜è¦

```python
# Map: ä¸ºæ¯ä¸ªæ®µè½ç”Ÿæˆæ‘˜è¦
def summarize_chunk(state: ChunkState):
    summary = llm.invoke(f"Summarize: {state['chunk']}")
    return {"summaries": [summary]}

# Reduce: åˆå¹¶æ‰€æœ‰æ®µè½æ‘˜è¦
def combine_summaries(state: OverallState):
    all_summaries = "\n".join(state["summaries"])
    final = llm.invoke(f"Create final summary: {all_summaries}")
    return {"final_summary": final}
```

### æ¡ˆä¾‹ 2ï¼šå¤šè¯­è¨€ç¿»è¯‘

```python
# Map: ç¿»è¯‘åˆ°å¤šç§è¯­è¨€
def send_to_translate(state):
    languages = ["es", "fr", "de", "zh"]
    return [Send("translate", {"lang": lang, "text": state["text"]})
            for lang in languages]

# Reduce: æ”¶é›†æ‰€æœ‰ç¿»è¯‘
def collect_translations(state):
    return {"all_translations": state["translations"]}
```

### æ¡ˆä¾‹ 3ï¼šå¤šè§’åº¦åˆ†æ

```python
# Map: ä»ä¸åŒè§’åº¦åˆ†ææ–‡æœ¬
def send_to_analyze(state):
    perspectives = ["technical", "business", "user", "security"]
    return [Send("analyze", {"perspective": p, "text": state["text"]})
            for p in perspectives]

# Reduce: ç»¼åˆæ‰€æœ‰åˆ†æ
def synthesize(state):
    combined = llm.invoke(f"Synthesize these analyses: {state['analyses']}")
    return {"final_analysis": combined}
```

---

## ğŸ“– æ‰©å±•é˜…è¯»

- [LangGraph Map-Reduce å®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/)
- [Send API è¯¦ç»†è¯´æ˜](https://langchain-ai.github.io/langgraph/concepts/low_level/#send)
- [Pydantic å®˜æ–¹æ–‡æ¡£](https://docs.pydantic.dev/)

---

## ğŸ” å¸¸è§é—®é¢˜

### Q1: Send å’Œæ™®é€šè¾¹æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**æ™®é€šè¾¹ï¼š** é™æ€è·¯ç”±ï¼Œè®¾è®¡æ—¶ç¡®å®š
```python
graph.add_edge("A", "B")  # A æ€»æ˜¯æµå‘ B
```

**Sendï¼š** åŠ¨æ€è·¯ç”±ï¼Œè¿è¡Œæ—¶ç¡®å®š
```python
# æ ¹æ®æ•°æ®åŠ¨æ€åˆ›å»ºå¤šä¸ªå¹¶è¡Œä»»åŠ¡
return [Send("B", data) for data in dynamic_data]
```

### Q2: ä¸ºä»€ä¹ˆ generate_joke è¿”å› `{"jokes": [joke]}` è€Œä¸æ˜¯ `{"jokes": joke}`ï¼Ÿ

å› ä¸º `OverallState.jokes` ä½¿ç”¨äº† `operator.add` reducerï¼Œå®ƒæœŸæœ›æ“ä½œåˆ—è¡¨ï¼š

```python
# æ­£ç¡® âœ…
operator.add(["joke1"], ["joke2"])  # â†’ ["joke1", "joke2"]

# é”™è¯¯ âŒ
operator.add("joke1", "joke2")  # â†’ "joke1joke2" (å­—ç¬¦ä¸²æ‹¼æ¥)
```

### Q3: å¯ä»¥åœ¨ Send ä¸­å‘é€å®Œå…¨ä¸åŒçš„çŠ¶æ€å—ï¼Ÿ

å¯ä»¥ï¼`Send` å‘é€çš„çŠ¶æ€ä¸éœ€è¦ä¸ `OverallState` åŒ¹é…ï¼š

```python
# OverallState æœ‰ topic, subjects, jokes
# ä½† Send å¯ä»¥å‘é€ä»»æ„ç»“æ„
Send("generate_joke", {"subject": "cats", "style": "silly"})
```

åªè¦ç›®æ ‡èŠ‚ç‚¹ï¼ˆ`generate_joke`ï¼‰èƒ½å¤„ç†è¿™ä¸ªçŠ¶æ€å³å¯ã€‚

---

**æ€»ç»“**ï¼šMap-Reduce æ˜¯ LangGraph ä¸­å¤„ç†æ‰¹é‡ã€å¹¶è¡Œä»»åŠ¡çš„å¼ºå¤§æ¨¡å¼ã€‚é€šè¿‡ `Send` APIï¼Œæˆ‘ä»¬å¯ä»¥åŠ¨æ€åˆ›å»ºä»»æ„æ•°é‡çš„å¹¶è¡Œä»»åŠ¡ï¼Œç„¶åç”¨ reducer ä¼˜é›…åœ°èšåˆç»“æœã€‚è¿™æ˜¯æ„å»ºå¯æ‰©å±•ã€é«˜æ€§èƒ½ AI åº”ç”¨çš„å…³é”®æŠ€æœ¯ï¼

---

## å®Œæ•´æ¡ˆä¾‹ä»£ç ï¼ˆå¯ç›´æ¥è¿è¡Œï¼‰

ä»¥ä¸‹æ˜¯ä¸€ä¸ªå®Œæ•´çš„ Map-Reduce ç¤ºä¾‹ï¼Œå±•ç¤ºäº†ç¬‘è¯ç”Ÿæˆç³»ç»Ÿçš„åŠ¨æ€å¹¶è¡Œå¤„ç†ï¼š

```python
"""
LangGraph Map-Reduce å®Œæ•´ç¤ºä¾‹
æ¼”ç¤º Send API åŠ¨æ€åˆ›å»ºå¹¶è¡Œä»»åŠ¡

åœºæ™¯ï¼šæ™ºèƒ½ç¬‘è¯ç”Ÿæˆç³»ç»Ÿ
1. Map é˜¶æ®µï¼šæ ¹æ®ä¸»é¢˜ç”Ÿæˆå¤šä¸ªå­ä¸»é¢˜çš„ç¬‘è¯
2. Reduce é˜¶æ®µï¼šä»æ‰€æœ‰ç¬‘è¯ä¸­é€‰å‡ºæœ€å¥½çš„ä¸€ä¸ª
"""

import operator
from typing import Annotated, List
from typing_extensions import TypedDict
from pydantic import BaseModel
from langgraph.graph import StateGraph, START, END
from langgraph.types import Send
from langchain_openai import ChatOpenAI

# ========== 1. æ•°æ®æ¨¡å‹å®šä¹‰ ==========

class Subjects(BaseModel):
    """å­ä¸»é¢˜åˆ—è¡¨æ¨¡å‹"""
    subjects: List[str]

class Joke(BaseModel):
    """ç¬‘è¯æ¨¡å‹"""
    joke: str

class BestJoke(BaseModel):
    """æœ€ä½³ç¬‘è¯é€‰æ‹©æ¨¡å‹"""
    id: int  # æœ€ä½³ç¬‘è¯çš„ç´¢å¼•

# ========== 2. çŠ¶æ€å®šä¹‰ ==========

# å…¨å±€çŠ¶æ€ï¼ˆè´¯ç©¿æ•´ä¸ªå›¾ï¼‰
class OverallState(TypedDict):
    topic: str                                    # ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜
    subjects: List[str]                           # ç”Ÿæˆçš„å­ä¸»é¢˜åˆ—è¡¨
    jokes: Annotated[List[str], operator.add]     # æ‰€æœ‰ç”Ÿæˆçš„ç¬‘è¯ï¼ˆæ”¯æŒå¹¶è¡Œè¿½åŠ ï¼‰
    best_selected_joke: str                       # æœ€ç»ˆé€‰å‡ºçš„æœ€ä½³ç¬‘è¯

# å±€éƒ¨çŠ¶æ€ï¼ˆåªç”¨äº Map èŠ‚ç‚¹ï¼‰
class JokeState(TypedDict):
    subject: str  # å•ä¸ªç¬‘è¯ç”ŸæˆèŠ‚ç‚¹åªéœ€è¦çŸ¥é“å­ä¸»é¢˜

# ========== 3. åˆå§‹åŒ– LLM ==========

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)

# ========== 4. æç¤ºè¯æ¨¡æ¿ ==========

subjects_prompt = """è¯·æ ¹æ®ä»¥ä¸‹ä¸»é¢˜ç”Ÿæˆ 3 ä¸ªç›¸å…³çš„å­ä¸»é¢˜ï¼Œç”¨äºåˆ›ä½œç¬‘è¯ã€‚

ä¸»é¢˜: {topic}

è¦æ±‚ï¼š
- æ¯ä¸ªå­ä¸»é¢˜åº”è¯¥æ˜¯å…·ä½“çš„ã€æœ‰è¶£çš„
- å­ä¸»é¢˜ä¹‹é—´åº”è¯¥æœ‰ä¸€å®šå·®å¼‚æ€§
- é€‚åˆåˆ›ä½œå¹½é»˜å†…å®¹

è¯·ç›´æ¥è¿”å› 3 ä¸ªå­ä¸»é¢˜ã€‚"""

joke_prompt = """è¯·åˆ›ä½œä¸€ä¸ªå…³äº "{subject}" çš„ç¬‘è¯ã€‚

è¦æ±‚ï¼š
- ç¬‘è¯è¦ç®€çŸ­æœ‰è¶£
- é€‚åˆæ‰€æœ‰å¹´é¾„æ®µ
- å°½é‡å‡ºäººæ„æ–™çš„ç»“å±€

è¯·ç›´æ¥è¿”å›ç¬‘è¯å†…å®¹ã€‚"""

best_joke_prompt = """ä»¥ä¸‹æ˜¯å‡ ä¸ªå…³äº "{topic}" çš„ç¬‘è¯ï¼Œè¯·é€‰å‡ºæœ€å¥½çš„ä¸€ä¸ªã€‚

ç¬‘è¯åˆ—è¡¨ï¼š
{jokes}

è¯·è¿”å›æœ€å¥½ç¬‘è¯çš„ç¼–å·ï¼ˆä» 0 å¼€å§‹ï¼‰ã€‚"""

# ========== 5. å®šä¹‰èŠ‚ç‚¹å‡½æ•° ==========

def generate_topics(state: OverallState):
    """
    ç”Ÿæˆå­ä¸»é¢˜ï¼ˆMap ä¹‹å‰çš„å‡†å¤‡æ­¥éª¤ï¼‰
    å°†ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜åˆ†è§£ä¸ºå¤šä¸ªå­ä¸»é¢˜
    """
    topic = state["topic"]

    prompt = subjects_prompt.format(topic=topic)
    response = llm.with_structured_output(Subjects).invoke(prompt)

    print(f"ğŸ¯ ä¸»é¢˜: {topic}")
    print(f"ğŸ“ ç”Ÿæˆäº† {len(response.subjects)} ä¸ªå­ä¸»é¢˜: {response.subjects}")

    return {"subjects": response.subjects}

def continue_to_jokes(state: OverallState):
    """
    åŠ¨æ€ä»»åŠ¡åˆ†å‘å‡½æ•°ï¼ˆMap çš„æ ¸å¿ƒï¼‰
    ä¸ºæ¯ä¸ªå­ä¸»é¢˜åˆ›å»ºä¸€ä¸ª Send ä»»åŠ¡
    """
    subjects = state["subjects"]

    # â­ å…³é”®ï¼šä½¿ç”¨ Send API åŠ¨æ€åˆ›å»ºå¹¶è¡Œä»»åŠ¡
    sends = [Send("generate_joke", {"subject": s}) for s in subjects]

    print(f"ğŸ“¤ åˆ†å‘ {len(sends)} ä¸ªç¬‘è¯ç”Ÿæˆä»»åŠ¡")
    return sends

def generate_joke(state: JokeState):
    """
    ç”Ÿæˆå•ä¸ªç¬‘è¯ï¼ˆMap èŠ‚ç‚¹ï¼‰
    æ¯ä¸ªå¹¶è¡Œä»»åŠ¡ç‹¬ç«‹æ‰§è¡Œ
    """
    subject = state["subject"]

    prompt = joke_prompt.format(subject=subject)
    response = llm.with_structured_output(Joke).invoke(prompt)

    print(f"ğŸ˜‚ ç”Ÿæˆç¬‘è¯ - ä¸»é¢˜: {subject}")

    # è¿”å›åˆ—è¡¨ï¼å› ä¸º jokes å­—æ®µä½¿ç”¨ operator.add ä½œä¸º reducer
    return {"jokes": [response.joke]}

def best_joke(state: OverallState):
    """
    é€‰æ‹©æœ€ä½³ç¬‘è¯ï¼ˆReduce èŠ‚ç‚¹ï¼‰
    æ”¶é›†æ‰€æœ‰å¹¶è¡Œç”Ÿæˆçš„ç¬‘è¯ï¼Œé€‰å‡ºæœ€å¥½çš„ä¸€ä¸ª
    """
    topic = state["topic"]
    jokes = state["jokes"]

    # æ ¼å¼åŒ–ç¬‘è¯åˆ—è¡¨
    jokes_formatted = "\n\n".join([
        f"ç¬‘è¯ {i}:\n{joke}"
        for i, joke in enumerate(jokes)
    ])

    prompt = best_joke_prompt.format(topic=topic, jokes=jokes_formatted)
    response = llm.with_structured_output(BestJoke).invoke(prompt)

    # è·å–è¢«é€‰ä¸­çš„ç¬‘è¯
    selected_joke = jokes[response.id]

    print(f"ğŸ† é€‰å‡ºæœ€ä½³ç¬‘è¯ï¼ˆç¼–å· {response.id}ï¼‰")
    return {"best_selected_joke": selected_joke}

# ========== 6. æ„å»ºå›¾ ==========

def build_joke_generator():
    """æ„å»ºç¬‘è¯ç”Ÿæˆå›¾"""

    builder = StateGraph(OverallState)

    # æ·»åŠ èŠ‚ç‚¹
    builder.add_node("generate_topics", generate_topics)
    builder.add_node("generate_joke", generate_joke)
    builder.add_node("best_joke", best_joke)

    # æ·»åŠ è¾¹
    builder.add_edge(START, "generate_topics")

    # â­ æ¡ä»¶è¾¹ï¼šä½¿ç”¨ Send åŠ¨æ€åˆ†å‘ä»»åŠ¡
    builder.add_conditional_edges(
        "generate_topics",       # æºèŠ‚ç‚¹
        continue_to_jokes,       # è¿”å› Send åˆ—è¡¨çš„å‡½æ•°
        ["generate_joke"]        # å¯èƒ½çš„ç›®æ ‡èŠ‚ç‚¹
    )

    # æ‰€æœ‰ Map ä»»åŠ¡å®Œæˆåï¼Œè¿›å…¥ Reduce èŠ‚ç‚¹
    builder.add_edge("generate_joke", "best_joke")
    builder.add_edge("best_joke", END)

    return builder.compile()

# ========== 7. ä¸»ç¨‹åº ==========

if __name__ == "__main__":
    # æ„å»ºå›¾
    graph = build_joke_generator()

    # å¯è§†åŒ–å›¾ç»“æ„
    print("=" * 60)
    print("ğŸ“Š å›¾ç»“æ„å¯è§†åŒ–")
    print("=" * 60)

    try:
        from IPython.display import Image, display
        display(Image(graph.get_graph().draw_mermaid_png()))
    except Exception:
        print(graph.get_graph().draw_mermaid())

    # æ‰§è¡Œæµ‹è¯•
    print("\n" + "=" * 60)
    print("ğŸš€ æ‰§è¡Œç¬‘è¯ç”Ÿæˆç³»ç»Ÿ")
    print("=" * 60 + "\n")

    topic = "åŠ¨ç‰©"

    # ä½¿ç”¨ stream æ¨¡å¼è§‚å¯Ÿæ‰§è¡Œè¿‡ç¨‹
    print("â³ æ‰§è¡Œä¸­...\n")

    for step in graph.stream({"topic": topic}):
        for node_name, output in step.items():
            if node_name == "generate_joke":
                print(f"  ğŸ“Œ ç¬‘è¯ç”Ÿæˆå®Œæˆ")
            else:
                print(f"ğŸ“Œ èŠ‚ç‚¹ [{node_name}] å®Œæˆ")

    # è·å–æœ€ç»ˆç»“æœ
    result = graph.invoke({"topic": topic})

    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“‹ æœ€ç»ˆç»“æœ")
    print("=" * 60)

    print(f"\nğŸ¯ ä¸»é¢˜: {result['topic']}")
    print(f"\nğŸ“ å­ä¸»é¢˜: {result['subjects']}")

    print(f"\nğŸ˜‚ æ‰€æœ‰ç”Ÿæˆçš„ç¬‘è¯:")
    for i, joke in enumerate(result['jokes']):
        print(f"\n  ç¬‘è¯ {i}:")
        print(f"  {joke}")

    print(f"\nğŸ† æœ€ä½³ç¬‘è¯:")
    print(f"  {result['best_selected_joke']}")

    # æµ‹è¯•ä¸åŒä¸»é¢˜
    print("\n" + "=" * 60)
    print("ğŸ”„ æµ‹è¯•å…¶ä»–ä¸»é¢˜")
    print("=" * 60 + "\n")

    for test_topic in ["ç§‘æŠ€", "ç¾é£Ÿ"]:
        print(f"ä¸»é¢˜: {test_topic}")
        result = graph.invoke({"topic": test_topic})
        print(f"æœ€ä½³ç¬‘è¯: {result['best_selected_joke'][:50]}...\n")
```

### è¿è¡Œç»“æœç¤ºä¾‹

```
============================================================
ğŸ“Š å›¾ç»“æ„å¯è§†åŒ–
============================================================
%%{init: {'flowchart': {'curve': 'linear'}}}%%
graph TD;
    __start__([__start__]):::startclass;
    generate_topics([generate_topics]):::otherclass;
    generate_joke([generate_joke]):::otherclass;
    best_joke([best_joke]):::otherclass;
    __end__([__end__]):::endclass;
    __start__ --> generate_topics;
    generate_topics -.-> generate_joke;
    generate_joke --> best_joke;
    best_joke --> __end__;

============================================================
ğŸš€ æ‰§è¡Œç¬‘è¯ç”Ÿæˆç³»ç»Ÿ
============================================================

â³ æ‰§è¡Œä¸­...

ğŸ¯ ä¸»é¢˜: åŠ¨ç‰©
ğŸ“ ç”Ÿæˆäº† 3 ä¸ªå­ä¸»é¢˜: ['çŒ«', 'ç‹—', 'å¤§è±¡']
ğŸ“¤ åˆ†å‘ 3 ä¸ªç¬‘è¯ç”Ÿæˆä»»åŠ¡
ğŸ“Œ èŠ‚ç‚¹ [generate_topics] å®Œæˆ
ğŸ˜‚ ç”Ÿæˆç¬‘è¯ - ä¸»é¢˜: çŒ«
  ğŸ“Œ ç¬‘è¯ç”Ÿæˆå®Œæˆ
ğŸ˜‚ ç”Ÿæˆç¬‘è¯ - ä¸»é¢˜: ç‹—
  ğŸ“Œ ç¬‘è¯ç”Ÿæˆå®Œæˆ
ğŸ˜‚ ç”Ÿæˆç¬‘è¯ - ä¸»é¢˜: å¤§è±¡
  ğŸ“Œ ç¬‘è¯ç”Ÿæˆå®Œæˆ
ğŸ† é€‰å‡ºæœ€ä½³ç¬‘è¯ï¼ˆç¼–å· 1ï¼‰
ğŸ“Œ èŠ‚ç‚¹ [best_joke] å®Œæˆ

============================================================
ğŸ“‹ æœ€ç»ˆç»“æœ
============================================================

ğŸ¯ ä¸»é¢˜: åŠ¨ç‰©

ğŸ“ å­ä¸»é¢˜: ['çŒ«', 'ç‹—', 'å¤§è±¡']

ğŸ˜‚ æ‰€æœ‰ç”Ÿæˆçš„ç¬‘è¯:

  ç¬‘è¯ 0:
  ä¸ºä»€ä¹ˆçŒ«æ€»æ˜¯çœ‹èµ·æ¥å¾ˆå‚²æ…¢ï¼Ÿå› ä¸ºå®ƒä»¬çŸ¥é“æ¯æ¬¡ä½ å«å®ƒä»¬çš„åå­—ï¼Œå®ƒä»¬é€‰æ‹©ä¸å›åº”ï¼

  ç¬‘è¯ 1:
  ç‹—ä¸ºä»€ä¹ˆä¸ä¼šç”¨ç”µè„‘ï¼Ÿå› ä¸ºå®ƒä»¬æ€»æ˜¯æŠŠ"Bark"é”™æ‰“æˆ"Bytes"ï¼

  ç¬‘è¯ 2:
  å¤§è±¡ä¸ºä»€ä¹ˆä»æ¥ä¸ç©æ‰è¿·è—ï¼Ÿå› ä¸ºå®ƒå¤ªå¤§äº†ï¼Œè—å“ªéƒ½è¢«å‘ç°ï¼

ğŸ† æœ€ä½³ç¬‘è¯:
  ç‹—ä¸ºä»€ä¹ˆä¸ä¼šç”¨ç”µè„‘ï¼Ÿå› ä¸ºå®ƒä»¬æ€»æ˜¯æŠŠ"Bark"é”™æ‰“æˆ"Bytes"ï¼

============================================================
ğŸ”„ æµ‹è¯•å…¶ä»–ä¸»é¢˜
============================================================

ä¸»é¢˜: ç§‘æŠ€
æœ€ä½³ç¬‘è¯: ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯ç©¿ç°è‰²è¡£æœï¼Ÿå› ä¸ºä»–ä»¬ä¸æƒ³å¤„ç†"é¢œè‰²"å¼‚å¸¸ï¼...

ä¸»é¢˜: ç¾é£Ÿ
æœ€ä½³ç¬‘è¯: ä¸ºä»€ä¹ˆæŠ«è¨ä»æ¥ä¸è¯´è°ï¼Ÿå› ä¸ºå®ƒæ€»æ˜¯"è–„é¥¼"å¦ç™½ï¼...
```

### æ ¸å¿ƒçŸ¥è¯†ç‚¹å›é¡¾

| æ¦‚å¿µ | è¯´æ˜ | ä»£ç ç¤ºä¾‹ |
|------|------|----------|
| **Send API** | åŠ¨æ€åˆ›å»ºå¹¶è¡Œä»»åŠ¡ | `Send("node_name", {"key": value})` |
| **åŠ¨æ€åˆ†å‘** | è¿è¡Œæ—¶å†³å®šå¹¶è¡Œæ•°é‡ | `[Send(...) for item in items]` |
| **OverallState** | å…¨å±€çŠ¶æ€ï¼ŒåŒ…å«æ‰€æœ‰å­—æ®µ | `jokes: Annotated[List[str], operator.add]` |
| **å±€éƒ¨ State** | Map èŠ‚ç‚¹åªéœ€è¦çš„å­—æ®µ | `class JokeState: subject: str` |
| **æ¡ä»¶è¾¹ + Send** | å®ç°åŠ¨æ€ Map | `add_conditional_edges(src, send_func, [targets])` |
| **Reducer** | åˆå¹¶å¹¶è¡Œç»“æœ | `operator.add` æ‹¼æ¥åˆ—è¡¨ |
| **Map é˜¶æ®µ** | å¹¶è¡Œå¤„ç†æ¯ä¸ªå­ä»»åŠ¡ | `generate_joke` èŠ‚ç‚¹ |
| **Reduce é˜¶æ®µ** | èšåˆæ‰€æœ‰ç»“æœ | `best_joke` èŠ‚ç‚¹ |
