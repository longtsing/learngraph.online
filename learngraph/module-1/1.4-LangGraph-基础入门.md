# LangGraph åŸºç¡€å…¥é—¨

>  ç½‘ç«™ä½¿ç”¨è¯´æ˜
> - æœ¬ç½‘ç«™å¯ä»¥å…ç™»é™†è¿è¡Œ Python ä»£ç 
> - Python ä»£ç å¯ä»¥ç¼–è¾‘å¹¶ä¸´æ—¶ä¿å­˜ï¼Œä½†ä¸ä¼šæ°¸ä¹…ä¿å­˜ï¼Œç½‘é¡µåˆ·æ–°åä¼šè‡ªåŠ¨è¿˜åŸ
> - å¯¹ç½‘ç«™çš„ä½¿ç”¨æœ‰ä»»ä½•é—®é¢˜ï¼Œå¯ä»¥åˆ° [é—®é¢˜åé¦ˆ](http://localhost:5173/feedback.html) ï¼ˆæŒ‰é’®åœ¨æ¯ä¸ªé¡µé¢çš„å³ä¸‹è§’ï¼‰å…ç™»å½•è¿›è¡Œè¯„è®º
> - è¿è¡Œ `LangGraph/LangChain`ä»£ç ï¼Œéœ€è¦ç”¨æˆ·è¾“å…¥è‡ªå·±çš„ [API Key](http://localhost:5173/python-run.html)
> - é‡è¦å£°æ˜ï¼šæœ¬ç½‘ç«™ä¸ä¼šä¿å­˜ç”¨æˆ·çš„ API Key æ•°æ®ï¼Œè¯·æ”¾å¿ƒè¾“å…¥

## æ¦‚è¿°

æœ¬æ–‡æ¡£å‚è€ƒ **LangChain Academy** çš„åŸºç¡€å…¥é—¨æ¨¡å—ï¼Œè¿›è¡Œå¤§å¹…è¡¥å……å’Œæ‹“å±•ã€‚è¿™æ˜¯å­¦ä¹  LangGraph çš„ç¬¬ä¸€æ­¥ï¼Œå¸®åŠ©ä½ ç†è§£ LangChain ç”Ÿæ€ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ã€Chat Modelsï¼ˆèŠå¤©æ¨¡å‹ï¼‰çš„ä½¿ç”¨ï¼Œä»¥åŠåŸºç¡€å·¥å…·é›†æˆã€‚é€šè¿‡æœ¬æ•™ç¨‹ï¼Œä½ å°†æŒæ¡æ„å»º Agentic AI åº”ç”¨çš„åŸºç¡€çŸ¥è¯†ã€‚

---

## ğŸ“š æœ¯è¯­è¡¨

| æœ¯è¯­åç§° | LangGraph å®šä¹‰å’Œè§£è¯» | Python å®šä¹‰å’Œè¯´æ˜ | é‡è¦ç¨‹åº¦ |
|---------|---------------------|------------------|---------|
| **LangChain** | æ„å»º LLM åº”ç”¨çš„å¼€å‘æ¡†æ¶ï¼Œæä¾›æ¨¡å—åŒ–ç»„ä»¶å’Œæ ‡å‡†åŒ–æ¥å£ | Python åŒ…ï¼ŒåŒ…å« Chat Modelsã€Promptsã€Toolsã€Memory ç­‰æ¨¡å— | â­â­â­â­â­ |
| **LangGraph** | LangChain ç”Ÿæ€çš„å›¾ç¼–æ’æ¡†æ¶ï¼Œç”¨äºæ„å»ºæœ‰çŠ¶æ€çš„ Agent ç³»ç»Ÿ | Python åº“ï¼Œé€šè¿‡å›¾ç»“æ„(StateGraph)ç¼–æ’å¤æ‚å·¥ä½œæµ | â­â­â­â­â­ |
| **Chat Model** | èŠå¤©æ¨¡å‹ï¼Œæ¥å—æ¶ˆæ¯åˆ—è¡¨è¾“å…¥å¹¶è¿”å› AI æ¶ˆæ¯çš„ LLM æ¥å£ | ChatOpenAI ç­‰ç±»ï¼Œå®ç° Runnable æ¥å£çš„ç»Ÿä¸€è°ƒç”¨æ–¹æ³• | â­â­â­â­â­ |
| **Temperature** | æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶ LLM è¾“å‡ºçš„éšæœºæ€§å’Œåˆ›é€ æ€§ | æµ®ç‚¹æ•°å‚æ•°(0-2)ï¼Œ0 ä¸ºç¡®å®šæ€§è¾“å‡ºï¼Œ1 ä¸ºæœ€å¤§åˆ›é€ æ€§ | â­â­â­â­ |
| **Message Types** | æ¶ˆæ¯ç±»å‹ï¼ŒåŒºåˆ†å¯¹è¯ä¸­çš„ä¸åŒè§’è‰²å’Œç”¨é€” | HumanMessageã€AIMessageã€SystemMessageã€FunctionMessage ç±» | â­â­â­â­â­ |
| **Runnable Interface** | å¯è¿è¡Œæ¥å£ï¼ŒLangChain æ‰€æœ‰ç»„ä»¶çš„ç»Ÿä¸€è°ƒç”¨æ ‡å‡† | å®šä¹‰ invokeã€streamã€batchã€ainvoke ç­‰æ–¹æ³•çš„æ¥å£ | â­â­â­â­â­ |
| **Tavily Search** | ä¸º LLM ä¼˜åŒ–çš„æœç´¢å¼•æ“ï¼Œæä¾›ç»“æ„åŒ–æœç´¢ç»“æœ | TavilySearchResults ç±»ï¼Œè¿”å›åŒ…å« url å’Œ content çš„å­—å…¸åˆ—è¡¨ | â­â­â­â­ |
| **Environment Variable** | ç¯å¢ƒå˜é‡ï¼Œç”¨äºå®‰å…¨å­˜å‚¨ API å¯†é’¥ç­‰æ•æ„Ÿä¿¡æ¯ | os.environ å­—å…¸ï¼Œé€šè¿‡ get/set æ–¹æ³•è®¿é—®ç³»ç»Ÿç¯å¢ƒå˜é‡ | â­â­â­â­â­ |
| **getpass** | å®‰å…¨è¾“å…¥æ¨¡å—ï¼Œéšè—ç”¨æˆ·è¾“å…¥å†…å®¹(å¦‚å¯†ç ) | Python æ ‡å‡†åº“æ¨¡å—ï¼Œgetpass.getpass() æ–¹æ³•å®ç°éšè—è¾“å…¥ | â­â­â­â­ |
| **Streaming** | æµå¼è¾“å‡ºï¼Œé€ token è¿”å› LLM ç”Ÿæˆç»“æœè€Œéä¸€æ¬¡æ€§è¿”å› | stream() æ–¹æ³•è¿”å›ç”Ÿæˆå™¨ï¼Œé€šè¿‡ for å¾ªç¯é€ä¸ªè·å–è¾“å‡º | â­â­â­â­ |
| **Model Selection** | æ¨¡å‹é€‰æ‹©ï¼Œæ ¹æ®ä»»åŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„ LLM æ¨¡å‹ | é€šè¿‡ model å‚æ•°æŒ‡å®šï¼Œå¦‚ "gpt-4"ã€"gpt-3.5-turbo" ç­‰ | â­â­â­â­ |
| **Token Usage** | Token ä½¿ç”¨é‡ï¼Œè®°å½• LLM è¾“å…¥è¾“å‡ºæ¶ˆè€—çš„ token æ•°é‡ | response_metadata ä¸­çš„ token_usage å­—æ®µï¼ŒåŒ…å«è®¡è´¹ä¿¡æ¯ | â­â­â­â­ |

---

## æ ¸å¿ƒæ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ LangChainï¼Ÿ

LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»º **LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰åº”ç”¨** çš„å¼€å‘æ¡†æ¶ã€‚å®ƒæä¾›äº†ï¼š

- **æ¨¡å—åŒ–ç»„ä»¶**ï¼šChat Modelsã€Promptsã€Toolsã€Memory ç­‰
- **æ ‡å‡†åŒ–æ¥å£**ï¼šç»Ÿä¸€çš„ APIï¼Œæ”¯æŒå¤šç§ LLM æä¾›å•†
- **é“¾å¼ç»„åˆ**ï¼šå°†å¤šä¸ªç»„ä»¶ç»„åˆæˆå¤æ‚çš„å·¥ä½œæµ

### ä»€ä¹ˆæ˜¯ LangGraphï¼Ÿ

LangGraph æ˜¯ LangChain ç”Ÿæ€ç³»ç»Ÿä¸­çš„**å›¾ç¼–æ’æ¡†æ¶**ï¼Œä¸“é—¨ç”¨äºæ„å»º Agent å’Œå¤š Agent åº”ç”¨ã€‚å®ƒçš„æ ¸å¿ƒä¼˜åŠ¿ï¼š

- **å¾ªç¯æ”¯æŒï¼ˆCyclesï¼‰**ï¼šæ”¯æŒå¸¦å¾ªç¯çš„å·¥ä½œæµï¼Œè€Œä¸ä»…ä»…æ˜¯ DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰
- **ç²¾ç¡®æ§åˆ¶ï¼ˆControllabilityï¼‰**ï¼šç›¸å¯¹äºæ‹–æ‹½å¼çš„ SDKï¼ŒLangGraph å¯ä»¥ç¼–ç¨‹ç²¾ç¡®æ§åˆ¶ Agent çš„æ‰§è¡Œæµç¨‹
- **çŠ¶æ€æŒä¹…åŒ–ï¼ˆPersistenceï¼‰**ï¼šæ”¯æŒçŠ¶æ€çš„ä¿å­˜å’Œæ¢å¤

### ä¸ºä»€ä¹ˆéœ€è¦ LangGraphï¼Ÿ

ä¼ ç»Ÿçš„ Agent æ¡†æ¶å­˜åœ¨é—®é¢˜ï¼š
- ç¼ºä¹å¯¹æ‰§è¡Œæµç¨‹çš„æ§åˆ¶
- éš¾ä»¥å¤„ç†å¤æ‚çš„å†³ç­–é€»è¾‘
- æ— æ³•å¯é åœ°æŠ•å…¥ç”Ÿäº§ç¯å¢ƒ

LangGraph çš„è§£å†³æ–¹æ¡ˆï¼š
- å°† Agent å·¥ä½œæµå»ºæ¨¡ä¸º**çŠ¶æ€å›¾**
- é€šè¿‡èŠ‚ç‚¹å’Œè¾¹ç²¾ç¡®æ§åˆ¶æ‰§è¡Œè·¯å¾„
- æ”¯æŒäººå·¥ä»‹å…¥ã€é”™è¯¯æ¢å¤ç­‰ç”Ÿäº§çº§ç‰¹æ€§

### LangGraph çš„æ ¸å¿ƒé€»è¾‘ï¼ˆé‡è¦ï¼ï¼‰
LangGraph çš„æ ¸å¿ƒç›®çš„ï¼Œæ˜¯è®©å¼€å‘è€…èƒ½å¤Ÿï¼š

- å®šä¹‰å¤æ‚å¤šæ™ºèƒ½ä½“ï¼ˆmulti-agentï¼‰å·¥ä½œæµ
- è®©è¿™äº›æ™ºèƒ½ä½“å¯è§†åŒ–ã€å¯æ§ã€å¯å›æº¯
- æ”¯æŒæœ‰çŠ¶æ€ï¼ˆstatefulï¼‰å¯¹è¯ä¸æ‰§è¡Œï¼Œè€Œä¸ä»…æ˜¯ä¸€æ¬¡æ€§è°ƒç”¨

## è¯¾ç¨‹ç»“æ„

æœ¬è¯¾ç¨‹åŒ…å«å¤šä¸ªæ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—èšç„¦ç‰¹å®šä¸»é¢˜ï¼š

```
ã€ŠAgenticAI ä¸ LangGraph é£é€Ÿä¸Šæ‰‹ã€‹/
â”œâ”€â”€ ç¬¬ 0 ç« /        # åŸºç¡€å…¥é—¨ï¼ˆæœ¬æ•™ç¨‹ï¼‰
â”œâ”€â”€ ç¬¬ 1 ç« /        # LangGraph æ ¸å¿ƒæ¦‚å¿µ
â”œâ”€â”€ ç¬¬ 2 ç« /        # Agent æ¶æ„
â”œâ”€â”€ ç¬¬ 3 ç« /        # Multi-Agent ç³»ç»Ÿ
â”œâ”€â”€ ç¬¬ 4 ç« /        # é«˜çº§æ¨¡å¼ï¼ˆMap-Reduceã€Sub-graphs ç­‰ï¼‰
â””â”€â”€ ...
```

æ¯ä¸ªæ¨¡å—åŒ…å«ï¼š
- **å¯æ‰§è¡Œçš„**ï¼šäº¤äº’å¼ç½‘é¡µï¼Œå¯åœ¨æœ¬ä¹¦é¡µé¢ç›´æ¥æ‰§è¡Œ Python ä»£ç 
- **è§†é¢‘æ•™ç¨‹**ï¼šé…å¥—è®²è§£è§†é¢‘

---

## ç¯å¢ƒé…ç½®è¯¦è§£

### 1. å®‰è£…ä¾èµ–ï¼ˆä¸åŒçš„æ“ä½œç³»ç»Ÿã€ä¸åŒçš„ Python ç¯å¢ƒé…ç½®å¯èƒ½ä¼šå‡ºç°å„ç§é—®é¢˜ï¼Œéœ€è¦ä¸€å®šçš„è€å¿ƒå¤„ç†ï¼‰

```bash
pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python
```

**ä¾èµ–è¯´æ˜ï¼š**

| åŒ…å | ç”¨é€” |
|------|------|
| `langchain_openai` | OpenAI æ¨¡å‹é›†æˆï¼ˆChatGPTã€GPT-4 ç­‰ï¼‰ |
| `langchain_core` | LangChain æ ¸å¿ƒç»„ä»¶ï¼ˆMessagesã€Runnables ç­‰ï¼‰ |
| `langchain_community` | ç¤¾åŒºå·¥å…·ï¼ˆTavily æœç´¢ç­‰ï¼‰ |
| `tavily-python` | Tavily æœç´¢å¼•æ“ SDK |

### 2. é…ç½® API å¯†é’¥

```python
import os, getpass

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("OPENAI_API_KEY")
```

**Python çŸ¥è¯†ç‚¹ï¼šç¯å¢ƒå˜é‡ä¸å®‰å…¨æ€§**

```python
# æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦å­˜åœ¨
os.environ.get(var)  # è¿”å›å€¼æˆ– None

# å®‰å…¨åœ°è·å–å¯†é’¥ï¼ˆè¾“å…¥æ—¶ä¸æ˜¾ç¤ºï¼‰
getpass.getpass(f"{var}: ")  # ç±»ä¼¼å¯†ç è¾“å…¥

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ[var] = "your-api-key"
```

**ä¸ºä»€ä¹ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Ÿ**
- ğŸ”’ **å®‰å…¨æ€§**ï¼šé¿å…å°†å¯†é’¥ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
- ğŸ”„ **çµæ´»æ€§**ï¼šå¯ä»¥åœ¨ä¸åŒç¯å¢ƒä½¿ç”¨ä¸åŒå¯†é’¥
- âœ… **æœ€ä½³å®è·µ**ï¼šéµå¾ª 12-Factor App åŸåˆ™

---

## ğŸ¤– Chat Models è¯¦è§£

### ä»€ä¹ˆæ˜¯ Chat Modelï¼Ÿ

Chat Model æ˜¯ä¸€ç§æ¥å—**æ¶ˆæ¯åˆ—è¡¨**ä½œä¸ºè¾“å…¥ï¼Œè¿”å›**èŠå¤©æ¶ˆæ¯**ä½œä¸ºè¾“å‡ºçš„æ¨¡å‹ã€‚ä¸ä¼ ç»Ÿçš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ä¸åŒï¼ŒChat Model ç†è§£å¯¹è¯çš„ä¸Šä¸‹æ–‡å’Œè§’è‰²ã€‚

### æ ¸å¿ƒç‰¹æ€§

```
è¾“å…¥ï¼š[HumanMessage, AIMessage, SystemMessage, ...]
  â†“
Chat Model (å¦‚ GPT-4)
  â†“
è¾“å‡ºï¼šAIMessage
```

### LangChain çš„ Chat Model é›†æˆ

LangChain **ä¸æ‰˜ç®¡æ¨¡å‹**ï¼Œè€Œæ˜¯æä¾›ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒå¤šä¸ªæä¾›å•†ï¼š

| æä¾›å•† | æ¨¡å‹ç¤ºä¾‹ | é›†æˆåŒ… |
|--------|---------|--------|
| OpenAI | GPT-4, GPT-3.5 | `langchain_openai` |
| Anthropic | Claude | `langchain_anthropic` |
| Google | Gemini | `langchain_google_genai` |
| Azure | Azure OpenAI | `langchain_openai` |

**å¥½å¤„ï¼š**
- ç»Ÿä¸€ APIï¼Œè½»æ¾åˆ‡æ¢æ¨¡å‹
- æ¨¡å‹æ— å…³çš„åº”ç”¨è®¾è®¡
- æ”¯æŒ 70+ æ¨¡å‹æä¾›å•†

---

## ğŸ’» Chat Model å®æˆ˜

### 1. åˆå§‹åŒ– Chat Model

```python
from langchain_openai import ChatOpenAI

# åˆå§‹åŒ– GPT-4o
gpt4o_chat = ChatOpenAI(model="gpt-5-nano", temperature=0)

# åˆå§‹åŒ– GPT-3.5ï¼ˆæ›´ä¾¿å®œï¼‰
gpt35_chat = ChatOpenAI(model="gpt-3.5-turbo-0125", temperature=0)
```

**å…³é”®å‚æ•°è¯¦è§£ï¼š**

#### `model`ï¼ˆæ¨¡å‹åç§°ï¼‰

```python
# GPT-4/5 ç³»åˆ— - é«˜è´¨é‡ã€è¾ƒè´µ
"gpt-5-nano"              # æœ€æ–°ä¼˜åŒ–ç‰ˆæœ¬
"gpt-4-turbo"         # GPT-4 Turbo

# GPT-3.5 ç³»åˆ— - ä¾¿å®œã€å¿«é€Ÿ
"gpt-3.5-turbo-0125"  # GPT-3.5 æœ€æ–°ç‰ˆæœ¬
```

**å¦‚ä½•é€‰æ‹©ï¼Ÿ**
- éœ€è¦é«˜è´¨é‡è¾“å‡º â†’ GPT-5
- éœ€è¦é™ä½æˆæœ¬ â†’ GPT-5-nano
- å…¼å®¹æ€§æ›´å¥½ â†’ GPT-4o-miniï¼ˆæœ¬è¯¾ç¨‹é»˜è®¤ï¼‰

#### `temperature`ï¼ˆæ¸©åº¦å‚æ•°ï¼‰

æ§åˆ¶è¾“å‡ºçš„**éšæœºæ€§**å’Œ**åˆ›é€ æ€§**ï¼š

```python
temperature = 0    # ç¡®å®šæ€§è¾“å‡ºï¼ˆé€‚åˆäº‹å®æŸ¥è¯¢ã€ä»£ç ç”Ÿæˆï¼‰
temperature = 0.7  # å¹³è¡¡ï¼ˆé€‚åˆå¯¹è¯ï¼‰
temperature = 1.0  # æœ€å¤§åˆ›é€ æ€§ï¼ˆé€‚åˆåˆ›æ„å†™ä½œï¼‰
```

**ç¤ºä¾‹å¯¹æ¯”ï¼š**

```python
# Temperature = 0 (æ¯æ¬¡è¾“å‡ºå‡ ä¹ç›¸åŒ)
"å·´é»æ˜¯æ³•å›½çš„é¦–éƒ½ã€‚"
"å·´é»æ˜¯æ³•å›½çš„é¦–éƒ½ã€‚"

# Temperature = 1.0 (æ¯æ¬¡è¾“å‡ºä¸åŒ)
"å·´é»ï¼Œè¿™åº§æµªæ¼«ä¹‹éƒ½ï¼Œæ˜¯æ³•å›½çš„é¦–éƒ½ã€‚"
"æ³•å›½çš„é¦–éƒ½æ˜¯ç¾ä¸½çš„å·´é»ã€‚"
```

---

### 2. è°ƒç”¨ Chat Model

#### æ–¹æ³• 1ï¼šä½¿ç”¨æ¶ˆæ¯å¯¹è±¡

```python
from langchain_core.messages import HumanMessage

# åˆ›å»ºæ¶ˆæ¯
msg = HumanMessage(content="Hello world", name="Lance")

# è°ƒç”¨æ¨¡å‹
response = gpt4o_chat.invoke([msg])
```

**è¾“å‡ºï¼š**
```python
AIMessage(
    content='Hello! How can I assist you today?',
    response_metadata={
        'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20},
        'model_name': 'gpt-5-nano-2024-05-13',
        'finish_reason': 'stop'
    },
    id='run-d3c4bc85-ef14-49f6-ba7e-91bf455cffee-0'
)
```

**LangChain çŸ¥è¯†ç‚¹ï¼šæ¶ˆæ¯ç±»å‹**

| æ¶ˆæ¯ç±»å‹ | ä½œç”¨ | ç¤ºä¾‹ |
|---------|------|------|
| `HumanMessage` | ç”¨æˆ·è¾“å…¥ | ç”¨æˆ·çš„é—®é¢˜ã€æŒ‡ä»¤ |
| `AIMessage` | AI å›å¤ | æ¨¡å‹çš„å›ç­” |
| `SystemMessage` | ç³»ç»ŸæŒ‡ä»¤ | è®¾å®š AI çš„è§’è‰²ã€è¡Œä¸º |
| `FunctionMessage` | å‡½æ•°è°ƒç”¨ç»“æœ | Tool æ‰§è¡Œçš„è¿”å›å€¼ |

**æ¶ˆæ¯å¯¹è±¡ç»“æ„ï¼š**

```python
HumanMessage(
    content="Hello world",  # æ¶ˆæ¯å†…å®¹
    name="Lance"            # å¯é€‰ï¼šå‘é€è€…åç§°
)
```

#### æ–¹æ³• 2ï¼šä½¿ç”¨å­—ç¬¦ä¸²ï¼ˆç®€åŒ–å†™æ³•ï¼‰

```python
response = gpt4o_chat.invoke("hello world")
```

**å†…éƒ¨è½¬æ¢ï¼š**
```python
"hello world"  â†’  HumanMessage(content="hello world")
```

**ä½•æ—¶ä½¿ç”¨ï¼Ÿ**
- âœ… ç®€å•å•è½®å¯¹è¯
- âŒ å¤šè½®å¯¹è¯ï¼ˆéœ€è¦ä¿ç•™å†å²ï¼‰

---

### 3. åˆ‡æ¢æ¨¡å‹

```python
# GPT-4o å›å¤
gpt4o_chat.invoke("hello world")
# â†’ AIMessage(content='Hello! How can I assist you today?', ...)

# GPT-3.5 å›å¤ï¼ˆä½¿ç”¨ç›¸åŒæ¥å£ï¼ï¼‰
gpt35_chat.invoke("hello world")
# â†’ AIMessage(content='Hello! How can I assist you today?', ...)
```

**ä¼˜åŠ¿ï¼š**
- ğŸ”„ ç»Ÿä¸€æ¥å£ï¼Œæ— éœ€ä¿®æ”¹ä»£ç 
- ğŸ’° çµæ´»åˆ‡æ¢ï¼Œä¼˜åŒ–æˆæœ¬
- ğŸ§ª A/B æµ‹è¯•ä¸åŒæ¨¡å‹

---

## ğŸ” æœç´¢å·¥å…·é›†æˆï¼šTavily

### ä»€ä¹ˆæ˜¯ Tavilyï¼Ÿ

Tavily æ˜¯ä¸€ä¸ª**ä¸º LLM ä¼˜åŒ–çš„æœç´¢å¼•æ“**ï¼Œæä¾›ï¼š
- ğŸ“Š ç»“æ„åŒ–æœç´¢ç»“æœ
- âš¡ å¿«é€Ÿå“åº”ï¼ˆé’ˆå¯¹ RAG ä¼˜åŒ–ï¼‰
- ğŸ’ é«˜è´¨é‡å†…å®¹ï¼ˆè¿‡æ»¤ä½è´¨é‡ç½‘é¡µï¼‰

### é…ç½® Tavily API

```python
_set_env("TAVILY_API_KEY")
```

**å…è´¹é¢åº¦ï¼š**
- æ–°ç”¨æˆ·èµ é€å…è´¹ credits
- è¶³å¤Ÿå®Œæˆæœ¬è¯¾ç¨‹çš„å­¦ä¹ 

### ä½¿ç”¨ Tavily æœç´¢

```python
from langchain_community.tools.tavily_search import TavilySearchResults

# åˆå§‹åŒ–æœç´¢å·¥å…·
tavily_search = TavilySearchResults(max_results=3)

# æ‰§è¡Œæœç´¢
search_docs = tavily_search.invoke("What is LangGraph?")
```

**è¾“å‡ºç¤ºä¾‹ï¼š**

```python
[
    {
        'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',
        'content': 'LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.'
    },
    {
        'url': 'https://langchain-ai.github.io/langgraph/',
        'content': 'Overview LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence.'
    },
    {
        'url': 'https://www.youtube.com/watch?v=nmDFSVRnr4Q',
        'content': 'LangGraph is an extension of LangChain enabling Multi-Agent conversation and cyclic chains.'
    }
]
```

**è¿”å›ç»“æ„ï¼š**

```python
{
    'url': str,      # æ¥æº URL
    'content': str   # æå–çš„æ–‡æœ¬å†…å®¹
}
```

---

## ğŸ“ æ ¸å¿ƒçŸ¥è¯†ç‚¹æ€»ç»“

### LangChain æ ¸å¿ƒæ¦‚å¿µ

#### 1. Runnable æ¥å£

æ‰€æœ‰ LangChain ç»„ä»¶ï¼ˆChat Modelsã€Toolsã€Chainsï¼‰éƒ½å®ç° **Runnable æ¥å£**ï¼š

| æ–¹æ³• | ä½œç”¨ | ä½¿ç”¨åœºæ™¯ |
|------|------|---------|
| `invoke(input)` | åŒæ­¥è°ƒç”¨ | å•æ¬¡è¯·æ±‚ |
| `stream(input)` | æµå¼è¾“å‡º | é•¿æ–‡æœ¬ç”Ÿæˆ |
| `batch(inputs)` | æ‰¹é‡è°ƒç”¨ | å¹¶è¡Œå¤„ç†å¤šä¸ªè¾“å…¥ |
| `ainvoke(input)` | å¼‚æ­¥è°ƒç”¨ | é«˜å¹¶å‘åœºæ™¯ |

**ç¤ºä¾‹ï¼š**

```python
# invoke - ç­‰å¾…å®Œæ•´å“åº”
response = chat.invoke("Tell me a joke")

# stream - é€ token è¿”å›
for chunk in chat.stream("Tell me a joke"):
    print(chunk.content, end="")
```

#### 2. Messagesï¼ˆæ¶ˆæ¯ç³»ç»Ÿï¼‰

LangChain ä½¿ç”¨**æ¶ˆæ¯å¯¹è±¡**è€Œéçº¯æ–‡æœ¬ï¼š

```python
# âŒ ä¸æ¨èï¼šçº¯æ–‡æœ¬
"What is the capital of France?"

# âœ… æ¨èï¼šæ¶ˆæ¯å¯¹è±¡
HumanMessage(content="What is the capital of France?")
```

**ä¼˜åŠ¿ï¼š**
- ğŸ“‹ ä¿ç•™å¯¹è¯å†å²
- ğŸ­ åŒºåˆ†ä¸åŒè§’è‰²
- ğŸ”§ æ”¯æŒå¤šæ¨¡æ€ï¼ˆæ–‡æœ¬ã€å›¾ç‰‡ã€éŸ³é¢‘ï¼‰

#### 3. æ¨¡å‹åˆå§‹åŒ–æœ€ä½³å®è·µ

```python
# âœ… åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–ä¸€æ¬¡
chat = ChatOpenAI(model="gpt-5-nano", temperature=0)

# âŒ ä¸è¦åœ¨å¾ªç¯ä¸­é‡å¤åˆå§‹åŒ–
for _ in range(10):
    chat = ChatOpenAI(...)  # æ€§èƒ½æµªè´¹
```

---

### Python æ ¸å¿ƒçŸ¥è¯†ç‚¹

#### 1. ç¯å¢ƒå˜é‡ç®¡ç†

```python
import os

# è¯»å–ç¯å¢ƒå˜é‡
api_key = os.environ.get("OPENAI_API_KEY")

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_KEY"] = "sk-..."

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨
if "OPENAI_API_KEY" in os.environ:
    print("API key is set")
```

**ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µï¼š**

```bash
# ä½¿ç”¨ .env æ–‡ä»¶ï¼ˆéœ€è¦ python-dotenvï¼‰
# .env
OPENAI_API_KEY=sk-xxx
TAVILY_API_KEY=tvly-xxx

# Python ä»£ç 
from dotenv import load_dotenv
load_dotenv()  # è‡ªåŠ¨åŠ è½½ .env æ–‡ä»¶
```

#### 2. getpass æ¨¡å—ï¼ˆå®‰å…¨è¾“å…¥ï¼‰

```python
import getpass

# ä¸æ˜¾ç¤ºè¾“å…¥å†…å®¹ï¼ˆç±»ä¼¼å¯†ç è¾“å…¥ï¼‰
password = getpass.getpass("Enter password: ")
# ç”¨æˆ·è¾“å…¥æ—¶å±å¹•ä¸æ˜¾ç¤º

# å¯¹æ¯”æ™®é€š input()
username = input("Enter username: ")  # è¾“å…¥å†…å®¹å¯è§
```

#### 3. åˆ—è¡¨æ¨å¯¼å¼

```python
# æœç´¢ç»“æœå¤„ç†ç¤ºä¾‹
urls = [doc['url'] for doc in search_docs]
# â†’ ['https://...', 'https://...', ...]

# ç­‰ä»·äºï¼š
urls = []
for doc in search_docs:
    urls.append(doc['url'])
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. API å¯†é’¥å®‰å…¨

#### âœ… æ­£ç¡®åšæ³•

```python
# 1. ä½¿ç”¨ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_KEY"] = "sk-..."

# 2. ä½¿ç”¨ .env æ–‡ä»¶
# .env
OPENAI_API_KEY=sk-xxx

# 3. ä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
# - AWS Secrets Manager
# - HashiCorp Vault
# - Azure Key Vault
```

#### âŒ é”™è¯¯åšæ³•

```python
# ä¸è¦ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
chat = ChatOpenAI(api_key="sk-xxxxxxxxxxxxxxxx")  # âŒ

# ä¸è¦æäº¤åˆ° Git
# config.py
API_KEY = "sk-xxxxxxxxxxxxxxxx"  # âŒ
```

### 2. æ¨¡å‹é€‰æ‹©ç­–ç•¥

| ä»»åŠ¡ç±»å‹ | æ¨èæ¨¡å‹ | åŸå›  |
|---------|---------|------|
| äº‹å®æŸ¥è¯¢ | GPT-4o | å‡†ç¡®æ€§é«˜ |
| åˆ›æ„å†™ä½œ | GPT-4 | è´¨é‡å¥½ |
| ç®€å•åˆ†ç±» | GPT-3.5 | æˆæœ¬ä½ |
| ä»£ç ç”Ÿæˆ | GPT-4o | ä»£ç è´¨é‡é«˜ |
| æ‰¹é‡å¤„ç† | GPT-3.5 | æˆæœ¬ä¼˜åŒ– |

### 3. Temperature è®¾ç½®æŒ‡å—

```python
# äº‹å®æ€§ä»»åŠ¡ - ä½ temperature
chat = ChatOpenAI(model="gpt-5-nano", temperature=0)
# é€‚åˆï¼šæ•°å­¦ã€ç¿»è¯‘ã€æ•°æ®æå–

# åˆ›æ„ä»»åŠ¡ - é«˜ temperature
chat = ChatOpenAI(model="gpt-5-nano", temperature=0.8)
# é€‚åˆï¼šæ•…äº‹åˆ›ä½œã€è¥é”€æ–‡æ¡ˆã€å¤´è„‘é£æš´

# å¹³è¡¡ä»»åŠ¡ - ä¸­ç­‰ temperature
chat = ChatOpenAI(model="gpt-5-nano", temperature=0.5)
# é€‚åˆï¼šå¯¹è¯ã€æ‘˜è¦ã€é—®ç­”
```

### 4. é”™è¯¯å¤„ç†

```python
from langchain_openai import ChatOpenAI

try:
    chat = ChatOpenAI(model="gpt-5-nano", temperature=0)
    response = chat.invoke("Hello")
except Exception as e:
    print(f"é”™è¯¯ï¼š{e}")
    # å¤„ç†é”™è¯¯ï¼šé‡è¯•ã€é™çº§åˆ°å…¶ä»–æ¨¡å‹ç­‰
```

**å¸¸è§é”™è¯¯ï¼š**
- `AuthenticationError`ï¼šAPI å¯†é’¥é”™è¯¯
- `RateLimitError`ï¼šè¶…è¿‡é€Ÿç‡é™åˆ¶
- `APIError`ï¼šOpenAI æœåŠ¡é”™è¯¯

---

## ğŸš€ è¿›é˜¶æŠ€å·§

### 1. ä½¿ç”¨ SystemMessage è®¾å®šè§’è‰²

```python
from langchain_core.messages import SystemMessage, HumanMessage

messages = [
    SystemMessage(content="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ Python æ•™å¸ˆï¼Œå–„äºç”¨ç®€å•çš„ä¾‹å­è§£é‡Šå¤æ‚æ¦‚å¿µã€‚"),
    HumanMessage(content="ä»€ä¹ˆæ˜¯è£…é¥°å™¨ï¼Ÿ")
]

response = chat.invoke(messages)
print(response.content)
```

**æ•ˆæœï¼š**
- AI ä¼šä»¥æ•™å¸ˆçš„è§’è‰²å›ç­”
- ä½¿ç”¨æ•™å­¦æ€§çš„è¯­è¨€å’Œç¤ºä¾‹

### 2. æµå¼è¾“å‡ºä¼˜åŒ–ç”¨æˆ·ä½“éªŒ

```python
# å®Œæ•´è¾“å‡ºï¼ˆç”¨æˆ·ç­‰å¾…è¾ƒä¹…ï¼‰
response = chat.invoke("å†™ä¸€ç¯‡å…³äº AI çš„æ–‡ç« ")
print(response.content)  # ç­‰å¾… 10 ç§’åä¸€æ¬¡æ€§æ˜¾ç¤º

# æµå¼è¾“å‡ºï¼ˆå®æ—¶åé¦ˆï¼‰
for chunk in chat.stream("å†™ä¸€ç¯‡å…³äº AI çš„æ–‡ç« "):
    print(chunk.content, end="", flush=True)  # é€ token æ˜¾ç¤º
```

### 3. æœç´¢ç»“æœåå¤„ç†

```python
# æå–æ‰€æœ‰ URL
urls = [doc['url'] for doc in search_docs]

# åˆå¹¶æ‰€æœ‰å†…å®¹
combined_content = "\n\n".join([doc['content'] for doc in search_docs])

# ç»“åˆæœç´¢ç»“æœç”Ÿæˆå›ç­”
messages = [
    SystemMessage(content=f"åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š\n{combined_content}"),
    HumanMessage(content="ä»€ä¹ˆæ˜¯ LangGraphï¼Ÿ")
]
response = chat.invoke(messages)
```

---

## ğŸ“Š æˆæœ¬ä¼˜åŒ–

### Token ä½¿ç”¨ç»Ÿè®¡

```python
response = chat.invoke("Hello world")

# æŸ¥çœ‹ token ä½¿ç”¨æƒ…å†µ
metadata = response.response_metadata['token_usage']
print(f"è¾“å…¥ tokens: {metadata['prompt_tokens']}")
print(f"è¾“å‡º tokens: {metadata['completion_tokens']}")
print(f"æ€»è®¡ tokens: {metadata['total_tokens']}")
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
è¾“å…¥ tokens: 9
è¾“å‡º tokens: 9
æ€»è®¡ tokens: 18
```

### æˆæœ¬ä¼°ç®—

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ï¼ˆ$/1M tokensï¼‰ | è¾“å‡ºä»·æ ¼ï¼ˆ$/1M tokensï¼‰ |
|------|----------------------|----------------------|
| GPT-4o | $5.00 | $15.00 |
| GPT-3.5 | $0.50 | $1.50 |

**è®¡ç®—ç¤ºä¾‹ï¼š**
```python
# GPT-4o å¤„ç† 1000 tokens è¾“å…¥ + 1000 tokens è¾“å‡º
cost = (1000/1000000 * 5) + (1000/1000000 * 15)
# = $0.005 + $0.015 = $0.02ï¼ˆ2 åˆ†é’±ï¼‰
```

---

## ğŸ¯ å®é™…åº”ç”¨æ¡ˆä¾‹

### æ¡ˆä¾‹ 1ï¼šç®€å•é—®ç­”æœºå™¨äºº

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage

# åˆå§‹åŒ–æ¨¡å‹
chat = ChatOpenAI(model="gpt-5-nano", temperature=0.7)

# å¯¹è¯å†å²
history = []

def chat_bot(user_input):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    history.append(HumanMessage(content=user_input))

    # è°ƒç”¨æ¨¡å‹
    response = chat.invoke(history)

    # æ·»åŠ  AI å›å¤åˆ°å†å²
    history.append(response)

    return response.content

# ä½¿ç”¨
print(chat_bot("ä½ å¥½"))
print(chat_bot("æˆ‘åˆšæ‰è¯´äº†ä»€ä¹ˆï¼Ÿ"))  # èƒ½è®°ä½ä¸Šä¸‹æ–‡
```

### æ¡ˆä¾‹ 2ï¼šæœç´¢å¢å¼ºé—®ç­”ï¼ˆç®€å• RAGï¼‰

```python
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_openai import ChatOpenAI

chat = ChatOpenAI(model="gpt-5-nano", temperature=0)
search = TavilySearchResults(max_results=3)

def search_qa(question):
    # 1. æœç´¢ç›¸å…³ä¿¡æ¯
    search_results = search.invoke(question)
    context = "\n\n".join([doc['content'] for doc in search_results])

    # 2. ç»“åˆæœç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ
    prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š

ä¿¡æ¯ï¼š
{context}

é—®é¢˜ï¼š{question}

ç­”æ¡ˆï¼š"""

    response = chat.invoke(prompt)
    return response.content

# ä½¿ç”¨
answer = search_qa("LangGraph çš„ä¸»è¦ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ")
print(answer)
```

### æ¡ˆä¾‹ 3ï¼šå¤šæ¨¡å‹å¯¹æ¯”

```python
models = {
    "GPT-4o": ChatOpenAI(model="gpt-5-nano", temperature=0),
    "GPT-3.5": ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
}

question = "è§£é‡Šé‡å­è®¡ç®—"

for name, model in models.items():
    response = model.invoke(question)
    print(f"\n{name} çš„å›ç­”ï¼š")
    print(response.content)
    print(f"Token ä½¿ç”¨ï¼š{response.response_metadata['token_usage']}")
```

---

## ğŸ” å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆè¦ä½¿ç”¨æ¶ˆæ¯å¯¹è±¡è€Œä¸æ˜¯å­—ç¬¦ä¸²ï¼Ÿ

**å­—ç¬¦ä¸²æ–¹å¼ï¼š**
```python
chat.invoke("Hello")  # ç®€å•ï¼Œä½†ä¸¢å¤±ä¸Šä¸‹æ–‡
```

**æ¶ˆæ¯å¯¹è±¡æ–¹å¼ï¼š**
```python
messages = [
    SystemMessage(content="ä½ æ˜¯åŠ©æ‰‹"),
    HumanMessage(content="Hello")
]
chat.invoke(messages)  # ä¿ç•™è§’è‰²ã€å†å²
```

**ä¼˜åŠ¿ï¼š**
- ğŸ”„ æ”¯æŒå¤šè½®å¯¹è¯
- ğŸ­ åŒºåˆ†ç³»ç»Ÿ/ç”¨æˆ·/AI è§’è‰²
- ğŸ“Š æ›´å¥½çš„è°ƒè¯•å’Œæ—¥å¿—

### Q2: temperature=0 çœŸçš„å®Œå…¨ç¡®å®šå—ï¼Ÿ

**ä¸å®Œå…¨ç¡®å®šï¼**

```python
chat = ChatOpenAI(temperature=0)

# ç›¸åŒè¾“å…¥ï¼Œ99% æƒ…å†µè¾“å‡ºç›¸åŒ
response1 = chat.invoke("1+1=?")  # â†’ "2"
response2 = chat.invoke("1+1=?")  # â†’ "2"

# ä½†æ¨¡å‹æ›´æ–°æˆ–å…¶ä»–å› ç´ å¯èƒ½å¯¼è‡´å¾®å°å·®å¼‚
```

**ä½•æ—¶ä½¿ç”¨ temperature=0ï¼Ÿ**
- âœ… éœ€è¦ä¸€è‡´æ€§çš„ä»»åŠ¡ï¼ˆæµ‹è¯•ã€è¯„ä¼°ï¼‰
- âœ… äº‹å®æ€§å›ç­”
- âŒ ä¸é€‚åˆåˆ›æ„ä»»åŠ¡

### Q3: å¦‚ä½•é€‰æ‹© max_resultsï¼Ÿ

```python
# æœç´¢ç»“æœæ•°é‡æƒè¡¡
search = TavilySearchResults(max_results=N)
```

| max_results | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|------------|------|------|
| 1-3 | å¿«é€Ÿã€èšç„¦ | å¯èƒ½é—æ¼ä¿¡æ¯ |
| 5-10 | å…¨é¢ | æˆæœ¬é«˜ã€å™ªéŸ³å¤š |
| 10+ | æœ€å…¨é¢ | è¶…è¿‡ LLM ä¸Šä¸‹æ–‡é™åˆ¶ |

**æ¨èï¼š**
- ç®€å•é—®é¢˜ï¼š3
- å¤æ‚ç ”ç©¶ï¼š5-10
- å¯¹æ¯”åˆ†æï¼š3-5

---

## ğŸ“– æ‰©å±•é˜…è¯»

- [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)
- [Chat Models æ¦‚å¿µè¯¦è§£](https://python.langchain.com/v0.2/docs/concepts/#chat-models)
- [OpenAI API å®šä»·](https://openai.com/api/pricing/)
- [Tavily æœç´¢ API](https://tavily.com/)
- [LangGraph å®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)

---

## ğŸ‰ ä¸‹ä¸€æ­¥

æ­å–œä½ å®Œæˆäº† LangChain Academy åŸºç¡€æ¨¡å—ï¼ä½ å·²ç»æŒæ¡äº†ï¼š

âœ… LangChain å’Œ LangGraph çš„æ ¸å¿ƒæ¦‚å¿µ
âœ… Chat Models çš„åˆå§‹åŒ–å’Œè°ƒç”¨
âœ… æ¶ˆæ¯ç³»ç»Ÿçš„ä½¿ç”¨
âœ… æœç´¢å·¥å…·çš„é›†æˆ
âœ… API å¯†é’¥å®‰å…¨ç®¡ç†

**æ¥ä¸‹æ¥å­¦ä¹ ï¼š**
1. **Module 1**ï¼šLangGraph æ ¸å¿ƒæ¦‚å¿µï¼ˆStateã€Graphã€Nodeã€Edgeï¼‰
2. **Module 2**ï¼šæ„å»ºä½ çš„ç¬¬ä¸€ä¸ª Agent
3. **Module 4**ï¼šé«˜çº§æ¨¡å¼ï¼ˆMap-Reduceã€Sub-graphsï¼‰

**å®è·µå»ºè®®ï¼š**
- ğŸ”¨ åŠ¨æ‰‹ä¿®æ”¹ä»£ç ï¼Œå°è¯•ä¸åŒå‚æ•°
- ğŸ§ª æµ‹è¯•ä¸åŒæ¨¡å‹çš„æ•ˆæœ
- ğŸ“ è®°å½•é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ³•
- ğŸ’¬ åŠ å…¥ç¤¾åŒºè®¨è®º

---

**æ€»ç»“**ï¼šæœ¬æ¨¡å—æ˜¯ LangGraph å­¦ä¹ ä¹‹æ—…çš„èµ·ç‚¹ã€‚é€šè¿‡æŒæ¡ Chat Models å’Œå·¥å…·é›†æˆï¼Œä½ å·²ç»å…·å¤‡äº†æ„å»º AI åº”ç”¨çš„åŸºç¡€èƒ½åŠ›ã€‚è®°ä½ï¼šLangChain æä¾›**ç»„ä»¶**ï¼ŒLangGraph æä¾›**ç¼–æ’**ï¼Œä¸¤è€…ç»“åˆæ‰èƒ½æ„å»ºå¼ºå¤§çš„ Agent ç³»ç»Ÿï¼
