# LangGraph Deployment è¯¦ç»†è§£è¯» ğŸš€

>  ç½‘ç«™ä½¿ç”¨è¯´æ˜
> - æœ¬ç½‘ç«™å¯ä»¥å…ç™»é™†è¿è¡Œ Python ä»£ç 
> - Python ä»£ç å¯ä»¥ç¼–è¾‘å¹¶ä¸´æ—¶ä¿å­˜ï¼Œä½†ä¸ä¼šæ°¸ä¹…ä¿å­˜ï¼Œç½‘é¡µåˆ·æ–°åä¼šè‡ªåŠ¨è¿˜åŸ
> - å¯¹ç½‘ç«™çš„ä½¿ç”¨æœ‰ä»»ä½•é—®é¢˜ï¼Œå¯ä»¥åˆ° [é—®é¢˜åé¦ˆ](http://localhost:5173/feedback.html) ï¼ˆæŒ‰é’®åœ¨æ¯ä¸ªé¡µé¢çš„å³ä¸‹è§’ï¼‰å…ç™»å½•è¿›è¡Œè¯„è®º
> - è¿è¡Œ `LangGraph/LangChain`ä»£ç ï¼Œéœ€è¦ç”¨æˆ·è¾“å…¥è‡ªå·±çš„ [API Key](http://localhost:5173/python-run.html)
> - é‡è¦å£°æ˜ï¼šæœ¬ç½‘ç«™ä¸ä¼šä¿å­˜ç”¨æˆ·çš„ API Key æ•°æ®ï¼Œè¯·æ”¾å¿ƒè¾“å…¥


## ğŸ“š æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è§£è¯» LangGraph çš„**éƒ¨ç½²ï¼ˆDeploymentï¼‰**æµç¨‹ã€‚éƒ¨ç½²æ˜¯å°†æˆ‘ä»¬æ„å»ºçš„ Agent ä»æœ¬åœ°å¼€å‘ç¯å¢ƒæ¨å‘ç”Ÿäº§ç¯å¢ƒçš„å…³é”®æ­¥éª¤ã€‚é€šè¿‡ LangGraph Cloud å’Œ LangGraph Studioï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°æµ‹è¯•ã€ç›‘æ§å’Œç®¡ç†æˆ‘ä»¬çš„ AI åº”ç”¨ã€‚

---

## ğŸ“š æœ¯è¯­è¡¨

| æœ¯è¯­åç§° | LangGraph å®šä¹‰å’Œè§£è¯» | Python å®šä¹‰å’Œè¯´æ˜ | é‡è¦ç¨‹åº¦ |
|---------|---------------------|------------------|---------|
| **LangGraph Cloud** | LangGraph API çš„æ‰˜ç®¡æœåŠ¡ï¼Œæ”¯æŒä» GitHub è‡ªåŠ¨éƒ¨ç½² | æä¾›å”¯ä¸€ URLã€ç›‘æ§è¿½è¸ªã€ç¯å¢ƒå˜é‡ç®¡ç†çš„äº‘å¹³å° | â­â­â­â­â­ |
| **LangGraph Studio** | å¯è§†åŒ– IDEï¼Œç”¨äºæµ‹è¯•å’Œè°ƒè¯• LangGraph åº”ç”¨ | Web ç•Œé¢ï¼Œæ”¯æŒæœ¬åœ°/äº‘ç«¯æ¨¡å¼ï¼Œå®æ—¶é¢„è§ˆå›¾ç»“æ„å’ŒçŠ¶æ€ | â­â­â­â­â­ |
| **LangGraph SDK** | Python å®¢æˆ·ç«¯åº“ï¼Œç”¨äºç¨‹åºåŒ–è°ƒç”¨ LangGraph API | æä¾› assistantsã€threadsã€runs ç­‰ APIï¼Œæ”¯æŒå¼‚æ­¥æ“ä½œ | â­â­â­â­â­ |
| **langgraph.json** | LangGraph éƒ¨ç½²é…ç½®æ–‡ä»¶ | å®šä¹‰å›¾è·¯å¾„ã€ä¾èµ–ã€ç¯å¢ƒå˜é‡ç­‰éƒ¨ç½²å‚æ•° | â­â­â­â­â­ |
| **Thread** | å¯¹è¯ä¼šè¯çš„çŠ¶æ€å®¹å™¨ï¼Œæ”¯æŒå¤šç”¨æˆ·å¹¶å‘ | é€šè¿‡ client.threads.create() åˆ›å»ºï¼Œç”¨ thread_id æ ‡è¯† | â­â­â­â­â­ |
| **Assistant** | å›¾çš„è¿è¡Œæ—¶å®ä¾‹ï¼Œå¯¹åº”ä¸€ä¸ªå·²éƒ¨ç½²çš„å›¾ | ç”± graph_id æ ‡è¯†ï¼Œå¯æœ‰å¤šä¸ªç‰ˆæœ¬å’Œé…ç½® | â­â­â­â­â­ |
| **stream_mode** | æ§åˆ¶æµå¼è¾“å‡ºæ ¼å¼çš„å‚æ•° | valuesï¼ˆå®Œæ•´çŠ¶æ€ï¼‰/updatesï¼ˆå¢é‡ï¼‰/messagesï¼ˆä»…æ¶ˆæ¯ï¼‰ | â­â­â­â­ |
| **async/await** | Python å¼‚æ­¥ç¼–ç¨‹è¯­æ³•ï¼Œç”¨äºéé˜»å¡ I/O | SDK æ‰€æœ‰æ–¹æ³•éƒ½æ˜¯å¼‚æ­¥çš„ï¼Œéœ€ä½¿ç”¨ await è°ƒç”¨ | â­â­â­â­ |
| **langgraph dev** | å¯åŠ¨æœ¬åœ°å¼€å‘æœåŠ¡å™¨çš„å‘½ä»¤ | æ”¯æŒçƒ­é‡è½½ï¼Œåœ¨ http://127.0.0.1:2024 æä¾› API | â­â­â­â­â­ |
| **getpass** | Python å®‰å…¨è¾“å…¥æ¨¡å—ï¼Œéšè—æ•æ„Ÿä¿¡æ¯ | getpass.getpass() è¾“å…¥æ—¶ä¸æ˜¾ç¤ºå­—ç¬¦ï¼Œé˜²æ­¢å¯†ç æ³„éœ² | â­â­â­â­ |

---

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

### ä¸ºä»€ä¹ˆéœ€è¦éƒ¨ç½²ï¼Ÿ

åœ¨å‰é¢çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å·²ç»å­¦ä¼šäº†ï¼š
- âœ… æ„å»ºå¸¦å·¥å…·çš„ Agentï¼ˆactï¼‰
- âœ… å¤„ç†å·¥å…·è¾“å‡ºï¼ˆobserveï¼‰
- âœ… è®© Agent è¿›è¡Œæ¨ç†ï¼ˆreasonï¼‰
- âœ… ä½¿ç”¨å†…å­˜ä¿æŒçŠ¶æ€ï¼ˆpersist stateï¼‰

ä½†è¿™äº›éƒ½æ˜¯åœ¨æœ¬åœ° Jupyter Notebook ä¸­è¿è¡Œçš„ã€‚è¦è®© Agent çœŸæ­£ä¸ºç”¨æˆ·æœåŠ¡ï¼Œæˆ‘ä»¬éœ€è¦ï¼š
- ğŸŒ **å¯è®¿é—®æ€§**ï¼šé€šè¿‡ API è®©å…¶ä»–åº”ç”¨è°ƒç”¨
- ğŸ“Š **å¯è§‚æµ‹æ€§**ï¼šç›‘æ§è¿è¡ŒçŠ¶æ€å’Œæ€§èƒ½
- ğŸ”„ **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒå¤šç”¨æˆ·å¹¶å‘è®¿é—®
- ğŸ›¡ï¸ **å¯é æ€§**ï¼šå¤„ç†é”™è¯¯ã€é‡è¯•ã€æŒä¹…åŒ–

è¿™å°±æ˜¯éƒ¨ç½²çš„æ„ä¹‰ï¼

---

## ğŸ—ï¸ LangGraph ç”Ÿæ€æ¶æ„

### æ ¸å¿ƒç»„ä»¶å…³ç³»å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å¼€å‘è€… (You)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“               â†“               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LangGraph   â”‚ â”‚  LangGraph   â”‚ â”‚  LangGraph   â”‚
â”‚   Library    â”‚ â”‚    Studio    â”‚ â”‚     SDK      â”‚
â”‚ (æ„å»ºå›¾ä»£ç )   â”‚ â”‚  (å¯è§†åŒ–IDE)  â”‚ â”‚  (ç¨‹åºåŒ–è°ƒç”¨)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚               â”‚               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LangGraph API                           â”‚
â”‚        (ä»»åŠ¡é˜Ÿåˆ— + æŒä¹…åŒ– + å¼‚æ­¥å¤„ç†)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æœ¬åœ°è¿è¡Œ      â”‚                â”‚ LangGraph    â”‚
â”‚ (å¼€å‘æµ‹è¯•)    â”‚                â”‚   Cloud      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚  (ç”Ÿäº§éƒ¨ç½²)   â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. LangGraph Library

**ä½œç”¨ï¼š** æ ¸å¿ƒ Python/JavaScript åº“ï¼Œç”¨äºæ„å»º Agent å·¥ä½œæµ

```python
from langgraph.graph import StateGraph, START, END

# ä½¿ç”¨ LangGraph å®šä¹‰å›¾
graph = StateGraph(State)
graph.add_node("agent", call_model)
graph.add_edge(START, "agent")
graph.add_edge("agent", END)
app = graph.compile()
```

**ç‰¹ç‚¹ï¼š**
- æä¾›å›¾æ„å»º API
- å®šä¹‰çŠ¶æ€ç®¡ç†
- æ”¯æŒæ¡ä»¶è¾¹ã€å¾ªç¯ç­‰é«˜çº§åŠŸèƒ½

### 2. LangGraph API

**ä½œç”¨ï¼š** å°†å›¾ä»£ç æ‰“åŒ…ä¸ºå¯éƒ¨ç½²çš„æœåŠ¡

**æ ¸å¿ƒåŠŸèƒ½ï¼š**
- ğŸ”„ **ä»»åŠ¡é˜Ÿåˆ—**ï¼šç®¡ç†å¼‚æ­¥æ“ä½œï¼Œå¤„ç†å¹¶å‘è¯·æ±‚
- ğŸ’¾ **æŒä¹…åŒ–**ï¼šä¿å­˜å¯¹è¯å†å²å’ŒçŠ¶æ€ï¼ˆè·¨ä¼šè¯ï¼‰
- ğŸ”Œ **HTTP API**ï¼šæä¾› RESTful æ¥å£

**ä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ**

ç›´æ¥è¿è¡Œå›¾ä»£ç æœ‰é™åˆ¶ï¼š
```python
# æœ¬åœ°ç›´æ¥è¿è¡Œ - åªèƒ½å•æ¬¡æ‰§è¡Œ
app = graph.compile()
result = app.invoke({"messages": [HumanMessage("Hello")]})
```

ä½¿ç”¨ LangGraph APIï¼š
```python
# é€šè¿‡ API - æ”¯æŒæµå¼ã€å¼‚æ­¥ã€å¤šçº¿ç¨‹
async for chunk in client.runs.stream(
    thread_id="user-123",
    assistant_id="agent",
    input={"messages": [HumanMessage("Hello")]}
):
    print(chunk)
```

### 3. LangGraph Cloud

**ä½œç”¨ï¼š** LangGraph API çš„æ‰˜ç®¡æœåŠ¡

**æ ¸å¿ƒç‰¹æ€§ï¼š**
- â˜ï¸ **ä» GitHub éƒ¨ç½²**ï¼šæ¨é€ä»£ç è‡ªåŠ¨éƒ¨ç½²
- ğŸ” **ç›‘æ§å’Œè¿½è¸ª**ï¼šæŸ¥çœ‹æ¯æ¬¡è¿è¡Œçš„è¯¦ç»†æ—¥å¿—
- ğŸŒ **å”¯ä¸€ URL**ï¼šæ¯ä¸ªéƒ¨ç½²è·å¾—ä¸“å±è®¿é—®åœ°å€
- ğŸ”‘ **API å¯†é’¥ç®¡ç†**ï¼šå®‰å…¨ç®¡ç†ç¯å¢ƒå˜é‡

**éƒ¨ç½²æµç¨‹ï¼š**
```
GitHub Repo â†’ LangSmith â†’ LangGraph Cloud â†’ ç”Ÿäº§ URL
```

### 4. LangGraph Studio

**ä½œç”¨ï¼š** å¯è§†åŒ– IDEï¼Œç”¨äºæµ‹è¯•å’Œè°ƒè¯•å›¾

**ä¸¤ç§è¿è¡Œæ¨¡å¼ï¼š**

#### æœ¬åœ°æ¨¡å¼ï¼ˆæ¨èç”¨äºå¼€å‘ï¼‰
```bash
# åœ¨é¡¹ç›®ç›®å½•è¿è¡Œ
langgraph dev

# è¾“å‡ºï¼š
# ğŸš€ API: http://127.0.0.1:2024
# ğŸ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
# ğŸ“š API Docs: http://127.0.0.1:2024/docs
```

**ç‰¹ç‚¹ï¼š**
- å®æ—¶é¢„è§ˆå›¾ç»“æ„
- äº¤äº’å¼æµ‹è¯•å¯¹è¯
- æŸ¥çœ‹æ¯æ­¥çš„çŠ¶æ€å˜åŒ–
- åç«¯ä½¿ç”¨æœ¬åœ° LangGraph API

#### äº‘æ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•ç”Ÿäº§éƒ¨ç½²ï¼‰
- è¿æ¥åˆ° LangGraph Cloud éƒ¨ç½²
- åœ¨çº¿åä½œå’Œåˆ†äº«
- è®¿é—®ç”Ÿäº§ç¯å¢ƒæ•°æ®

### 5. LangGraph SDK

**ä½œç”¨ï¼š** Python å®¢æˆ·ç«¯åº“ï¼Œç”¨äºç¨‹åºåŒ–äº¤äº’

```python
from langgraph_sdk import get_client

# åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆæœ¬åœ°æˆ–äº‘ç«¯ï¼‰
client = get_client(url="http://127.0.0.1:2024")

# åˆ—å‡ºæ‰€æœ‰åŠ©æ‰‹
assistants = await client.assistants.search()

# åˆ›å»ºå¯¹è¯çº¿ç¨‹
thread = await client.threads.create()

# è¿è¡Œå›¾
async for chunk in client.runs.stream(
    thread['thread_id'],
    "agent",
    input={"messages": [...]},
    stream_mode="values"
):
    process(chunk)
```

**ä¸»è¦ APIï¼š**
- `client.assistants` - ç®¡ç†åŠ©æ‰‹ï¼ˆå›¾å®šä¹‰ï¼‰
- `client.threads` - ç®¡ç†å¯¹è¯çº¿ç¨‹ï¼ˆçŠ¶æ€å®¹å™¨ï¼‰
- `client.runs` - æ‰§è¡Œå›¾è¿è¡Œï¼ˆè°ƒç”¨é€»è¾‘ï¼‰

---

## ğŸ› ï¸ æœ¬åœ°éƒ¨ç½²å®æˆ˜

### å‰ç½®å‡†å¤‡

#### 1. é¡¹ç›®ç»“æ„

ç¡®ä¿ä½ çš„é¡¹ç›®åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š

```
module-1/
â”œâ”€â”€ studio/
â”‚   â”œâ”€â”€ agent.py              # å›¾å®šä¹‰ä»£ç 
â”‚   â”œâ”€â”€ langgraph.json        # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ .env                  # ç¯å¢ƒå˜é‡ï¼ˆä¸è¦æäº¤åˆ° Gitï¼ï¼‰
â””â”€â”€ deployment.ipynb          # æµ‹è¯•ä»£ç 
```

#### 2. langgraph.json é…ç½®æ–‡ä»¶

```json
{
  "dependencies": ["."],
  "graphs": {
    "agent": "./agent.py:graph"
  },
  "env": ".env"
}
```

**å­—æ®µè¯´æ˜ï¼š**
- `dependencies`ï¼šPython åŒ…ä¾èµ–è·¯å¾„
- `graphs`ï¼šå›¾å®šä¹‰ï¼Œæ ¼å¼ä¸º `"å›¾ID": "æ–‡ä»¶è·¯å¾„:å˜é‡å"`
- `env`ï¼šç¯å¢ƒå˜é‡æ–‡ä»¶è·¯å¾„

#### 3. agent.py ç¤ºä¾‹

```python
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool

# å®šä¹‰å·¥å…·
@tool
def multiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

# å®šä¹‰çŠ¶æ€
class State(TypedDict):
    messages: Annotated[list, add_messages]

# å®šä¹‰èŠ‚ç‚¹
def call_model(state: State):
    llm = ChatOpenAI(model="gpt-5-nano")
    llm_with_tools = llm.bind_tools([multiply])
    response = llm_with_tools.invoke(state["messages"])
    return {"messages": [response]}

# æ„å»ºå›¾
graph_builder = StateGraph(State)
graph_builder.add_node("agent", call_model)
graph_builder.add_edge(START, "agent")
graph_builder.add_edge("agent", END)
graph = graph_builder.compile()
```

### å¯åŠ¨æœ¬åœ°å¼€å‘æœåŠ¡å™¨

#### æ­¥éª¤ 1ï¼šè¿›å…¥é¡¹ç›®ç›®å½•

```bash
cd /Users/brycewang/langchain-academy/module-1/studio
```

#### æ­¥éª¤ 2ï¼šå¯åŠ¨æœåŠ¡

```bash
langgraph dev
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
âœ“ Configuration loaded from langgraph.json
âœ“ Environment variables loaded from .env
âœ“ Graph 'agent' loaded successfully

- ğŸš€ API: http://127.0.0.1:2024
- ğŸ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- ğŸ“š API Docs: http://127.0.0.1:2024/docs

Watching for changes...
```

**é‡è¦æç¤ºï¼š**
- ä¿æŒç»ˆç«¯è¿è¡Œï¼ˆä¸è¦å…³é—­ï¼ï¼‰
- ä»£ç ä¿®æ”¹ä¼šè‡ªåŠ¨é‡è½½
- è®¿é—® API Docs æŸ¥çœ‹å®Œæ•´ API æ–‡æ¡£

#### æ­¥éª¤ 3ï¼šåœ¨æµè§ˆå™¨æ‰“å¼€ Studio

è®¿é—®ï¼š`https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`

**Studio ç•Œé¢åŠŸèƒ½ï¼š**
- ğŸ“Š **å›¾å¯è§†åŒ–**ï¼šæŸ¥çœ‹èŠ‚ç‚¹å’Œè¾¹çš„è¿æ¥
- ğŸ’¬ **äº¤äº’å¼æµ‹è¯•**ï¼šè¾“å…¥æ¶ˆæ¯ï¼ŒæŸ¥çœ‹ Agent å“åº”
- ğŸ” **çŠ¶æ€æ£€æŸ¥**ï¼šæ¯æ­¥æ‰§è¡ŒåæŸ¥çœ‹çŠ¶æ€å˜åŒ–
- ğŸ› **è°ƒè¯•å·¥å…·**ï¼šæŸ¥çœ‹é”™è¯¯å †æ ˆå’Œæ—¥å¿—

---

## ğŸ’» ä½¿ç”¨ SDK è°ƒç”¨æœ¬åœ° API

### å®‰è£…ä¾èµ–

```python
%pip install --quiet -U langgraph_sdk langchain_core
```

### ä»£ç ç¤ºä¾‹

#### 1. è¿æ¥åˆ°æœ¬åœ°æœåŠ¡å™¨

```python
from langgraph_sdk import get_client

# æœ¬åœ°å¼€å‘æœåŠ¡å™¨åœ°å€
URL = "http://127.0.0.1:2024"
client = get_client(url=URL)
```

**Python çŸ¥è¯†ç‚¹ï¼šasync/await**

LangGraph SDK ä½¿ç”¨å¼‚æ­¥ç¼–ç¨‹ï¼š

```python
# âŒ é”™è¯¯ - åŒæ­¥è°ƒç”¨ä¼šæŠ¥é”™
assistants = client.assistants.search()

# âœ… æ­£ç¡® - å¼‚æ­¥è°ƒç”¨
assistants = await client.assistants.search()
```

**ä¸ºä»€ä¹ˆä½¿ç”¨å¼‚æ­¥ï¼Ÿ**
- éé˜»å¡ I/Oï¼Œæé«˜å¹¶å‘æ€§èƒ½
- æ”¯æŒæµå¼å“åº”
- æ›´å¥½åœ°å¤„ç†é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡

**å¦‚ä½•åœ¨ Jupyter ä¸­ä½¿ç”¨ï¼Ÿ**
Jupyter Notebook é»˜è®¤æ”¯æŒé¡¶å±‚ `await`ï¼š

```python
# ç›´æ¥ä½¿ç”¨ awaitï¼ˆä»…åœ¨ Notebook ä¸­ï¼‰
result = await client.runs.stream(...)

# åœ¨æ™®é€š Python è„šæœ¬ä¸­éœ€è¦ï¼š
import asyncio
asyncio.run(main())
```

#### 2. æœç´¢å¯ç”¨çš„åŠ©æ‰‹ï¼ˆå›¾ï¼‰

```python
# æœç´¢æ‰€æœ‰å·²éƒ¨ç½²çš„å›¾
assistants = await client.assistants.search()

# æŸ¥çœ‹ç¬¬ä¸€ä¸ªåŠ©æ‰‹
print(assistants[0])
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```python
{
    'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',
    'graph_id': 'agent',
    'config': {},
    'metadata': {'created_by': 'system'},
    'name': 'agent',
    'created_at': '2025-03-04T22:57:28.424565+00:00',
    'updated_at': '2025-03-04T22:57:28.424565+00:00',
    'version': 1
}
```

**å­—æ®µè¯´æ˜ï¼š**
- `assistant_id`ï¼šå”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆUUIDï¼‰
- `graph_id`ï¼šå›¾çš„åç§°ï¼ˆæ¥è‡ª `langgraph.json`ï¼‰
- `config`ï¼šé…ç½®é€‰é¡¹ï¼ˆå¦‚æ¨¡å‹å‚æ•°ï¼‰
- `version`ï¼šç‰ˆæœ¬å·ï¼ˆæ”¯æŒå¤šç‰ˆæœ¬éƒ¨ç½²ï¼‰

#### 3. åˆ›å»ºå¯¹è¯çº¿ç¨‹

```python
# åˆ›å»ºæ–°çº¿ç¨‹ç”¨äºè·Ÿè¸ªçŠ¶æ€
thread = await client.threads.create()

print(thread['thread_id'])
# è¾“å‡ºï¼š'1ef6c123-4567-89ab-cdef-0123456789ab'
```

**LangGraph çŸ¥è¯†ç‚¹ï¼šThreadï¼ˆçº¿ç¨‹ï¼‰**

Thread æ˜¯ LangGraph ä¸­çš„**çŠ¶æ€å®¹å™¨**ï¼š

```
Thread = ç‹¬ç«‹çš„å¯¹è¯ä¼šè¯ = ç‹¬ç«‹çš„çŠ¶æ€å¿«ç…§
```

**ä¸ºä»€ä¹ˆéœ€è¦ Threadï¼Ÿ**
- æ”¯æŒå¤šç”¨æˆ·å¹¶å‘ï¼ˆæ¯ä¸ªç”¨æˆ·ä¸€ä¸ª Threadï¼‰
- æŒä¹…åŒ–å¯¹è¯å†å²ï¼ˆè·¨è¯·æ±‚ä¿æŒçŠ¶æ€ï¼‰
- éš”ç¦»ä¸åŒä¼šè¯ï¼ˆé¿å…çŠ¶æ€æ··æ·†ï¼‰

**ç¤ºä¾‹åœºæ™¯ï¼š**
```python
# ç”¨æˆ· A çš„å¯¹è¯
thread_a = await client.threads.create()
client.runs.stream(thread_a['thread_id'], "agent", input={"messages": [...]})

# ç”¨æˆ· B çš„å¯¹è¯ï¼ˆå®Œå…¨ç‹¬ç«‹ï¼‰
thread_b = await client.threads.create()
client.runs.stream(thread_b['thread_id'], "agent", input={"messages": [...]})
```

#### 4. è¿è¡Œå›¾å¹¶æµå¼è¾“å‡º

```python
from langchain_core.messages import HumanMessage

# è¾“å…¥æ¶ˆæ¯
input = {"messages": [HumanMessage(content="Multiply 3 by 2.")]}

# æµå¼è¿è¡Œå›¾
async for chunk in client.runs.stream(
    thread['thread_id'],     # çº¿ç¨‹ ID
    "agent",                 # å›¾ ID
    input=input,             # è¾“å…¥æ•°æ®
    stream_mode="values",    # æµæ¨¡å¼
):
    if chunk.data and chunk.event != "metadata":
        print(chunk.data['messages'][-1])
```

**å‚æ•°è¯¦è§£ï¼š**

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `thread_id` | çº¿ç¨‹æ ‡è¯†ç¬¦ | `'1ef6c123-...'` |
| `assistant_id` | åŠ©æ‰‹ IDï¼ˆå›¾åç§°ï¼‰ | `'agent'` |
| `input` | è¾“å…¥çŠ¶æ€ | `{"messages": [...]}` |
| `stream_mode` | æµæ¨¡å¼ | `"values"` / `"updates"` |

**LangGraph çŸ¥è¯†ç‚¹ï¼šStream Modes**

LangGraph æ”¯æŒå¤šç§æµæ¨¡å¼ï¼š

1. **`stream_mode="values"`** - å®Œæ•´çŠ¶æ€æµ
   ```python
   # æ¯æ­¥åè¿”å›å®Œæ•´çŠ¶æ€
   {'messages': [msg1]}
   {'messages': [msg1, msg2]}
   {'messages': [msg1, msg2, msg3]}
   ```

2. **`stream_mode="updates"`** - å¢é‡æ›´æ–°æµ
   ```python
   # æ¯æ­¥åªè¿”å›æ–°å¢çš„çŠ¶æ€
   {'messages': [msg1]}
   {'messages': [msg2]}
   {'messages': [msg3]}
   ```

3. **`stream_mode="messages"`** - æ¶ˆæ¯æµï¼ˆä»…æ¶ˆæ¯ï¼‰
   ```python
   # ç›´æ¥è¿”å›æ¶ˆæ¯å¯¹è±¡
   AIMessage(content="...")
   ToolMessage(content="...")
   ```

**è¿è¡Œè¾“å‡ºç¤ºä¾‹ï¼š**

```python
# ç¬¬ 1 æ­¥ï¼šç”¨æˆ·æ¶ˆæ¯
{'content': 'Multiply 3 by 2.', 'type': 'human', 'id': 'cdbd7bd8-...'}

# ç¬¬ 2 æ­¥ï¼šAI è°ƒç”¨å·¥å…·
{'content': '', 'type': 'ai', 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 2}}]}

# ç¬¬ 3 æ­¥ï¼šå·¥å…·æ‰§è¡Œç»“æœ
{'content': '6', 'type': 'tool', 'name': 'multiply', 'tool_call_id': 'call_iIPry...'}

# ç¬¬ 4 æ­¥ï¼šAI æœ€ç»ˆå“åº”
{'content': 'The result of multiplying 3 by 2 is 6.', 'type': 'ai'}
```

**ä»£ç è§£æï¼š**

```python
async for chunk in client.runs.stream(...):
    # chunk æ˜¯æµå¼å“åº”çš„ç‰‡æ®µ

    if chunk.data and chunk.event != "metadata":
        # chunk.dataï¼šåŒ…å«çŠ¶æ€æ•°æ®
        # chunk.eventï¼šäº‹ä»¶ç±»å‹ï¼ˆå¦‚ "values", "metadata"ï¼‰

        print(chunk.data['messages'][-1])
        # æ‰“å°æœ€æ–°æ¶ˆæ¯ï¼ˆåˆ—è¡¨æœ€åä¸€é¡¹ï¼‰
```

---

## â˜ï¸ äº‘ç«¯éƒ¨ç½²å®æˆ˜

### éƒ¨ç½²æµç¨‹æ¦‚è§ˆ

```
1. GitHub åˆ›å»ºä»“åº“
         â†“
2. æ¨é€ä»£ç åˆ° GitHub
         â†“
3. LangSmith è¿æ¥ä»“åº“
         â†“
4. é…ç½®éƒ¨ç½²å‚æ•°
         â†“
5. è‡ªåŠ¨éƒ¨ç½²åˆ° LangGraph Cloud
         â†“
6. è·å¾—ç”Ÿäº§ URL
```

### æ­¥éª¤ 1ï¼šåˆ›å»º GitHub ä»“åº“

#### 1.1 åœ¨ GitHub åˆ›å»ºæ–°ä»“åº“

- ç™»å½• [GitHub](https://github.com)
- ç‚¹å‡»å³ä¸Šè§’ "+" â†’ "New repository"
- ä»“åº“åç§°ï¼š`langchain-academy`
- è®¾ç½®ä¸º **Private**ï¼ˆæ¨èï¼Œé¿å…æ³„éœ² API å¯†é’¥ï¼‰
- **ä¸è¦**åˆå§‹åŒ– READMEã€.gitignore æˆ– License

#### 1.2 æ·»åŠ è¿œç¨‹ä»“åº“

```bash
# è¿›å…¥æœ¬åœ°é¡¹ç›®ç›®å½•
cd /Users/brycewang/langchain-academy

# æ·»åŠ è¿œç¨‹ä»“åº“
git remote add origin https://github.com/your-username/langchain-academy.git

# æŸ¥çœ‹è¿œç¨‹ä»“åº“
git remote -v
```

**Git çŸ¥è¯†ç‚¹ï¼šremote**

```bash
git remote add <åç§°> <URL>
#              ^^^^^  ^^^^^^
#              åˆ«å    ä»“åº“åœ°å€

# å¸¸è§åˆ«åï¼š
# origin - é»˜è®¤ä¸»ä»“åº“
# upstream - ä¸Šæ¸¸ä»“åº“ï¼ˆfork æ—¶ä½¿ç”¨ï¼‰
```

#### 1.3 æ¨é€ä»£ç 

```bash
# ç¡®ä¿æ‰€æœ‰æ–‡ä»¶å·²æäº¤
git add .
git commit -m "Add LangGraph agent"

# æ¨é€åˆ° GitHub
git push -u origin main
```

**é‡è¦è­¦å‘Šï¼šä¸è¦æäº¤ .env æ–‡ä»¶ï¼**

ç¡®ä¿ `.gitignore` åŒ…å«ï¼š
```
.env
*.env
.env.local
```

éªŒè¯ï¼š
```bash
# æ£€æŸ¥æ˜¯å¦è¯¯æäº¤äº†æ•æ„Ÿæ–‡ä»¶
git log --all --full-history -- "*.env"
```

### æ­¥éª¤ 2ï¼šåœ¨ LangSmith é…ç½®éƒ¨ç½²

#### 2.1 è®¿é—® LangSmith

- æ‰“å¼€ [LangSmith](https://smith.langchain.com/)
- ç™»å½•ï¼ˆä½¿ç”¨ä¸ LangChain ç›¸åŒçš„è´¦å·ï¼‰

#### 2.2 åˆ›å»ºæ–°éƒ¨ç½²

1. ç‚¹å‡»å·¦ä¾§å¯¼èˆªæ çš„ **"Deployments"** æ ‡ç­¾
2. ç‚¹å‡» **"+ New Deployment"** æŒ‰é’®
3. é€‰æ‹© **"Deploy from GitHub"**

#### 2.3 è¿æ¥ GitHub ä»“åº“

1. **æˆæƒ GitHub**ï¼š
   - é¦–æ¬¡ä½¿ç”¨éœ€è¦æˆæƒ LangSmith è®¿é—® GitHub
   - é€‰æ‹©æˆæƒæ‰€æœ‰ä»“åº“æˆ–ç‰¹å®šä»“åº“

2. **é€‰æ‹©ä»“åº“**ï¼š
   - Repositoryï¼š`your-username/langchain-academy`
   - Branchï¼š`main`

3. **é…ç½®å›¾è·¯å¾„**ï¼š
   - LangGraph API config fileï¼š`module-1/studio/langgraph.json`
   - è¿™æ˜¯ `langgraph.json` æ–‡ä»¶åœ¨ä»“åº“ä¸­çš„è·¯å¾„

#### 2.4 è®¾ç½®ç¯å¢ƒå˜é‡

![LangSmith Deployment Configuration](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbad4fd61c93d48e5d0f47_deployment2.png)

**ä¸ºä»€ä¹ˆéœ€è¦ï¼Ÿ**
- äº‘ç«¯ä¸èƒ½è®¿é—®ä½ çš„æœ¬åœ° `.env` æ–‡ä»¶
- éœ€è¦æ‰‹åŠ¨é…ç½® API å¯†é’¥å’Œå…¶ä»–ç¯å¢ƒå˜é‡

**å¦‚ä½•è®¾ç½®ï¼Ÿ**

æ–¹æ³• 1ï¼šä»æœ¬åœ° .env å¤åˆ¶
```bash
# æŸ¥çœ‹æœ¬åœ°ç¯å¢ƒå˜é‡
cat module-1/studio/.env

# è¾“å‡ºç¤ºä¾‹ï¼š
# OPENAI_API_KEY=sk-proj-...
# TAVILY_API_KEY=tvly-...
```

æ–¹æ³• 2ï¼šåœ¨ LangSmith UI ä¸­æ·»åŠ 
- ç‚¹å‡» "Environment Variables"
- æ·»åŠ æ¯ä¸ªå˜é‡ï¼š
  ```
  Name: OPENAI_API_KEY
  Value: sk-proj-...

  Name: TAVILY_API_KEY
  Value: tvly-...
  ```

**å®‰å…¨æç¤ºï¼š**
- âœ… ä½¿ç”¨ä¸“é—¨çš„ç”Ÿäº§ç¯å¢ƒå¯†é’¥
- âœ… å®šæœŸè½®æ¢å¯†é’¥
- âŒ ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç å¯†é’¥
- âŒ ä¸è¦åœ¨æ—¥å¿—ä¸­æ‰“å°å¯†é’¥

#### 2.5 éƒ¨ç½²

1. æ£€æŸ¥é…ç½®æ— è¯¯
2. ç‚¹å‡» **"Deploy"** æŒ‰é’®
3. ç­‰å¾…éƒ¨ç½²å®Œæˆï¼ˆé€šå¸¸ 1-2 åˆ†é’Ÿï¼‰

**éƒ¨ç½²è¿‡ç¨‹ï¼š**
```
[1/5] å…‹éš† GitHub ä»“åº“
[2/5] å®‰è£… Python ä¾èµ–
[3/5] åŠ è½½å›¾å®šä¹‰
[4/5] è¿è¡Œå¥åº·æ£€æŸ¥
[5/5] åˆ†é… URL
```

#### 2.6 è·å–éƒ¨ç½² URL

éƒ¨ç½²æˆåŠŸåï¼Œä½ ä¼šè·å¾—ä¸€ä¸ªå”¯ä¸€çš„ URLï¼š

```
https://langchain-academy-8011c561878d50b1883f7ed11b32d720.default.us.langgraph.app
```

**URL æ ¼å¼ï¼š**
```
https://<project-name>-<deployment-id>.<region>.langgraph.app
        ^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^  ^^^^^^^^
        é¡¹ç›®åç§°         å”¯ä¸€æ ‡è¯†ç¬¦        åŒºåŸŸ
```

---

### æ­¥éª¤ 3ï¼šä½¿ç”¨ SDK è°ƒç”¨äº‘ç«¯éƒ¨ç½²

#### 3.1 è®¾ç½® LangSmith API å¯†é’¥

```python
import os
import getpass

def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

# è®¾ç½® LangSmith API å¯†é’¥ï¼ˆç”¨äºèº«ä»½éªŒè¯ï¼‰
_set_env("LANGSMITH_API_KEY")
```

**Python çŸ¥è¯†ç‚¹ï¼šgetpass æ¨¡å—**

`getpass` ç”¨äºå®‰å…¨è¾“å…¥å¯†ç ï¼š

```python
import getpass

# æ™®é€š input - å¯†ç ä¼šæ˜¾ç¤º
password = input("Password: ")  # è¾“å…¥: abc123 â†’ å±å¹•æ˜¾ç¤º abc123

# getpass - å¯†ç éšè—
password = getpass.getpass("Password: ")  # è¾“å…¥: abc123 â†’ å±å¹•æ˜¾ç¤º ******
```

**ä¸ºä»€ä¹ˆéœ€è¦ LANGSMITH_API_KEYï¼Ÿ**
- äº‘ç«¯éƒ¨ç½²éœ€è¦èº«ä»½éªŒè¯
- é˜²æ­¢æœªæˆæƒè®¿é—®
- å…³è”åˆ°ä½ çš„ LangSmith è´¦æˆ·

**å¦‚ä½•è·å–ï¼Ÿ**
1. è®¿é—® [LangSmith Settings](https://smith.langchain.com/settings)
2. ç‚¹å‡» "API Keys"
3. åˆ›å»ºæ–°å¯†é’¥æˆ–å¤åˆ¶ç°æœ‰å¯†é’¥

#### 3.2 è¿æ¥åˆ°äº‘ç«¯æœåŠ¡

```python
from langgraph_sdk import get_client

# æ›¿æ¢ä¸ºä½ çš„éƒ¨ç½² URL
URL = "https://langchain-academy-8011c561878d50b1883f7ed11b32d720.default.us.langgraph.app"
client = get_client(url=URL)

# æœç´¢åŠ©æ‰‹
assistants = await client.assistants.search()
```

**é‡è¦æç¤ºï¼š**
- äº‘ç«¯ URL å’Œæœ¬åœ° URL ä½¿ç”¨ç›¸åŒçš„ SDK
- åˆ‡æ¢ç¯å¢ƒåªéœ€æ›´æ”¹ `url` å‚æ•°
- API è°ƒç”¨æ–¹å¼å®Œå…¨ä¸€è‡´

#### 3.3 è¿è¡Œäº‘ç«¯ Agent

```python
from langchain_core.messages import HumanMessage

# é€‰æ‹©åŠ©æ‰‹
agent = assistants[0]

# åˆ›å»ºçº¿ç¨‹
thread = await client.threads.create()

# è¾“å…¥æ¶ˆæ¯
input = {"messages": [HumanMessage(content="Multiply 3 by 2.")]}

# æµå¼è¿è¡Œï¼ˆä¸æœ¬åœ°å®Œå…¨ç›¸åŒï¼ï¼‰
async for chunk in client.runs.stream(
    thread['thread_id'],
    "agent",
    input=input,
    stream_mode="values",
):
    if chunk.data and chunk.event != "metadata":
        print(chunk.data['messages'][-1])
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```python
{'content': 'Multiply 3 by 2.', 'type': 'human', 'id': '8ea04559-...'}
{'content': '', 'type': 'ai', 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 2}}]}
{'content': '6', 'type': 'tool', 'name': 'multiply', 'tool_call_id': 'call_EQool...'}
{'content': '3 multiplied by 2 equals 6.', 'type': 'ai'}
```

---

### æ­¥éª¤ 4ï¼šåœ¨ Studio ä¸­è®¿é—®äº‘ç«¯éƒ¨ç½²

#### 4.1 æ‰“å¼€ LangGraph Studio

- è®¿é—® [LangGraph Studio](https://studio.langchain.com/)
- ç™»å½•ä½ çš„ LangSmith è´¦æˆ·

#### 4.2 é€‰æ‹©äº‘ç«¯éƒ¨ç½²

- åœ¨é¡¶éƒ¨åˆ‡æ¢åˆ° "Cloud" æ¨¡å¼
- é€‰æ‹©ä½ çš„éƒ¨ç½²ï¼ˆå¦‚ `langchain-academy`ï¼‰

#### 4.3 äº¤äº’å¼æµ‹è¯•

![LangGraph Studio Interface](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbad4fa159a09a51d601de_deployment3.png)

Studio æä¾›ä¸æœ¬åœ°ç›¸åŒçš„åŠŸèƒ½ï¼š
- å¯è§†åŒ–å›¾ç»“æ„
- è¾“å…¥æ¶ˆæ¯æµ‹è¯•
- æŸ¥çœ‹çŠ¶æ€å˜åŒ–
- ç›‘æ§æ€§èƒ½æŒ‡æ ‡

**äº‘ç«¯ Studio çš„é¢å¤–åŠŸèƒ½ï¼š**
- ğŸ“Š **è¿è¡Œå†å²**ï¼šæŸ¥çœ‹æ‰€æœ‰å†å²è¿è¡Œè®°å½•
- ğŸ” **è¿½è¸ªè¯¦æƒ…**ï¼šæ¯ä¸ª LLM è°ƒç”¨çš„ token ä½¿ç”¨ã€å»¶è¿Ÿç­‰
- ğŸ‘¥ **å›¢é˜Ÿåä½œ**ï¼šåˆ†äº«ç»™å›¢é˜Ÿæˆå‘˜
- ğŸ“ˆ **ä½¿ç”¨ç»Ÿè®¡**ï¼šAPI è°ƒç”¨é‡ã€è´¹ç”¨ç­‰

---

## ğŸ“ æ ¸å¿ƒçŸ¥è¯†ç‚¹æ€»ç»“

### LangGraph ç‰¹æœ‰æ¦‚å¿µ

#### 1. Deploymentï¼ˆéƒ¨ç½²ï¼‰

**å®šä¹‰ï¼š** å°† LangGraph åº”ç”¨ä»å¼€å‘ç¯å¢ƒè¿ç§»åˆ°ç”Ÿäº§ç¯å¢ƒçš„è¿‡ç¨‹

**å…³é”®ç»„ä»¶ï¼š**
- **langgraph.json**ï¼šé…ç½®æ–‡ä»¶ï¼Œå®šä¹‰å›¾è·¯å¾„å’Œä¾èµ–
- **LangGraph API**ï¼šæä¾› HTTP æ¥å£å’Œä»»åŠ¡é˜Ÿåˆ—
- **Thread**ï¼šçŠ¶æ€å®¹å™¨ï¼Œæ”¯æŒå¤šç”¨æˆ·ä¼šè¯
- **Assistant**ï¼šå›¾çš„è¿è¡Œæ—¶å®ä¾‹

#### 2. Thread vs Assistant

| æ¦‚å¿µ | ä½œç”¨ | ç±»æ¯” | æŒä¹…åŒ– |
|------|------|------|-------|
| **Assistant** | å›¾å®šä¹‰ï¼ˆä»£ç ï¼‰ | ç¨‹åºçš„å¯æ‰§è¡Œæ–‡ä»¶ | æ˜¯ |
| **Thread** | çŠ¶æ€å®ä¾‹ï¼ˆæ•°æ®ï¼‰ | ç¨‹åºçš„è¿è¡Œè¿›ç¨‹ | æ˜¯ |

```python
# ä¸€ä¸ª Assistantï¼ˆå›¾ï¼‰å¯ä»¥æœ‰å¤šä¸ª Threadï¼ˆä¼šè¯ï¼‰
assistant_id = "agent"

thread1 = await client.threads.create()  # ç”¨æˆ· A çš„ä¼šè¯
thread2 = await client.threads.create()  # ç”¨æˆ· B çš„ä¼šè¯

# åŒä¸€ä¸ª Assistantï¼Œä¸åŒçš„ Thread
client.runs.stream(thread1['thread_id'], assistant_id, ...)
client.runs.stream(thread2['thread_id'], assistant_id, ...)
```

#### 3. Stream Modes å¯¹æ¯”

```python
# åœºæ™¯ 1ï¼šéœ€è¦å®Œæ•´çŠ¶æ€ï¼ˆå¦‚ UI æ¸²æŸ“ï¼‰
stream_mode="values"
# â†’ {'messages': [msg1, msg2, msg3]}

# åœºæ™¯ 2ï¼šåªå…³å¿ƒæ–°å¢æ•°æ®ï¼ˆå¦‚å¢é‡æ›´æ–°ï¼‰
stream_mode="updates"
# â†’ {'messages': [msg3]}

# åœºæ™¯ 3ï¼šåªå¤„ç†æ¶ˆæ¯ï¼ˆå¦‚èŠå¤©åº”ç”¨ï¼‰
stream_mode="messages"
# â†’ AIMessage(content="...")
```

#### 4. æœ¬åœ° vs äº‘ç«¯éƒ¨ç½²

| ç‰¹æ€§ | æœ¬åœ°å¼€å‘ (`langgraph dev`) | äº‘ç«¯éƒ¨ç½² (LangGraph Cloud) |
|------|---------------------------|---------------------------|
| **ç”¨é€”** | å¼€å‘å’Œæµ‹è¯• | ç”Ÿäº§ç¯å¢ƒ |
| **URL** | `http://127.0.0.1:2024` | `https://xxx.langgraph.app` |
| **ç¯å¢ƒå˜é‡** | `.env` æ–‡ä»¶ | LangSmith UI é…ç½® |
| **çƒ­é‡è½½** | âœ… æ”¯æŒ | âŒ éœ€è¦é‡æ–°éƒ¨ç½² |
| **æŒä¹…åŒ–** | å†…å­˜ï¼ˆé‡å¯ä¸¢å¤±ï¼‰ | æ•°æ®åº“ï¼ˆæ°¸ä¹…ï¼‰ |
| **ç›‘æ§** | åŸºç¡€æ—¥å¿— | å®Œæ•´è¿½è¸ªå’Œåˆ†æ |
| **æˆæœ¬** | å…è´¹ | æŒ‰ä½¿ç”¨é‡è®¡è´¹ |

---

### Python ç‰¹æœ‰çŸ¥è¯†ç‚¹

#### 1. å¼‚æ­¥ç¼–ç¨‹ï¼ˆasync/awaitï¼‰

**ä¸ºä»€ä¹ˆä½¿ç”¨å¼‚æ­¥ï¼Ÿ**

åŒæ­¥è°ƒç”¨ï¼ˆé˜»å¡ï¼‰ï¼š
```python
# è°ƒç”¨ API â†’ ç­‰å¾…å“åº” â†’ ç»§ç»­æ‰§è¡Œ
result1 = call_api_1()  # ç­‰å¾… 2 ç§’
result2 = call_api_2()  # ç­‰å¾… 2 ç§’
# æ€»è€—æ—¶ï¼š4 ç§’
```

å¼‚æ­¥è°ƒç”¨ï¼ˆéé˜»å¡ï¼‰ï¼š
```python
# åŒæ—¶å‘èµ·å¤šä¸ªè¯·æ±‚ï¼Œå¹¶å‘ç­‰å¾…
result1 = await call_api_1()  # å¼‚æ­¥ç­‰å¾… 2 ç§’
result2 = await call_api_2()  # å¼‚æ­¥ç­‰å¾… 2 ç§’
# æ€»è€—æ—¶ï¼š2 ç§’ï¼ˆå¹¶å‘æ‰§è¡Œï¼‰
```

**åŸºç¡€è¯­æ³•ï¼š**

```python
# å®šä¹‰å¼‚æ­¥å‡½æ•°
async def fetch_data():
    result = await some_async_operation()
    return result

# è°ƒç”¨å¼‚æ­¥å‡½æ•°
# æ–¹å¼ 1ï¼šåœ¨ Jupyter Notebook ä¸­
data = await fetch_data()

# æ–¹å¼ 2ï¼šåœ¨æ™®é€š Python è„šæœ¬ä¸­
import asyncio
data = asyncio.run(fetch_data())
```

**LangGraph SDK ä¸­çš„åº”ç”¨ï¼š**

```python
# âœ… æ‰€æœ‰ SDK æ–¹æ³•éƒ½æ˜¯å¼‚æ­¥çš„
await client.assistants.search()
await client.threads.create()
async for chunk in client.runs.stream(...):
    process(chunk)
```

#### 2. å¼‚æ­¥è¿­ä»£å™¨ï¼ˆasync forï¼‰

**æ™®é€šè¿­ä»£å™¨ï¼š**
```python
# åŒæ­¥è¿­ä»£
for item in [1, 2, 3]:
    print(item)
```

**å¼‚æ­¥è¿­ä»£å™¨ï¼š**
```python
# å¼‚æ­¥è¿­ä»£
async for chunk in async_generator():
    print(chunk)
```

**åœ¨ LangGraph ä¸­çš„ä½¿ç”¨ï¼š**

```python
# client.runs.stream() è¿”å›å¼‚æ­¥ç”Ÿæˆå™¨
async for chunk in client.runs.stream(thread_id, assistant_id, input=...):
    # æ¯æ¬¡ yield ä¸€ä¸ªæ–°çš„çŠ¶æ€ç‰‡æ®µ
    if chunk.data:
        print(chunk.data)
```

**ç­‰ä»·çš„åŒæ­¥å†™æ³•ï¼ˆç†è§£ç”¨ï¼‰ï¼š**
```python
# å¦‚æœ stream() æ˜¯åŒæ­¥çš„ï¼Œä»£ç ä¼šæ˜¯è¿™æ ·ï¼š
for chunk in client.runs.stream_sync(...):  # å‡è®¾æœ‰åŒæ­¥ç‰ˆæœ¬
    print(chunk.data)
```

#### 3. getpass å®‰å…¨è¾“å…¥

```python
import getpass

# å®‰å…¨è¾“å…¥å¯†ç ï¼ˆä¸æ˜¾ç¤ºï¼‰
api_key = getpass.getpass("API Key: ")

# å¸¸è§ä½¿ç”¨æ¨¡å¼
def _set_env(var: str):
    if not os.environ.get(var):
        os.environ[var] = getpass.getpass(f"{var}: ")

_set_env("OPENAI_API_KEY")
```

**å®‰å…¨æ€§ä¼˜åŠ¿ï¼š**
- è¾“å…¥ä¸ä¼šæ˜¾ç¤ºåœ¨å±å¹•ä¸Š
- ä¸ä¼šè¢«æ—¥å¿—è®°å½•
- é˜²æ­¢è‚©çª¥æ”»å‡»ï¼ˆShoulder Surfingï¼‰

#### 4. ç¯å¢ƒå˜é‡ç®¡ç†

**è¯»å–ç¯å¢ƒå˜é‡ï¼š**
```python
import os

# æ–¹å¼ 1ï¼šç›´æ¥è·å–ï¼ˆå¯èƒ½è¿”å› Noneï¼‰
api_key = os.environ.get("OPENAI_API_KEY")

# æ–¹å¼ 2ï¼šå¿…é¡»å­˜åœ¨ï¼ˆä¸å­˜åœ¨ä¼šæŠ¥é”™ï¼‰
api_key = os.environ["OPENAI_API_KEY"]

# æ–¹å¼ 3ï¼šæä¾›é»˜è®¤å€¼
api_key = os.environ.get("OPENAI_API_KEY", "default-key")
```

**è®¾ç½®ç¯å¢ƒå˜é‡ï¼š**
```python
# æ–¹å¼ 1ï¼šä»£ç ä¸­è®¾ç½®ï¼ˆä¸´æ—¶ï¼Œä»…å½“å‰è¿›ç¨‹ï¼‰
os.environ["OPENAI_API_KEY"] = "sk-proj-..."

# æ–¹å¼ 2ï¼š.env æ–‡ä»¶ï¼ˆæ¨èï¼‰
# æ–‡ä»¶ï¼š.env
# å†…å®¹ï¼šOPENAI_API_KEY=sk-proj-...

# åŠ è½½ .env æ–‡ä»¶
from dotenv import load_dotenv
load_dotenv()
```

**æœ€ä½³å®è·µï¼š**
```python
# .env æ–‡ä»¶
OPENAI_API_KEY=sk-proj-...
TAVILY_API_KEY=tvly-...
LANGSMITH_API_KEY=lsv2_...

# Python ä»£ç 
from dotenv import load_dotenv
import os

load_dotenv()  # åŠ è½½ .env

# éªŒè¯å¿…éœ€çš„ç¯å¢ƒå˜é‡
required_vars = ["OPENAI_API_KEY", "TAVILY_API_KEY"]
for var in required_vars:
    if not os.environ.get(var):
        raise ValueError(f"Missing required environment variable: {var}")
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. é¡¹ç›®ç»“æ„è§„èŒƒ

**æ¨èç»“æ„ï¼š**

```
my-langgraph-project/
â”œâ”€â”€ .gitignore              # å¿½ç•¥æ•æ„Ÿæ–‡ä»¶
â”œâ”€â”€ README.md               # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ requirements.txt        # Python ä¾èµ–
â”œâ”€â”€ .env.example            # ç¯å¢ƒå˜é‡æ¨¡æ¿ï¼ˆä¸å«çœŸå®å¯†é’¥ï¼‰
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent.py           # å›¾å®šä¹‰
â”‚   â”œâ”€â”€ tools.py           # å·¥å…·å®šä¹‰
â”‚   â””â”€â”€ utils.py           # å·¥å…·å‡½æ•°
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_agent.py      # å•å…ƒæµ‹è¯•
â””â”€â”€ deployment/
    â”œâ”€â”€ langgraph.json     # éƒ¨ç½²é…ç½®
    â””â”€â”€ .env               # ç¯å¢ƒå˜é‡ï¼ˆä¸æäº¤ï¼ï¼‰
```

**.gitignore å¿…å¤‡å†…å®¹ï¼š**
```
# ç¯å¢ƒå˜é‡
.env
.env.local
*.env

# Python
__pycache__/
*.pyc
.venv/
venv/

# LangGraph
.langraph/
```

### 2. ç¯å¢ƒå˜é‡ç®¡ç†

#### .env.example æ¨¡æ¿

```bash
# OpenAI API
OPENAI_API_KEY=your_openai_key_here

# Tavily Search API
TAVILY_API_KEY=your_tavily_key_here

# LangSmith (for tracing)
LANGSMITH_API_KEY=your_langsmith_key_here
LANGSMITH_PROJECT=my-project
```

**ä½¿ç”¨æµç¨‹ï¼š**
1. å¤åˆ¶ `.env.example` ä¸º `.env`
2. å¡«å…¥çœŸå® API å¯†é’¥
3. `.env` ä¸æäº¤åˆ° Gitï¼ˆé€šè¿‡ `.gitignore`ï¼‰

#### å¤šç¯å¢ƒé…ç½®

```
.env.development    # å¼€å‘ç¯å¢ƒ
.env.staging        # é¢„å‘å¸ƒç¯å¢ƒ
.env.production     # ç”Ÿäº§ç¯å¢ƒ
```

**åŠ è½½æŒ‡å®šç¯å¢ƒï¼š**
```python
import os
from dotenv import load_dotenv

env = os.getenv("ENV", "development")
load_dotenv(f".env.{env}")
```

### 3. ç‰ˆæœ¬ç®¡ç†

#### langgraph.json ç‰ˆæœ¬æ§åˆ¶

```json
{
  "dependencies": ["."],
  "graphs": {
    "agent": "./agent.py:graph"
  },
  "env": ".env",
  "version": "1.0.0"
}
```

#### Git æ ‡ç­¾ï¼ˆTagï¼‰

```bash
# åˆ›å»ºç‰ˆæœ¬æ ‡ç­¾
git tag -a v1.0.0 -m "Release version 1.0.0"

# æ¨é€æ ‡ç­¾åˆ° GitHub
git push origin v1.0.0

# LangSmith éƒ¨ç½²æ—¶å¯ä»¥æŒ‡å®šæ ‡ç­¾
# éƒ¨ç½²é…ç½® â†’ Git Ref â†’ v1.0.0
```

### 4. ç›‘æ§å’Œè°ƒè¯•

#### å¯ç”¨ LangSmith è¿½è¸ª

```python
import os

# å¯ç”¨è¿½è¸ª
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_PROJECT"] = "my-agent-deployment"

# è¿è¡Œ Agent
# æ‰€æœ‰è°ƒç”¨ä¼šè‡ªåŠ¨è®°å½•åˆ° LangSmith
```

**æŸ¥çœ‹è¿½è¸ªï¼š**
1. è®¿é—® [LangSmith](https://smith.langchain.com/)
2. é€‰æ‹©é¡¹ç›® `my-agent-deployment`
3. æŸ¥çœ‹æ¯æ¬¡è¿è¡Œçš„è¯¦ç»†æ—¥å¿—ï¼š
   - LLM è°ƒç”¨ï¼ˆæç¤ºè¯ã€å“åº”ã€token ä½¿ç”¨ï¼‰
   - å·¥å…·è°ƒç”¨ï¼ˆå‚æ•°ã€ç»“æœï¼‰
   - çŠ¶æ€å˜åŒ–ï¼ˆæ¯æ­¥çš„çŠ¶æ€å¿«ç…§ï¼‰

#### æœ¬åœ°è°ƒè¯•æŠ€å·§

```python
# æ·»åŠ è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# åœ¨èŠ‚ç‚¹ä¸­æ‰“å°çŠ¶æ€
def call_model(state: State):
    print(f"Current state: {state}")  # è°ƒè¯•æ—¥å¿—
    response = llm.invoke(state["messages"])
    return {"messages": [response]}
```

### 5. é”™è¯¯å¤„ç†

#### ä¼˜é›…çš„é”™è¯¯æ¢å¤

```python
def call_model(state: State):
    try:
        response = llm.invoke(state["messages"])
        return {"messages": [response]}
    except Exception as e:
        # è®°å½•é”™è¯¯
        logging.error(f"Error in call_model: {e}")

        # è¿”å›é”™è¯¯æ¶ˆæ¯
        return {"messages": [AIMessage(content=f"Sorry, an error occurred: {str(e)}")]}
```

#### é‡è¯•æœºåˆ¶

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def call_model_with_retry(state: State):
    response = llm.invoke(state["messages"])
    return {"messages": [response]}
```

### 6. æ€§èƒ½ä¼˜åŒ–

#### ä½¿ç”¨æµå¼å“åº”

```python
# âŒ ç­‰å¾…å®Œæ•´å“åº”ï¼ˆæ…¢ï¼‰
response = await client.runs.invoke(thread_id, assistant_id, input=...)

# âœ… æµå¼è·å–ï¼ˆå¿«ï¼Œç”¨æˆ·ä½“éªŒå¥½ï¼‰
async for chunk in client.runs.stream(thread_id, assistant_id, input=...):
    display(chunk)  # å®æ—¶æ˜¾ç¤º
```

#### ç¼“å­˜å¸¸ç”¨ç»“æœ

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def expensive_computation(input_data):
    # æ˜‚è´µçš„è®¡ç®—
    return result
```

---

## ğŸš€ è¿›é˜¶æŠ€å·§

### 1. å¤šç‰ˆæœ¬éƒ¨ç½²

**åœºæ™¯ï¼š** åŒæ—¶è¿è¡Œå¤šä¸ªç‰ˆæœ¬çš„ Agentï¼ˆå¦‚ A/B æµ‹è¯•ï¼‰

**å®ç°ï¼š**

```python
# éƒ¨ç½² v1
await client.assistants.create(
    graph_id="agent",
    config={"model": "gpt-5-nano"},
    version="v1"
)

# éƒ¨ç½² v2
await client.assistants.create(
    graph_id="agent",
    config={"model": "gpt-5-nano"},
    version="v2"
)

# ç”¨æˆ·éšæœºåˆ†é…ç‰ˆæœ¬
import random
version = random.choice(["v1", "v2"])
await client.runs.stream(thread_id, f"agent-{version}", input=...)
```

### 2. è‡ªå®šä¹‰é…ç½®

**langgraph.json é«˜çº§é…ç½®ï¼š**

```json
{
  "dependencies": ["."],
  "graphs": {
    "agent": {
      "module": "./agent.py",
      "graph": "graph",
      "config": {
        "model": "gpt-5-nano",
        "temperature": 0.7,
        "max_tokens": 1000
      }
    }
  },
  "env": ".env",
  "python_version": "3.11"
}
```

**åœ¨ä»£ç ä¸­ä½¿ç”¨é…ç½®ï¼š**

```python
from langgraph.graph import StateGraph
from langgraph.config import get_config

def call_model(state: State):
    config = get_config()
    model_name = config.get("model", "gpt-5-nano")
    temperature = config.get("temperature", 0)

    llm = ChatOpenAI(model=model_name, temperature=temperature)
    response = llm.invoke(state["messages"])
    return {"messages": [response]}
```

### 3. ä¸­æ–­å’Œæ¢å¤

**ä½¿ç”¨åœºæ™¯ï¼š** éœ€è¦äººå·¥å®¡æ‰¹çš„å·¥ä½œæµ

```python
from langgraph.checkpoint.memory import MemorySaver

# ç¼–è¯‘æ—¶æ·»åŠ  checkpointer
checkpointer = MemorySaver()
app = graph.compile(checkpointer=checkpointer)

# è¿è¡Œåˆ°ä¸­æ–­ç‚¹
config = {"configurable": {"thread_id": "thread-1"}}
result = app.invoke(input, config=config)

# ç¨åæ¢å¤ï¼ˆä»ä¸Šæ¬¡çŠ¶æ€ç»§ç»­ï¼‰
result = app.invoke(None, config=config)
```

### 4. é›†æˆåˆ°ç”Ÿäº§åº”ç”¨

#### FastAPI é›†æˆ

```python
from fastapi import FastAPI
from langgraph_sdk import get_client

app = FastAPI()
client = get_client(url="http://127.0.0.1:2024")

@app.post("/chat")
async def chat(message: str, thread_id: str):
    input_data = {"messages": [HumanMessage(content=message)]}

    response = ""
    async for chunk in client.runs.stream(
        thread_id,
        "agent",
        input=input_data,
        stream_mode="values"
    ):
        if chunk.data:
            response = chunk.data['messages'][-1]['content']

    return {"response": response}
```

#### Streamlit å‰ç«¯

```python
import streamlit as st
from langgraph_sdk import get_client

st.title("My AI Assistant")

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = get_client(url="http://127.0.0.1:2024")

# åˆ›å»ºæˆ–è·å– thread
if "thread_id" not in st.session_state:
    thread = asyncio.run(client.threads.create())
    st.session_state.thread_id = thread['thread_id']

# èŠå¤©ç•Œé¢
user_input = st.text_input("You:", "")

if user_input:
    input_data = {"messages": [HumanMessage(content=user_input)]}

    async for chunk in client.runs.stream(
        st.session_state.thread_id,
        "agent",
        input=input_data,
        stream_mode="values"
    ):
        if chunk.data:
            st.write("AI:", chunk.data['messages'][-1]['content'])
```

---

## ğŸ” å¸¸è§é—®é¢˜

### Q1: æœ¬åœ°å¼€å‘æ—¶ï¼Œä¿®æ”¹ä»£ç åéœ€è¦é‡å¯æœåŠ¡å™¨å—ï¼Ÿ

**ç­”ï¼š** ä¸éœ€è¦ï¼`langgraph dev` æ”¯æŒçƒ­é‡è½½ã€‚

```bash
# å¯åŠ¨æœåŠ¡å™¨
langgraph dev

# ä¿®æ”¹ agent.py
# ä¿å­˜æ–‡ä»¶åï¼Œç»ˆç«¯ä¼šæ˜¾ç¤ºï¼š
âœ“ Detected changes in agent.py
âœ“ Reloading graph...
âœ“ Graph reloaded successfully
```

**æ³¨æ„ï¼š** å¦‚æœä¿®æ”¹äº† `langgraph.json` æˆ– `.env`ï¼Œéœ€è¦æ‰‹åŠ¨é‡å¯ã€‚

### Q2: å¦‚ä½•åœ¨æœ¬åœ°å’Œäº‘ç«¯ä¹‹é—´åˆ‡æ¢ï¼Ÿ

**ç­”ï¼š** åªéœ€ä¿®æ”¹ `URL` å‚æ•°ã€‚

```python
# æœ¬åœ°
client = get_client(url="http://127.0.0.1:2024")

# äº‘ç«¯
client = get_client(url="https://xxx.langgraph.app")

# å…¶ä»–ä»£ç å®Œå…¨ç›¸åŒï¼
```

**æœ€ä½³å®è·µï¼š** ä½¿ç”¨ç¯å¢ƒå˜é‡

```python
import os

URL = os.getenv("LANGGRAPH_URL", "http://127.0.0.1:2024")
client = get_client(url=URL)
```

### Q3: Thread çš„çŠ¶æ€ä¼šæŒä¹…åŒ–å¤šä¹…ï¼Ÿ

**æœ¬åœ°ï¼š**
- ä½¿ç”¨å†…å­˜å­˜å‚¨ï¼ˆMemorySaverï¼‰
- é‡å¯æœåŠ¡å™¨åä¸¢å¤±
- é€‚åˆå¼€å‘æµ‹è¯•

**äº‘ç«¯ï¼š**
- ä½¿ç”¨æ•°æ®åº“å­˜å‚¨
- é»˜è®¤ä¿ç•™ 30 å¤©
- å¯é…ç½®ä¿ç•™æ—¶é—´

**æŸ¥è¯¢ Thread çŠ¶æ€ï¼š**
```python
# è·å– Thread çš„å†å²è®°å½•
thread_state = await client.threads.get_state(thread_id)
print(thread_state.values)  # å½“å‰çŠ¶æ€
print(thread_state.next)    # ä¸‹ä¸€æ­¥èŠ‚ç‚¹
```

### Q4: å¦‚ä½•è°ƒè¯•äº‘ç«¯éƒ¨ç½²çš„é”™è¯¯ï¼Ÿ

**æ–¹æ³• 1ï¼šæŸ¥çœ‹ LangSmith æ—¥å¿—**
1. è®¿é—® LangSmith â†’ Deployments
2. é€‰æ‹©ä½ çš„éƒ¨ç½²
3. ç‚¹å‡» "Logs" æ ‡ç­¾
4. æŸ¥çœ‹é”™è¯¯å †æ ˆå’Œè°ƒç”¨è¯¦æƒ…

**æ–¹æ³• 2ï¼šå¯ç”¨è¯¦ç»†è¿½è¸ª**
```python
# åœ¨ langgraph.json ä¸­æ·»åŠ 
{
  "env": ".env",
  "tracing": {
    "enabled": true,
    "project": "my-project"
  }
}
```

**æ–¹æ³• 3ï¼šæœ¬åœ°å¤ç°**
```python
# ä½¿ç”¨ç›¸åŒçš„è¾“å…¥åœ¨æœ¬åœ°æµ‹è¯•
async for chunk in client.runs.stream(
    thread_id,
    "agent",
    input=problematic_input,  # å¯¼è‡´é”™è¯¯çš„è¾“å…¥
    stream_mode="values"
):
    print(chunk)
```

### Q5: éƒ¨ç½²åå¦‚ä½•æ›´æ–°ä»£ç ï¼Ÿ

**æ–¹æ³• 1ï¼šæ¨é€åˆ° GitHubï¼ˆæ¨èï¼‰**
```bash
# ä¿®æ”¹ä»£ç 
vim agent.py

# æäº¤å¹¶æ¨é€
git add .
git commit -m "Update agent logic"
git push origin main

# LangGraph Cloud ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶é‡æ–°éƒ¨ç½²
```

**æ–¹æ³• 2ï¼šæ‰‹åŠ¨è§¦å‘éƒ¨ç½²**
1. è®¿é—® LangSmith â†’ Deployments
2. é€‰æ‹©ä½ çš„éƒ¨ç½²
3. ç‚¹å‡» "Redeploy" æŒ‰é’®

**æ³¨æ„ï¼š** é‡æ–°éƒ¨ç½²ä¼šæœ‰å‡ åˆ†é’Ÿçš„åœæœºæ—¶é—´ã€‚

### Q6: å¦‚ä½•é™åˆ¶ API è°ƒç”¨é€Ÿç‡ï¼Ÿ

**åœºæ™¯ï¼š** é˜²æ­¢æ¶æ„ç”¨æˆ·æ»¥ç”¨æˆ–è¶…å‡º OpenAI é…é¢

**æ–¹æ³• 1ï¼šåœ¨å›¾ä¸­æ·»åŠ é€Ÿç‡é™åˆ¶**
```python
from ratelimit import limits, sleep_and_retry

# æ¯åˆ†é’Ÿæœ€å¤š 10 æ¬¡è°ƒç”¨
@sleep_and_retry
@limits(calls=10, period=60)
def call_model(state: State):
    response = llm.invoke(state["messages"])
    return {"messages": [response]}
```

**æ–¹æ³• 2ï¼šä½¿ç”¨ LangGraph Cloud é…ç½®**
```json
{
  "rate_limits": {
    "per_user": {
      "requests": 100,
      "window": "1h"
    }
  }
}
```

### Q7: stream_mode="values" å’Œ "updates" æœ‰ä»€ä¹ˆå®é™…åŒºåˆ«ï¼Ÿ

**ç¤ºä¾‹åœºæ™¯ï¼š** èŠå¤©åº”ç”¨æ˜¾ç¤º Agent æ€è€ƒè¿‡ç¨‹

**ä½¿ç”¨ "values"ï¼š**
```python
async for chunk in client.runs.stream(thread_id, "agent", input=..., stream_mode="values"):
    # æ¯æ¬¡è·å¾—å®Œæ•´çŠ¶æ€
    all_messages = chunk.data['messages']

    # UI éœ€è¦æ¯æ¬¡é‡æ–°æ¸²æŸ“æ•´ä¸ªå¯¹è¯
    display_all_messages(all_messages)
```

**ä½¿ç”¨ "updates"ï¼š**
```python
async for chunk in client.runs.stream(thread_id, "agent", input=..., stream_mode="updates"):
    # åªè·å¾—æ–°å¢æ¶ˆæ¯
    new_messages = chunk.data['messages']

    # UI åªéœ€è¦è¿½åŠ æ–°æ¶ˆæ¯
    append_messages(new_messages)
```

**é€‰æ‹©å»ºè®®ï¼š**
- **"values"**ï¼šé€‚åˆç®€å• UIï¼Œæ¯æ¬¡å…¨é‡æ›´æ–°
- **"updates"**ï¼šé€‚åˆå¤æ‚ UIï¼Œéœ€è¦å¢é‡æ›´æ–°ï¼ˆæ›´é«˜æ•ˆï¼‰

---

## ğŸ“Š æœ¬åœ° vs äº‘ç«¯å¯¹æ¯”æ€»ç»“

| ç»´åº¦ | æœ¬åœ°å¼€å‘ | äº‘ç«¯éƒ¨ç½² |
|------|---------|---------|
| **å¯åŠ¨å‘½ä»¤** | `langgraph dev` | é€šè¿‡ LangSmith UI |
| **URL** | `http://127.0.0.1:2024` | `https://xxx.langgraph.app` |
| **ç¯å¢ƒå˜é‡** | `.env` æ–‡ä»¶ | LangSmith UI é…ç½® |
| **ä»£ç æ›´æ–°** | ä¿å­˜æ–‡ä»¶å³å¯ï¼ˆçƒ­é‡è½½ï¼‰ | æ¨é€ Git â†’ è‡ªåŠ¨éƒ¨ç½² |
| **çŠ¶æ€æŒä¹…åŒ–** | å†…å­˜ï¼ˆé‡å¯ä¸¢å¤±ï¼‰ | æ•°æ®åº“ï¼ˆæ°¸ä¹…ï¼‰ |
| **é€‚ç”¨åœºæ™¯** | å¼€å‘ã€æµ‹è¯•ã€è°ƒè¯• | ç”Ÿäº§ã€å¤šç”¨æˆ·ã€é•¿æœŸè¿è¡Œ |
| **æˆæœ¬** | å…è´¹ï¼ˆä»…æœ¬åœ°èµ„æºï¼‰ | æŒ‰ä½¿ç”¨é‡è®¡è´¹ |
| **å¯è§‚æµ‹æ€§** | åŸºç¡€æ—¥å¿— | å®Œæ•´è¿½è¸ªã€ç›‘æ§ã€å‘Šè­¦ |

---

## ğŸ¯ å®æˆ˜ç»ƒä¹ 

### ç»ƒä¹  1ï¼šæœ¬åœ°éƒ¨ç½²ä¸€ä¸ªç®€å• Agent

**ä»»åŠ¡ï¼š** åˆ›å»ºä¸€ä¸ªè®¡ç®—å™¨ Agentï¼Œæ”¯æŒåŠ å‡ä¹˜é™¤

1. åˆ›å»ºé¡¹ç›®ç»“æ„
2. å®šä¹‰å·¥å…·å’Œå›¾
3. é…ç½® `langgraph.json`
4. å¯åŠ¨ `langgraph dev`
5. ä½¿ç”¨ SDK æµ‹è¯•

**æç¤ºï¼š**
```python
@tool
def add(a: int, b: int) -> int:
    """Add two numbers."""
    return a + b

@tool
def subtract(a: int, b: int) -> int:
    """Subtract b from a."""
    return a - b

# ç»‘å®šå·¥å…·åˆ° LLM
tools = [add, subtract]
llm_with_tools = ChatOpenAI(model="gpt-5-nano").bind_tools(tools)
```

### ç»ƒä¹  2ï¼šéƒ¨ç½²åˆ° LangGraph Cloud

**ä»»åŠ¡ï¼š** å°†ç»ƒä¹  1 çš„ Agent éƒ¨ç½²åˆ°äº‘ç«¯

1. åˆ›å»º GitHub ä»“åº“
2. æ¨é€ä»£ç 
3. åœ¨ LangSmith é…ç½®éƒ¨ç½²
4. è·å–ç”Ÿäº§ URL
5. ä½¿ç”¨ SDK è°ƒç”¨äº‘ç«¯ API

### ç»ƒä¹  3ï¼šå¤šçº¿ç¨‹å¯¹è¯

**ä»»åŠ¡ï¼š** åˆ›å»º 3 ä¸ªç‹¬ç«‹çš„å¯¹è¯çº¿ç¨‹ï¼Œæµ‹è¯•çŠ¶æ€éš”ç¦»

```python
# åˆ›å»º 3 ä¸ªçº¿ç¨‹
threads = [await client.threads.create() for _ in range(3)]

# æ¯ä¸ªçº¿ç¨‹å‘é€ä¸åŒæ¶ˆæ¯
messages = [
    "What is 3 + 5?",
    "What is 10 - 2?",
    "What is 4 * 6?"
]

# å¹¶å‘è¿è¡Œ
for thread, message in zip(threads, messages):
    asyncio.create_task(
        client.runs.stream(thread['thread_id'], "agent", input={"messages": [HumanMessage(message)]})
    )
```

---

## ğŸ“– æ‰©å±•é˜…è¯»

- [LangGraph Cloud å®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/cloud/)
- [LangGraph Studio ä½¿ç”¨æŒ‡å—](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/)
- [LangGraph SDK API å‚è€ƒ](https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/)
- [LangSmith è¿½è¸ªå’Œç›‘æ§](https://docs.smith.langchain.com/)

---

**æ€»ç»“ï¼š** é€šè¿‡æœ¬æ•™ç¨‹ï¼Œä½ å·²ç»æŒæ¡äº† LangGraph çš„å®Œæ•´éƒ¨ç½²æµç¨‹ï¼ä»æœ¬åœ°å¼€å‘æµ‹è¯•åˆ°äº‘ç«¯ç”Ÿäº§éƒ¨ç½²ï¼Œå†åˆ°ä½¿ç”¨ SDK è¿›è¡Œç¨‹åºåŒ–è°ƒç”¨ã€‚è¿™äº›æŠ€èƒ½æ˜¯æ„å»ºå¯æ‰©å±•ã€å¯é çš„ AI åº”ç”¨çš„åŸºçŸ³ã€‚ç»§ç»­å®è·µï¼Œæ¢ç´¢æ›´å¤šé«˜çº§åŠŸèƒ½ï¼ğŸš€
