# 1.1 å‡½æ•°åŸºç¡€ï¼šæ‰“é€ å¯å¤ç”¨çš„ Agent ç»„ä»¶

## å¼•è¨€ï¼šä»£ç é‡ç”¨çš„è‰ºæœ¯

æƒ³è±¡ä½ éœ€è¦åœ¨ Agent çš„ 10 ä¸ªä¸åŒåœ°æ–¹è°ƒç”¨ OpenAI APIã€‚ä½ ä¼šå¤åˆ¶ç²˜è´´ 10 æ¬¡ç›¸åŒçš„ä»£ç å—ï¼Ÿç»å¯¹ä¸ä¼šï¼è¿™å°±æ˜¯å‡½æ•°å­˜åœ¨çš„æ„ä¹‰ï¼š**DRY (Don't Repeat Yourself)** åŸåˆ™ã€‚

> **å°ç™½ç†è§£**ï¼šå‡½æ•°å°±åƒæ˜¯ä¸€ä¸ª**é­”æ³•ç›’å­**ï¼š
> - ä½ æŠŠä¸œè¥¿æ”¾è¿›å»ï¼ˆè¾“å…¥/å‚æ•°ï¼‰
> - ç›’å­é‡Œå‘ç”Ÿä¸€äº›æ“ä½œï¼ˆå‡½æ•°ä½“ï¼‰
> - ç„¶åå‡ºæ¥ä¸€ä¸ªç»“æœï¼ˆè¿”å›å€¼ï¼‰
>
> æœ€é‡è¦çš„æ˜¯ï¼šè¿™ä¸ªé­”æ³•ç›’å­å¯ä»¥**åå¤ä½¿ç”¨**ï¼å†™ä¸€æ¬¡ï¼Œç”¨æ— æ•°æ¬¡ã€‚

å‡½æ•°æ˜¯ç¼–ç¨‹çš„åŸºæœ¬æ„å»ºå—ã€‚åœ¨ AI Agent å¼€å‘ä¸­ï¼Œä½ ä¼šç”¨å‡½æ•°æ¥ï¼š
- å°è£… API è°ƒç”¨
- å¤„ç†å’Œè½¬æ¢æ•°æ®
- å®ç°ä¸šåŠ¡é€»è¾‘
- æ„å»ºå¯æµ‹è¯•çš„ç»„ä»¶

æœ¬èŠ‚å°†æ•™ä½ å¦‚ä½•ç¼–å†™**ä¸“ä¸šçº§**çš„ Python å‡½æ•°ï¼Œä¸ºåç»­çš„ Agent å¼€å‘æ‰“ä¸‹åšå®åŸºç¡€ã€‚

## å­¦ä¹ ç›®æ ‡

- âœ… æŒæ¡å‡½æ•°çš„å®šä¹‰ä¸è°ƒç”¨
- âœ… ç†è§£å‚æ•°ä¼ é€’çš„å„ç§å½¢å¼
- âœ… ä½¿ç”¨ç±»å‹æ³¨è§£ç¼–å†™æ¸…æ™°çš„å‡½æ•°ç­¾å
- âœ… ç¼–å†™æ ‡å‡†çš„å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²
- âœ… å®æˆ˜ï¼šå°è£… LLM API è°ƒç”¨

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šå‡½æ•°çš„å®šä¹‰ä¸è°ƒç”¨

### ä¸ºä»€ä¹ˆéœ€è¦å‡½æ•°ï¼Ÿ

> **å°ç™½è§£è¯»**ï¼šæƒ³è±¡ä½ æ˜¯ä¸€ä¸ªé¤å…çš„å¨å¸ˆï¼Œæ¯æ¬¡æœ‰å®¢äººç‚¹"ç•ªèŒ„ç‚’è›‹"ï¼Œä½ éƒ½è¦ä»å¤´æƒ³æ€ä¹ˆåšï¼š
> - å…ˆæ‰“è›‹ã€å†åˆ‡ç•ªèŒ„ã€åŠ ç›ã€çƒ­æ²¹...
>
> è¿™å¤ªç´¯äº†ï¼èªæ˜çš„åšæ³•æ˜¯ï¼š**å†™ä¸€ä»½èœè°±ï¼ˆå‡½æ•°ï¼‰**ï¼Œä»¥åæ¯æ¬¡åšè¿™é“èœï¼Œç…§ç€èœè°±æ¥å°±è¡Œã€‚
>
> å‡½æ•°å°±æ˜¯ç¨‹åºå‘˜çš„"èœè°±"ï¼

### æœ€ç®€å•çš„å‡½æ•°

```python
def greet() -> None:
    """æ‰“å°é—®å€™è¯­"""
    print("Hello, AI Agent!")

# è°ƒç”¨å‡½æ•°
greet()  # è¾“å‡º: Hello, AI Agent!
```

**è§£æ**ï¼š
- `def`: å®šä¹‰å‡½æ•°çš„å…³é”®å­—ï¼ˆdefine çš„ç¼©å†™ï¼‰
- `greet`: å‡½æ•°åï¼ˆä½¿ç”¨ snake_caseï¼Œå³å°å†™+ä¸‹åˆ’çº¿ï¼‰
- `()`: å‚æ•°åˆ—è¡¨ï¼ˆè¿™é‡Œä¸ºç©ºï¼Œè¡¨ç¤ºä¸éœ€è¦è¾“å…¥ï¼‰
- `-> None`: è¿”å›ç±»å‹æ³¨è§£ï¼ˆNone è¡¨ç¤ºä¸è¿”å›å€¼ï¼‰
- `"""..."""`: æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆdocstringï¼‰ï¼Œè§£é‡Šå‡½æ•°æ˜¯å¹²ä»€ä¹ˆçš„

> **å›¾è§£å‡½æ•°ç»“æ„**ï¼š
> ```python
> def greet() -> None:
> â”‚   â”‚      â”‚    â”‚
> â”‚   â”‚      â”‚    â””â”€â”€ è¿”å›ç±»å‹ï¼šå‘Šè¯‰åˆ«äººè¿™ä¸ªå‡½æ•°ä¼šè¿”å›ä»€ä¹ˆ
> â”‚   â”‚      â””â”€â”€ å‚æ•°åˆ—è¡¨ï¼šå‡½æ•°éœ€è¦ä»€ä¹ˆè¾“å…¥
> â”‚   â””â”€â”€ å‡½æ•°åï¼šç»™å‡½æ•°èµ·çš„åå­—
> â””â”€â”€ å…³é”®å­—ï¼šå‘Šè¯‰ Python "æˆ‘è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°"
> ```

### å¸¦å‚æ•°çš„å‡½æ•°

```python
def greet_agent(name: str) -> None:
    """
    å‘æŒ‡å®šçš„ Agent æ‰“æ‹›å‘¼

    Args:
        name: Agent çš„åç§°
    """
    print(f"Hello, {name}!")

# è°ƒç”¨
greet_agent("ResearchBot")  # Hello, ResearchBot!
greet_agent("ChatGPT")      # Hello, ChatGPT!
```

> **å°ç™½ç†è§£ - å‚æ•°å°±æ˜¯"å¡«ç©º"**ï¼š
>
> æƒ³è±¡è¿™ä¸ªå‡½æ•°æ˜¯ä¸€ä¸ª"å¡«ç©ºæ¨¡æ¿"ï¼š
> ```
> Hello, ____!
>        â†‘
>       è¿™é‡Œéœ€è¦å¡«å…¥åå­—
> ```
>
> å½“ä½ è°ƒç”¨ `greet_agent("ChatGPT")` æ—¶ï¼Œå°±æ˜¯æŠŠ "ChatGPT" å¡«å…¥ç©ºæ ¼ã€‚

### å¸¦è¿”å›å€¼çš„å‡½æ•°

```python
def create_greeting(name: str) -> str:
    """
    åˆ›å»ºé—®å€™è¯­å­—ç¬¦ä¸²

    Args:
        name: Agent çš„åç§°

    Returns:
        æ ¼å¼åŒ–çš„é—®å€™è¯­
    """
    return f"Hello, {name}!"

# è°ƒç”¨å¹¶ä½¿ç”¨è¿”å›å€¼
message: str = create_greeting("Claude")
print(message)  # Hello, Claude!
```

> **å°ç™½ç†è§£ - return æ˜¯ä»€ä¹ˆï¼Ÿ**
>
> `return` å°±åƒæ˜¯æŠŠç»“æœ"äº¤å‡ºæ¥"ï¼š
> ```
> è¾“å…¥ "Claude"
>      â†“
> â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
> â”‚  create_greeting å‡½æ•°        â”‚
> â”‚                             â”‚
> â”‚  å¤„ç†ï¼šf"Hello, {name}!"    â”‚
> â”‚                             â”‚
> â”‚  return â† "æŠŠç»“æœäº¤å‡ºæ¥"     â”‚
> â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
>      â†“
> è¾“å‡º "Hello, Claude!"
> ```
>
> - æœ‰ `return` çš„å‡½æ•°ï¼šè®¡ç®—å®Œä¼šæŠŠç»“æœç»™ä½ 
> - æ²¡æœ‰ `return` çš„å‡½æ•°ï¼šåªæ˜¯åšäº‹ï¼Œä¸ç»™ä½ ç»“æœ

> **ğŸ’¡ å…³é”®æ¦‚å¿µ**ï¼š
> - æœ‰ `return` è¯­å¥çš„å‡½æ•°ä¼šè¿”å›å€¼
> - æ²¡æœ‰ `return` æˆ– `return None` çš„å‡½æ•°è¿”å› `None`
> - `return` åçš„ä»£ç ä¸ä¼šæ‰§è¡Œï¼ˆå‡½æ•°ç«‹å³é€€å‡ºï¼‰

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šå‚æ•°ä¼ é€’æœºåˆ¶

### ä¸ºä»€ä¹ˆæœ‰è¿™ä¹ˆå¤šç§å‚æ•°ï¼Ÿ

> **å°ç™½è§£è¯»**ï¼šæƒ³è±¡ä½ å»é¤å…ç‚¹é¤ï¼š
> - **å¿…ç‚¹é¡¹**ï¼ˆä½ç½®å‚æ•°ï¼‰ï¼š"æˆ‘è¦ä¸€ä»½ç‰›æ’"
> - **å¯é€‰é¡¹**ï¼ˆé»˜è®¤å‚æ•°ï¼‰ï¼š"äº”åˆ†ç†Ÿ"ï¼ˆä¸è¯´å°±é»˜è®¤ä¸ƒåˆ†ç†Ÿï¼‰
> - **æŒ‡åé“å§“**ï¼ˆå…³é”®å­—å‚æ•°ï¼‰ï¼š"é…èœè¦è¥¿å…°èŠ±ï¼Œé¥®æ–™è¦å¯ä¹"
> - **éšä¾¿åŠ **ï¼ˆ*args, **kwargsï¼‰ï¼š"è¿˜æœ‰...è¿˜æœ‰...å†æ¥ä¸ªç”œç‚¹"
>
> Python çš„å‚æ•°è®¾è®¡ä¹Ÿæ˜¯è¿™æ ·ï¼Œæ—¢çµæ´»åˆæœ‰è§„åˆ™ï¼

### ä½ç½®å‚æ•°ï¼ˆPositional Argumentsï¼‰

```python
def calculate_cost(
    input_tokens: int,
    output_tokens: int,
    price_per_1k: float
) -> float:
    """
    è®¡ç®— API è°ƒç”¨æˆæœ¬

    Args:
        input_tokens: è¾“å…¥ token æ•°é‡
        output_tokens: è¾“å‡º token æ•°é‡
        price_per_1k: æ¯ 1000 tokens çš„ä»·æ ¼

    Returns:
        æ€»æˆæœ¬ï¼ˆç¾å…ƒï¼‰
    """
    total_tokens: int = input_tokens + output_tokens
    cost: float = (total_tokens / 1000) * price_per_1k
    return cost

# ä½ç½®å‚æ•°è°ƒç”¨ï¼šé¡ºåºå¾ˆé‡è¦ï¼
cost = calculate_cost(1000, 500, 0.002)
print(f"${cost:.4f}")  # $0.0030
```

> **å°ç™½ç†è§£ - ä½ç½®å‚æ•°**ï¼š
>
> ä½ç½®å‚æ•°å°±åƒ"æ’é˜Ÿ"ï¼š
> ```
> calculate_cost(1000, 500, 0.002)
>                â”‚     â”‚     â”‚
>                â†“     â†“     â†“
>       input_tokens  output_tokens  price_per_1k
>           (ç¬¬1ä½)      (ç¬¬2ä½)        (ç¬¬3ä½)
> ```
>
> **é¡ºåºä¸èƒ½ä¹±ï¼** å¦‚æœä½ å†™ `calculate_cost(0.002, 500, 1000)`ï¼Œ
> é‚£ 0.002 ä¼šè¢«å½“æˆ input_tokensï¼Œå®Œå…¨é”™äº†ï¼

### å…³é”®å­—å‚æ•°ï¼ˆKeyword Argumentsï¼‰

```python
# ä½¿ç”¨å…³é”®å­—å‚æ•°ï¼šé¡ºåºæ— å…³ç´§è¦
cost = calculate_cost(
    output_tokens=500,
    input_tokens=1000,
    price_per_1k=0.002
)
print(f"${cost:.4f}")  # $0.0030

# æ··åˆä½¿ç”¨ï¼ˆä½ç½®å‚æ•°å¿…é¡»åœ¨å…³é”®å­—å‚æ•°ä¹‹å‰ï¼‰
cost = calculate_cost(1000, output_tokens=500, price_per_1k=0.002)
```

> **å°ç™½ç†è§£ - å…³é”®å­—å‚æ•°**ï¼š
>
> å…³é”®å­—å‚æ•°å°±åƒ"æŒ‡åé“å§“"ï¼š
> ```
> "output_tokens=500" æ„æ€æ˜¯ï¼šæˆ‘è¦æŠŠ 500 ç»™ output_tokens è¿™ä¸ªå‚æ•°
> ```
>
> å¥½å¤„æ˜¯ï¼š
> - é¡ºåºå¯ä»¥éšä¾¿æ¢
> - ä»£ç æ›´æ¸…æ™°ï¼Œä¸€çœ¼å°±çŸ¥é“æ¯ä¸ªå€¼æ˜¯ä»€ä¹ˆæ„æ€
> - ä¸æ€•è®°é”™é¡ºåº

> **âš ï¸ å¸¸è§é™·é˜±**ï¼š
> ```python
> # âŒ é”™è¯¯ï¼šå…³é”®å­—å‚æ•°åœ¨ä½ç½®å‚æ•°ä¹‹å
> cost = calculate_cost(input_tokens=1000, 500, 0.002)
> # SyntaxError: positional argument follows keyword argument
> ```

### é»˜è®¤å‚æ•°å€¼ï¼ˆDefault Argumentsï¼‰

```python
def call_llm(
    prompt: str,
    model: str = "gpt-3.5-turbo",
    temperature: float = 0.7,
    max_tokens: int = 2000
) -> str:
    """
    è°ƒç”¨ LLM APIï¼ˆç®€åŒ–ç‰ˆï¼‰

    Args:
        prompt: æç¤ºè¯
        model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ gpt-3.5-turbo
        temperature: æ¸©åº¦å‚æ•°ï¼Œé»˜è®¤ 0.7
        max_tokens: æœ€å¤§ tokensï¼Œé»˜è®¤ 2000

    Returns:
        LLM å“åº”
    """
    print(f"è°ƒç”¨ {model}ï¼Œtemperature={temperature}ï¼Œmax_tokens={max_tokens}")
    print(f"Prompt: {prompt}")
    return f"[æ¨¡æ‹Ÿå“åº”] æ”¶åˆ°æç¤º: {prompt[:30]}..."

# åªä¼ å¿…éœ€å‚æ•°
response = call_llm("What is AI?")

# è¦†ç›–éƒ¨åˆ†é»˜è®¤å€¼
response = call_llm("What is AI?", model="gpt-4", temperature=0.5)

# ä½¿ç”¨æ‰€æœ‰é»˜è®¤å€¼
response = call_llm(
    "What is AI?",
    model="claude-3-opus",
    temperature=0.9,
    max_tokens=4000
)
```

> **å°ç™½ç†è§£ - é»˜è®¤å‚æ•°**ï¼š
>
> é»˜è®¤å‚æ•°å°±åƒ"é¢„è®¾é€‰é¡¹"ï¼š
> ```python
> model: str = "gpt-3.5-turbo"
> ```
>
> æ„æ€æ˜¯ï¼š"å¦‚æœä½ ä¸å‘Šè¯‰æˆ‘ç”¨ä»€ä¹ˆæ¨¡å‹ï¼Œæˆ‘å°±é»˜è®¤ç”¨ gpt-3.5-turbo"
>
> è¿™è®©å‡½æ•°è°ƒç”¨å˜å¾—å¾ˆæ–¹ä¾¿ï¼š
> - ç®€å•æƒ…å†µï¼š`call_llm("é—®é¢˜")` ï¼ˆç”¨æ‰€æœ‰é»˜è®¤å€¼ï¼‰
> - éœ€è¦å®šåˆ¶ï¼š`call_llm("é—®é¢˜", model="gpt-4")` ï¼ˆåªæ”¹éœ€è¦çš„ï¼‰

> **ğŸ’¡ æœ€ä½³å®è·µ**ï¼š
> - å¿…éœ€å‚æ•°æ”¾åœ¨å‰é¢
> - å¯é€‰å‚æ•°ä½¿ç”¨é»˜è®¤å€¼
> - é»˜è®¤å€¼åº”è¯¥æ˜¯ä¸å¯å˜å¯¹è±¡ï¼ˆå­—ç¬¦ä¸²ã€æ•°å­—ã€Noneï¼‰

> **âš ï¸ å±é™©çš„é»˜è®¤å€¼**ï¼š
> ```python
> # âŒ é”™è¯¯ï¼šä½¿ç”¨å¯å˜å¯¹è±¡ä½œä¸ºé»˜è®¤å€¼
> def add_message(message: str, history: list = []) -> list:
>     history.append(message)
>     return history
>
> # é—®é¢˜ï¼šæ‰€æœ‰è°ƒç”¨å…±äº«åŒä¸€ä¸ªåˆ—è¡¨ï¼
> h1 = add_message("Hello")    # ['Hello']
> h2 = add_message("World")    # ['Hello', 'World'] â† ä¸æ˜¯æœŸæœ›çš„ç»“æœï¼
>
> # âœ… æ­£ç¡®åšæ³•
> def add_message(message: str, history: list | None = None) -> list:
>     if history is None:
>         history = []
>     history.append(message)
>     return history
> ```
>
> **ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Ÿ** å› ä¸º Python ä¸­ï¼Œé»˜è®¤å€¼åªåœ¨å‡½æ•°**å®šä¹‰æ—¶**åˆ›å»ºä¸€æ¬¡ã€‚
> å¦‚æœé»˜è®¤å€¼æ˜¯å¯å˜å¯¹è±¡ï¼ˆå¦‚åˆ—è¡¨ï¼‰ï¼Œæ‰€æœ‰è°ƒç”¨éƒ½ä¼šå…±ç”¨åŒä¸€ä¸ªå¯¹è±¡ï¼

### å¯å˜å‚æ•°ï¼ˆ*args å’Œ **kwargsï¼‰

```python
def log_messages(*messages: str) -> None:
    """
    è®°å½•å¤šæ¡æ¶ˆæ¯

    Args:
        *messages: å¯å˜æ•°é‡çš„æ¶ˆæ¯å­—ç¬¦ä¸²
    """
    for i, msg in enumerate(messages, 1):
        print(f"[{i}] {msg}")

# è°ƒç”¨
log_messages("Starting agent")
log_messages("User input", "Processing", "Generating response")
```

> **å°ç™½ç†è§£ - *args æ˜¯ä»€ä¹ˆï¼Ÿ**
>
> `*args` å°±åƒä¸€ä¸ª"æ”¶çº³è¢‹"ï¼Œå¯ä»¥è£…ä»»æ„æ•°é‡çš„ä½ç½®å‚æ•°ï¼š
> ```
> log_messages("A", "B", "C")
>              â†“    â†“    â†“
>            éƒ½è¢«è£…è¿› messages è¿™ä¸ªå…ƒç»„é‡Œ
>            messages = ("A", "B", "C")
> ```
>
> æ‰€ä»¥ `*` çš„å«ä¹‰æ˜¯ï¼š"æŠŠåé¢æ‰€æœ‰çš„ä½ç½®å‚æ•°éƒ½æ”¶é›†èµ·æ¥"

```python
def create_agent_config(**kwargs: str | int | float) -> dict:
    """
    åˆ›å»º Agent é…ç½®

    Args:
        **kwargs: ä»»æ„å…³é”®å­—å‚æ•°

    Returns:
        é…ç½®å­—å…¸
    """
    config: dict = {
        "model": "gpt-3.5-turbo",
        "temperature": 0.7,
    }
    config.update(kwargs)
    return config

# è°ƒç”¨
config = create_agent_config(
    model="gpt-4",
    temperature=0.5,
    max_tokens=4000,
    custom_param="value"
)
print(config)
```

> **å°ç™½ç†è§£ - **kwargs æ˜¯ä»€ä¹ˆï¼Ÿ**
>
> `**kwargs` å°±åƒä¸€ä¸ª"å‘½åæ”¶çº³è¢‹"ï¼Œå¯ä»¥è£…ä»»æ„æ•°é‡çš„å…³é”®å­—å‚æ•°ï¼š
> ```
> create_agent_config(model="gpt-4", max_tokens=4000)
>                     â†“              â†“
>                   éƒ½è¢«è£…è¿› kwargs è¿™ä¸ªå­—å…¸é‡Œ
>                   kwargs = {"model": "gpt-4", "max_tokens": 4000}
> ```
>
> æ‰€ä»¥ `**` çš„å«ä¹‰æ˜¯ï¼š"æŠŠåé¢æ‰€æœ‰çš„å…³é”®å­—å‚æ•°éƒ½æ”¶é›†èµ·æ¥"

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šè¿”å›å€¼å¤„ç†

### å•è¿”å›å€¼

```python
def get_token_count(text: str) -> int:
    """
    è®¡ç®—æ–‡æœ¬çš„ token æ•°é‡ï¼ˆç®€åŒ–ç‰ˆï¼‰

    Args:
        text: è¾“å…¥æ–‡æœ¬

    Returns:
        token æ•°é‡
    """
    # ç®€åŒ–å®ç°ï¼šæŒ‰ç©ºæ ¼åˆ†è¯
    return len(text.split())

count: int = get_token_count("Hello, how are you?")
print(count)  # 4
```

### å¤šè¿”å›å€¼ï¼ˆä½¿ç”¨å…ƒç»„ï¼‰

```python
def analyze_text(text: str) -> tuple[int, int, float]:
    """
    åˆ†ææ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯

    Args:
        text: è¾“å…¥æ–‡æœ¬

    Returns:
        (å­—ç¬¦æ•°, å•è¯æ•°, å¹³å‡å•è¯é•¿åº¦)
    """
    char_count: int = len(text)
    words: list[str] = text.split()
    word_count: int = len(words)
    avg_word_len: float = char_count / word_count if word_count > 0 else 0.0

    return char_count, word_count, avg_word_len

# è§£åŒ…è¿”å›å€¼
chars, words, avg_len = analyze_text("AI Agent Development")
print(f"å­—ç¬¦: {chars}, å•è¯: {words}, å¹³å‡: {avg_len:.2f}")
```

> **å°ç™½ç†è§£ - å¤šè¿”å›å€¼è§£åŒ…**ï¼š
>
> Python å…è®¸å‡½æ•°è¿”å›å¤šä¸ªå€¼ï¼ˆå…¶å®æ˜¯è¿”å›ä¸€ä¸ªå…ƒç»„ï¼‰ï¼š
> ```python
> return char_count, word_count, avg_word_len
>        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
>                      â†“
>        å®é™…è¿”å› (19, 3, 6.33) è¿™ä¸ªå…ƒç»„
> ```
>
> ç„¶åä½ å¯ä»¥"è§£åŒ…"è¿™ä¸ªå…ƒç»„ï¼š
> ```python
> chars, words, avg_len = analyze_text("AI Agent Development")
>   â”‚      â”‚       â”‚
>   â†“      â†“       â†“
>   19     3      6.33
> ```
>
> å°±åƒæ‹†å¿«é€’ä¸€æ ·ï¼Œä¸€ä¸ªåŒ…è£¹æ‹†å‡ºä¸‰æ ·ä¸œè¥¿ï¼

### è¿”å›å­—å…¸ï¼ˆæ›´æ¸…æ™°çš„å¤šè¿”å›å€¼ï¼‰

```python
def analyze_text_dict(text: str) -> dict[str, int | float]:
    """
    åˆ†ææ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯ï¼ˆè¿”å›å­—å…¸ï¼‰

    Args:
        text: è¾“å…¥æ–‡æœ¬

    Returns:
        åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    words: list[str] = text.split()

    return {
        "char_count": len(text),
        "word_count": len(words),
        "avg_word_length": len(text) / len(words) if words else 0.0,
    }

# ä½¿ç”¨è¿”å›å€¼
stats = analyze_text_dict("LangChain and LangGraph")
print(stats["word_count"])  # 3
print(stats["avg_word_length"])  # 7.0
```

> **å°ç™½ç†è§£ - å­—å…¸ vs å…ƒç»„è¿”å›å€¼**ï¼š
>
> | è¿”å›æ–¹å¼ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
> |---------|------|------|
> | **å…ƒç»„** `(a, b, c)` | ç®€æ´ | å¿…é¡»è®°ä½é¡ºåº |
> | **å­—å…¸** `{"a": 1}` | æ¸…æ™°ï¼Œå¯ä»¥æŒ‰åå­—å– | ä»£ç ç¨é•¿ |
>
> **å»ºè®®**ï¼šè¿”å› 2-3 ä¸ªå€¼ç”¨å…ƒç»„ï¼Œè¶…è¿‡ 3 ä¸ªç”¨å­—å…¸ã€‚

### æ—©è¿”å›æ¨¡å¼ï¼ˆEarly Returnï¼‰

```python
def validate_and_process(
    text: str,
    max_length: int = 1000
) -> str | None:
    """
    éªŒè¯å¹¶å¤„ç†æ–‡æœ¬

    Args:
        text: è¾“å…¥æ–‡æœ¬
        max_length: æœ€å¤§é•¿åº¦

    Returns:
        å¤„ç†åçš„æ–‡æœ¬ï¼ŒéªŒè¯å¤±è´¥è¿”å› None
    """
    # æ—©è¿”å›ï¼šéªŒè¯å¤±è´¥ç«‹å³è¿”å›
    if not text:
        print("é”™è¯¯: æ–‡æœ¬ä¸ºç©º")
        return None

    if len(text) > max_length:
        print(f"é”™è¯¯: æ–‡æœ¬è¶…è¿‡æœ€å¤§é•¿åº¦ {max_length}")
        return None

    # ä¸»é€»è¾‘
    processed = text.strip().lower()
    return processed

# ä½¿ç”¨
result = validate_and_process("  Hello World  ")
if result:
    print(f"å¤„ç†ç»“æœ: {result}")
```

> **å°ç™½ç†è§£ - æ—©è¿”å›æ¨¡å¼**ï¼š
>
> ä¼ ç»Ÿå†™æ³•ï¼ˆåµŒå¥—æ·±ï¼‰ï¼š
> ```python
> def process(text):
>     if text:
>         if len(text) <= 1000:
>             if text.isalpha():
>                 # ä¸»é€»è¾‘åœ¨è¿™é‡Œ
>                 return text.lower()
> ```
>
> æ—©è¿”å›å†™æ³•ï¼ˆæ‰å¹³åŒ–ï¼‰ï¼š
> ```python
> def process(text):
>     if not text:
>         return None
>     if len(text) > 1000:
>         return None
>     if not text.isalpha():
>         return None
>     # ä¸»é€»è¾‘åœ¨è¿™é‡Œ
>     return text.lower()
> ```
>
> **æ—©è¿”å›çš„å¥½å¤„**ï¼šä»£ç æ›´æ‰å¹³ã€æ›´æ˜“è¯»ã€æ›´å°‘åµŒå¥—ã€‚

---

## ç¬¬å››éƒ¨åˆ†ï¼šç±»å‹æ³¨è§£ä¸æ–‡æ¡£å­—ç¬¦ä¸²

### ä¸ºä»€ä¹ˆéœ€è¦ç±»å‹æ³¨è§£ï¼Ÿ

> **å°ç™½è§£è¯»**ï¼šç±»å‹æ³¨è§£å°±åƒç»™å‡½æ•°å†™"è¯´æ˜ä¹¦"ï¼š
>
> æ²¡æœ‰ç±»å‹æ³¨è§£ï¼š
> ```python
> def process(data, count):
>     ...
> ```
> çœ‹åˆ°è¿™ä¸ªï¼Œä½ ä¼šé—®ï¼šdata æ˜¯ä»€ä¹ˆï¼Ÿå­—ç¬¦ä¸²ï¼Ÿåˆ—è¡¨ï¼Ÿcount æ˜¯æ•´æ•°è¿˜æ˜¯æµ®ç‚¹æ•°ï¼Ÿ
>
> æœ‰ç±»å‹æ³¨è§£ï¼š
> ```python
> def process(data: list[str], count: int) -> dict:
>     ...
> ```
> ä¸€ç›®äº†ç„¶ï¼data æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œcount æ˜¯æ•´æ•°ï¼Œè¿”å›å­—å…¸ã€‚

### å®Œæ•´çš„ç±»å‹æ³¨è§£ç¤ºä¾‹

```python
from typing import Optional, Union

def call_api(
    endpoint: str,
    method: str = "GET",
    data: Optional[dict] = None,
    timeout: float = 30.0
) -> Union[dict, None]:
    """
    è°ƒç”¨ API ç«¯ç‚¹

    è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²ç¤ºä¾‹ï¼Œéµå¾ª Google é£æ ¼ã€‚

    Args:
        endpoint: API ç«¯ç‚¹ URL
        method: HTTP æ–¹æ³•ï¼ˆGET, POST ç­‰ï¼‰
        data: è¯·æ±‚æ•°æ®ï¼ˆå¯é€‰ï¼‰
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        API å“åº”çš„ JSON æ•°æ®ï¼Œå¤±è´¥è¿”å› None

    Raises:
        ValueError: å¦‚æœ method ä¸æ˜¯æœ‰æ•ˆçš„ HTTP æ–¹æ³•
        ConnectionError: å¦‚æœæ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨

    Examples:
        >>> call_api("https://api.example.com/data")
        {'status': 'success', 'data': [...]}

        >>> call_api(
        ...     "https://api.example.com/users",
        ...     method="POST",
        ...     data={"name": "Alice"}
        ... )
        {'id': 123, 'name': 'Alice'}
    """
    # å®ç°ç»†èŠ‚...
    pass
```

> **å°ç™½ç†è§£ - å¸¸è§ç±»å‹æ³¨è§£**ï¼š
>
> | å†™æ³• | å«ä¹‰ |
> |-----|------|
> | `str` | å­—ç¬¦ä¸² |
> | `int` | æ•´æ•° |
> | `float` | æµ®ç‚¹æ•° |
> | `bool` | å¸ƒå°”å€¼ True/False |
> | `list[str]` | å­—ç¬¦ä¸²åˆ—è¡¨ |
> | `dict[str, int]` | é”®æ˜¯å­—ç¬¦ä¸²ã€å€¼æ˜¯æ•´æ•°çš„å­—å…¸ |
> | `str \| None` | å­—ç¬¦ä¸²æˆ– None |
> | `Optional[str]` | ç­‰åŒäº `str \| None` |

### ç±»å‹æ³¨è§£æœ€ä½³å®è·µ

```python
from typing import List, Dict, Tuple, Optional, Union

# âœ… æ¨èï¼šä½¿ç”¨ç°ä»£è¯­æ³•ï¼ˆPython 3.10+ï¼‰
def process_messages(
    messages: list[str],              # è€Œä¸æ˜¯ List[str]
    metadata: dict[str, int],         # è€Œä¸æ˜¯ Dict[str, int]
    result: tuple[int, str],          # è€Œä¸æ˜¯ Tuple[int, str]
    optional_key: str | None = None   # è€Œä¸æ˜¯ Optional[str]
) -> str | int:                       # è€Œä¸æ˜¯ Union[str, int]
    """å¤„ç†æ¶ˆæ¯åˆ—è¡¨"""
    pass

# âœ… å¤æ‚ç±»å‹çš„åˆ«å
MessageHistory = list[dict[str, str]]
AgentConfig = dict[str, str | int | float]

def create_agent(
    history: MessageHistory,
    config: AgentConfig
) -> None:
    """ä½¿ç”¨ç±»å‹åˆ«åä½¿ä»£ç æ›´æ¸…æ™°"""
    pass
```

---

## ç¬¬äº”éƒ¨åˆ†ï¼šå®æˆ˜æ¡ˆä¾‹â€”â€”å°è£… LLM API è°ƒç”¨

è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªçœŸå®çš„ã€å¯å¤ç”¨çš„ LLM API è°ƒç”¨å‡½æ•°ï¼š

```python
"""
LLM API è°ƒç”¨å°è£…
æ¼”ç¤ºå¦‚ä½•å°† API è°ƒç”¨å°è£…æˆå¯å¤ç”¨çš„å‡½æ•°
"""

from typing import Optional
import time


def call_openai_api(
    prompt: str,
    model: str = "gpt-3.5-turbo",
    temperature: float = 0.7,
    max_tokens: int = 2000,
    max_retries: int = 3,
    retry_delay: float = 1.0,
    api_key: Optional[str] = None
) -> dict[str, str | int]:
    """
    è°ƒç”¨ OpenAI APIï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

    è¿™ä¸ªå‡½æ•°å°è£…äº† OpenAI API è°ƒç”¨çš„å¤æ‚æ€§ï¼Œæä¾›ï¼š
    - è‡ªåŠ¨é‡è¯•
    - é”™è¯¯å¤„ç†
    - Token ç»Ÿè®¡
    - æ ‡å‡†åŒ–çš„å“åº”æ ¼å¼

    Args:
        prompt: è¾“å…¥æç¤ºè¯
        model: æ¨¡å‹åç§°
        temperature: æ¸©åº¦å‚æ•° (0-2)
        max_tokens: æœ€å¤§ç”Ÿæˆ tokens
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
        api_key: API å¯†é’¥ï¼ˆå¯é€‰ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰

    Returns:
        åŒ…å«ä»¥ä¸‹é”®çš„å­—å…¸:
        - 'response': LLM å“åº”æ–‡æœ¬
        - 'model': ä½¿ç”¨çš„æ¨¡å‹
        - 'tokens_used': ä½¿ç”¨çš„ token æ•°
        - 'success': æ˜¯å¦æˆåŠŸ

    Raises:
        ValueError: å¦‚æœå‚æ•°æ— æ•ˆ
        RuntimeError: å¦‚æœè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ä»å¤±è´¥

    Examples:
        >>> result = call_openai_api("What is AI?")
        >>> print(result['response'])
        'AI stands for Artificial Intelligence...'

        >>> result = call_openai_api(
        ...     "Explain quantum computing",
        ...     model="gpt-4",
        ...     temperature=0.5
        ... )
    """
    # å‚æ•°éªŒè¯
    if not prompt:
        raise ValueError("Prompt ä¸èƒ½ä¸ºç©º")

    if not (0 <= temperature <= 2):
        raise ValueError("Temperature å¿…é¡»åœ¨ 0-2 ä¹‹é—´")

    if max_tokens <= 0:
        raise ValueError("max_tokens å¿…é¡»å¤§äº 0")

    # é‡è¯•é€»è¾‘
    for attempt in range(max_retries):
        try:
            print(f"[å°è¯• {attempt + 1}/{max_retries}] è°ƒç”¨ {model}...")

            # è¿™é‡Œæ˜¯å®é™…çš„ API è°ƒç”¨
            # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿè°ƒç”¨
            response_text = f"[æ¨¡æ‹Ÿå“åº”] æ”¶åˆ°æç¤º: '{prompt[:50]}...'"
            tokens_used = len(prompt.split()) + len(response_text.split())

            # æ¨¡æ‹ŸæˆåŠŸ
            return {
                "response": response_text,
                "model": model,
                "tokens_used": tokens_used,
                "success": True,
            }

        except Exception as e:
            print(f"é”™è¯¯: {e}")

            if attempt < max_retries - 1:
                print(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                time.sleep(retry_delay)
            else:
                print(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
                return {
                    "response": "",
                    "model": model,
                    "tokens_used": 0,
                    "success": False,
                }

    raise RuntimeError("API è°ƒç”¨å¤±è´¥")


def format_prompt_with_context(
    user_input: str,
    context: list[str],
    system_prompt: str = "You are a helpful AI assistant."
) -> str:
    """
    æ ¼å¼åŒ–åŒ…å«ä¸Šä¸‹æ–‡çš„æç¤ºè¯

    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        context: ä¸Šä¸‹æ–‡æ¶ˆæ¯åˆ—è¡¨
        system_prompt: ç³»ç»Ÿæç¤ºè¯

    Returns:
        æ ¼å¼åŒ–çš„å®Œæ•´æç¤ºè¯
    """
    parts: list[str] = [f"System: {system_prompt}"]

    if context:
        parts.append("\nConversation History:")
        for i, msg in enumerate(context, 1):
            parts.append(f"{i}. {msg}")

    parts.append(f"\nUser: {user_input}")
    parts.append("Assistant:")

    return "\n".join(parts)


def estimate_token_cost(
    token_count: int,
    model: str = "gpt-3.5-turbo"
) -> float:
    """
    ä¼°ç®— API è°ƒç”¨æˆæœ¬

    Args:
        token_count: token æ•°é‡
        model: æ¨¡å‹åç§°

    Returns:
        ä¼°ç®—æˆæœ¬ï¼ˆç¾å…ƒï¼‰
    """
    # ç®€åŒ–çš„å®šä»·è¡¨
    pricing: dict[str, float] = {
        "gpt-3.5-turbo": 0.002,
        "gpt-4": 0.03,
        "gpt-4-turbo": 0.01,
    }

    price_per_1k = pricing.get(model, 0.002)
    cost = (token_count / 1000) * price_per_1k

    return cost


# æ¼”ç¤ºä½¿ç”¨
def main() -> None:
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤º LLM API è°ƒç”¨"""

    # 1. ç®€å•è°ƒç”¨
    print("=== ç®€å•è°ƒç”¨ ===")
    result = call_openai_api("What is machine learning?")
    print(f"å“åº”: {result['response']}")
    print(f"Tokens: {result['tokens_used']}")

    # 2. å¸¦ä¸Šä¸‹æ–‡çš„è°ƒç”¨
    print("\n=== å¸¦ä¸Šä¸‹æ–‡è°ƒç”¨ ===")
    context = [
        "User: Hello",
        "Assistant: Hi! How can I help you?",
    ]
    prompt = format_prompt_with_context(
        "What is AI?",
        context,
        "You are a friendly AI tutor."
    )
    result = call_openai_api(prompt, model="gpt-4", temperature=0.5)
    print(f"å“åº”: {result['response']}")

    # 3. æˆæœ¬ä¼°ç®—
    print("\n=== æˆæœ¬ä¼°ç®— ===")
    tokens = result['tokens_used']
    cost = estimate_token_cost(tokens, model="gpt-4")
    print(f"ä½¿ç”¨ {tokens} tokensï¼Œä¼°ç®—æˆæœ¬: ${cost:.4f}")


if __name__ == "__main__":
    main()
```

---

## æœ¬èŠ‚æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **å‡½æ•°æ˜¯ä»£ç å¤ç”¨çš„åŸºç¡€** - DRY åŸåˆ™
2. **ç±»å‹æ³¨è§£æ˜¯å¿…é¡»çš„** - è®©ä»£ç è‡ªæ–‡æ¡£åŒ–
3. **æ–‡æ¡£å­—ç¬¦ä¸²å¾ˆé‡è¦** - æœªæ¥çš„ä½ ä¼šæ„Ÿè°¢ç°åœ¨çš„ä½ 
4. **å‚æ•°é¡ºåº**: ä½ç½®å‚æ•° â†’ é»˜è®¤å‚æ•° â†’ *args â†’ **kwargs
5. **æ—©è¿”å›æ¨¡å¼** - å‡å°‘åµŒå¥—ï¼Œæé«˜å¯è¯»æ€§

### æ ¸å¿ƒæ¦‚å¿µä¸€è§ˆè¡¨

| æ¦‚å¿µ | ä¸€å¥è¯è§£é‡Š | ç”Ÿæ´»æ¯”å–» |
|------|----------|---------|
| **å‡½æ•°** | å¯å¤ç”¨çš„ä»£ç å— | èœè°± |
| **å‚æ•°** | å‡½æ•°çš„è¾“å…¥ | åšèœéœ€è¦çš„é£Ÿæ |
| **è¿”å›å€¼** | å‡½æ•°çš„è¾“å‡º | åšå¥½çš„èœ |
| **ä½ç½®å‚æ•°** | æŒ‰é¡ºåºä¼ å…¥ | æ’é˜Ÿä¹°ç¥¨ |
| **å…³é”®å­—å‚æ•°** | æŒ‡åé“å§“ä¼ å…¥ | ç‚¹åå«å· |
| **é»˜è®¤å‚æ•°** | æœ‰é¢„è®¾å€¼çš„å‚æ•° | é»˜è®¤ä¸ƒåˆ†ç†Ÿ |
| **ç±»å‹æ³¨è§£** | è¯´æ˜å‚æ•°/è¿”å›å€¼ç±»å‹ | äº§å“è¯´æ˜ä¹¦ |

### æœ€ä½³å®è·µæ¸…å•

- âœ… å‡½æ•°åä½¿ç”¨å°å†™+ä¸‹åˆ’çº¿ï¼ˆsnake_caseï¼‰
- âœ… å‡½æ•°åº”è¯¥åªåšä¸€ä»¶äº‹ï¼ˆå•ä¸€èŒè´£ï¼‰
- âœ… ä½¿ç”¨ç±»å‹æ³¨è§£
- âœ… ç¼–å†™æ–‡æ¡£å­—ç¬¦ä¸²
- âœ… é»˜è®¤å‚æ•°ä½¿ç”¨ä¸å¯å˜å¯¹è±¡
- âœ… å‚æ•°éªŒè¯æ”¾åœ¨å‡½æ•°å¼€å¤´
- âœ… ä½¿ç”¨æ—©è¿”å›å¤„ç†é”™è¯¯æƒ…å†µ

---

**ä¸‹ä¸€èŠ‚ï¼š[1.2 é«˜é˜¶å‡½æ•°ä¸å‡½æ•°å¼ç¼–ç¨‹](1.2-é«˜é˜¶å‡½æ•°ä¸å‡½æ•°å¼ç¼–ç¨‹.md)**
